{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d822d036",
   "metadata": {},
   "source": [
    "# 한글 손글씨 인식 서비스 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "669397dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel, AutoTokenizer\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel, AutoTokenizer\n",
    "import requests \n",
    "import unicodedata\n",
    "from io import BytesIO\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b48e68e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8050af31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "# load image from the IAM database\n",
    "url = 'https://fki.tic.heia-fr.ch/static/img/a01-122-02-00.jpg'\n",
    "image = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained('microsoft/trocr-large-handwritten')\n",
    "model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-large-handwritten')\n",
    "pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values\n",
    "\n",
    "generated_ids = model.generate(pixel_values)\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddd754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import VisionEncoderDecoderModel\n",
    "\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"team-lucid/trocr-small-korean\")\n",
    "\n",
    "pixel_values = torch.rand(1, 3, 384, 384)\n",
    "generated_ids = model.generate(pixel_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240d7f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel, AutoTokenizer\n",
    "import requests \n",
    "import unicodedata\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained(\"ddobokki/ko-trocr\") \n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"ddobokki/ko-trocr\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ddobokki/ko-trocr\")\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/ddobokki/ocr_img_example/master/g.jpg\"\n",
    "response = requests.get(url)\n",
    "img = Image.open(BytesIO(response.content))\n",
    "\n",
    "pixel_values = processor(img, return_tensors=\"pt\").pixel_values \n",
    "generated_ids = model.generate(pixel_values, max_length=64)\n",
    "generated_text = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "generated_text = unicodedata.normalize(\"NFC\", generated_text)\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57975d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] init TrOCR Inferencer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniforge3/envs/torch/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7871\n",
      "IMPORTANT: You are using gradio version 3.40.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n",
      "Running on public URL: https://354061f7d5e6fb531c.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TrOCRInferencer:\n",
    "    def __init__(self):\n",
    "        print(\"[info] init TrOCR Inferencer\")\n",
    "        self.processor = TrOCRProcessor.from_pretrained(\"ddobokki/ko-trocr\")\n",
    "        self.model = VisionEncoderDecoderModel.from_pretrained(\"ddobokki/ko-trocr\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"ddobokki/ko-trocr\")\n",
    "    def inference(self, image):\n",
    "        pixel_values = self.processor(images=image, return_tensors='pt').pixel_values\n",
    "        generated_ids = self.model.generate(pixel_values, max_length=64)\n",
    "        generated_text = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        generated_text = unicodedata.normalize(\"NFC\", generated_text)\n",
    "        \n",
    "        return generated_text\n",
    "\n",
    "inferencer = TrOCRInferencer()\n",
    "\n",
    "def image_to_text(image):\n",
    "    image = Image.fromarray(image).convert('RGB')\n",
    "    text = inferencer.inference(image)\n",
    "    return text\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"# Handwritten Image OCR\")\n",
    "    with gr.Tab(\"Image upload\"):\n",
    "        image = gr.Image(label=\"Handritten image file\")\n",
    "        output = gr.Textbox(label=\"Output Box\")\n",
    "        convert_btn = gr.Button(\"Convert\")\n",
    "        convert_btn.click(\n",
    "            fn=image_to_text, inputs=image, outputs=output\n",
    "        )\n",
    "        gr.Markdown(\"## Image Examples\")\n",
    "        gr.Examples(\n",
    "            examples=[\n",
    "                os.path.join(os.getcwd(), \"examples/Hello.png\"),\n",
    "                os.path.join(os.getcwd(), \"examples/Hello_cursive.png\"),\n",
    "                os.path.join(os.getcwd(), \"examples/Red.png\"),\n",
    "                os.path.join(os.getcwd(), \"examples/sentence.png\"),\n",
    "                os.path.join(os.getcwd(), \"examples/i_love_you.png\"),\n",
    "                os.path.join(os.getcwd(), \"examples/merrychristmas.png\"),\n",
    "                os.path.join(os.getcwd(), \"examples/Rock.png\"),\n",
    "                os.path.join(os.getcwd(), \"examples/Bob.png\"),\n",
    "                ],\n",
    "            inputs=image,\n",
    "            outputs=output,\n",
    "            fn=image_to_text\n",
    "            )\n",
    "    with gr.Tab(\"Drawing\"):\n",
    "        gr.Markdown(\"# Handwritten Image OCR\")\n",
    "        sketchpad = gr.Sketchpad(\n",
    "            label = \"Handwritten Sektchpad\",\n",
    "            shape=(600, 300),\n",
    "            brush_radius=3,\n",
    "            invert_colors=False,\n",
    "            )\n",
    "        output = gr.Textbox(label=\"Output Box\")\n",
    "        convert_btn = gr.Button(\"Convert\")\n",
    "        convert_btn.click(\n",
    "            fn=image_to_text, inputs=sketchpad, outputs=output\n",
    "            )\n",
    "app.launch(inline=False, share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
