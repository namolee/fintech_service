{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eae9f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9737aa0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2    3      4     5      6        7     8     9     10  \\\n",
       "0      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
       "1      7.8  0.88  0.00  2.6  0.098  25.0   67.0  0.99680  3.20  0.68   9.8   \n",
       "2      7.8  0.76  0.04  2.3  0.092  15.0   54.0  0.99700  3.26  0.65   9.8   \n",
       "3     11.2  0.28  0.56  1.9  0.075  17.0   60.0  0.99800  3.16  0.58   9.8   \n",
       "4      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
       "...    ...   ...   ...  ...    ...   ...    ...      ...   ...   ...   ...   \n",
       "6492   6.2  0.21  0.29  1.6  0.039  24.0   92.0  0.99114  3.27  0.50  11.2   \n",
       "6493   6.6  0.32  0.36  8.0  0.047  57.0  168.0  0.99490  3.15  0.46   9.6   \n",
       "6494   6.5  0.24  0.19  1.2  0.041  30.0  111.0  0.99254  2.99  0.46   9.4   \n",
       "6495   5.5  0.29  0.30  1.1  0.022  20.0  110.0  0.98869  3.34  0.38  12.8   \n",
       "6496   6.0  0.21  0.38  0.8  0.020  22.0   98.0  0.98941  3.26  0.32  11.8   \n",
       "\n",
       "      11  12  \n",
       "0      5   1  \n",
       "1      5   1  \n",
       "2      5   1  \n",
       "3      6   1  \n",
       "4      5   1  \n",
       "...   ..  ..  \n",
       "6492   6   0  \n",
       "6493   5   0  \n",
       "6494   6   0  \n",
       "6495   7   0  \n",
       "6496   6   0  \n",
       "\n",
       "[6497 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/haram4th/ADsP/main/wine.csv\", header=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47b8b0e",
   "metadata": {},
   "source": [
    "1. Alcohol\n",
    "2. Malic acid\n",
    "3. Ash\n",
    "4. Alcalinity of ash\n",
    "5. Magnesium\n",
    "6. Total phenols\n",
    "7. Flavanoids\n",
    "8. Nonflavanoid phenols\n",
    "9. Proanthocyanins\n",
    "10.Color intensity\n",
    "11.Hue\n",
    "12.OD280/OD315 of diluted wines\n",
    "13.Proline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7259c64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6497 entries, 0 to 6496\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       6497 non-null   float64\n",
      " 1   1       6497 non-null   float64\n",
      " 2   2       6497 non-null   float64\n",
      " 3   3       6497 non-null   float64\n",
      " 4   4       6497 non-null   float64\n",
      " 5   5       6497 non-null   float64\n",
      " 6   6       6497 non-null   float64\n",
      " 7   7       6497 non-null   float64\n",
      " 8   8       6497 non-null   float64\n",
      " 9   9       6497 non-null   float64\n",
      " 10  10      6497 non-null   float64\n",
      " 11  11      6497 non-null   int64  \n",
      " 12  12      6497 non-null   int64  \n",
      "dtypes: float64(11), int64(2)\n",
      "memory usage: 660.0 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aac85a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499a3ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ccfc83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12\n",
       "0    4898\n",
       "1    1599\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[12].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61640759",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(12, axis=1)\n",
    "y = data[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1412e6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4b1056f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.30769231,  2.41176471, -2.21428571, ...,  0.29411765,\n",
       "        -0.5       , -1.        ],\n",
       "       [ 0.61538462,  3.47058824, -2.21428571, ...,  1.        ,\n",
       "        -0.27777778, -1.        ],\n",
       "       [ 0.61538462,  2.76470588, -1.92857143, ...,  0.82352941,\n",
       "        -0.27777778, -1.        ],\n",
       "       ...,\n",
       "       [-0.38461538, -0.29411765, -0.85714286, ..., -0.29411765,\n",
       "        -0.5       ,  0.        ],\n",
       "       [-1.15384615,  0.        , -0.07142857, ..., -0.76470588,\n",
       "         1.38888889,  1.        ],\n",
       "       [-0.76923077, -0.47058824,  0.5       , ..., -1.11764706,\n",
       "         0.83333333,  0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = RobustScaler()\n",
    "X_scaled = rs.fit_transform(X)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96ecc56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "6492    0\n",
       "6493    0\n",
       "6494    0\n",
       "6495    0\n",
       "6496    0\n",
       "Name: 12, Length: 6497, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bc9d732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1df35e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_scaled, y ,test_size=0.4 , stratify=y,random_state=10)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.5,stratify=y_valid, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74083a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87c9e71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                416       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,089\n",
      "Trainable params: 1,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 10:36:03.363255: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-10 10:36:03.367211: I tensorflow/c/logging.cc:34] DirectML: creating device on adapter 0 (AMD Radeon(TM) Graphics)\n",
      "2024-09-10 10:36:03.761307: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 10:36:03.761362: W tensorflow/core/common_runtime/pluggable_device/pluggable_device_bfc_allocator.cc:28] Overriding allow_growth setting because force_memory_growth was requested by the device.\n",
      "2024-09-10 10:36:03.761386: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0246dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/8 [==>...........................] - ETA: 3s - loss: 0.6234 - accuracy: 0.7060"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 10:38:53.089251: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-10 10:38:53.165078: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 10:38:53.165148: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 70ms/step - loss: 0.5925 - accuracy: 0.7589 - val_loss: 0.5562 - val_accuracy: 0.8114\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5127 - accuracy: 0.8630 - val_loss: 0.4806 - val_accuracy: 0.8814\n",
      "Epoch 3/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.4632 - accuracy: 0.8960"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 10:38:53.701170: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-10 10:38:53.726895: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 10:38:53.726980: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4418 - accuracy: 0.9123 - val_loss: 0.4123 - val_accuracy: 0.9184\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3767 - accuracy: 0.9418 - val_loss: 0.3497 - val_accuracy: 0.9415\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3172 - accuracy: 0.9574 - val_loss: 0.2930 - val_accuracy: 0.9623\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.2639 - accuracy: 0.9679 - val_loss: 0.2432 - val_accuracy: 0.9707\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.2171 - accuracy: 0.9731 - val_loss: 0.2007 - val_accuracy: 0.9754\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1776 - accuracy: 0.9779 - val_loss: 0.1660 - val_accuracy: 0.9792\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1455 - accuracy: 0.9831 - val_loss: 0.1384 - val_accuracy: 0.9831\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1204 - accuracy: 0.9851 - val_loss: 0.1171 - val_accuracy: 0.9846\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1009 - accuracy: 0.9859 - val_loss: 0.1007 - val_accuracy: 0.9846\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0861 - accuracy: 0.9874 - val_loss: 0.0883 - val_accuracy: 0.9854\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0748 - accuracy: 0.9885 - val_loss: 0.0788 - val_accuracy: 0.9869\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0660 - accuracy: 0.9890 - val_loss: 0.0714 - val_accuracy: 0.9885\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0593 - accuracy: 0.9895 - val_loss: 0.0656 - val_accuracy: 0.9892\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0541 - accuracy: 0.9900 - val_loss: 0.0609 - val_accuracy: 0.9892\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0497 - accuracy: 0.9905 - val_loss: 0.0572 - val_accuracy: 0.9900\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0462 - accuracy: 0.9903 - val_loss: 0.0543 - val_accuracy: 0.9908\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0433 - accuracy: 0.9903 - val_loss: 0.0518 - val_accuracy: 0.9908\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0408 - accuracy: 0.9908 - val_loss: 0.0497 - val_accuracy: 0.9908\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0386 - accuracy: 0.9913 - val_loss: 0.0479 - val_accuracy: 0.9915\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0367 - accuracy: 0.9915 - val_loss: 0.0464 - val_accuracy: 0.9923\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0351 - accuracy: 0.9920 - val_loss: 0.0451 - val_accuracy: 0.9923\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0337 - accuracy: 0.9928 - val_loss: 0.0440 - val_accuracy: 0.9923\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0324 - accuracy: 0.9931 - val_loss: 0.0430 - val_accuracy: 0.9931\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0313 - accuracy: 0.9936 - val_loss: 0.0421 - val_accuracy: 0.9923\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0301 - accuracy: 0.9938 - val_loss: 0.0413 - val_accuracy: 0.9923\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0292 - accuracy: 0.9941 - val_loss: 0.0406 - val_accuracy: 0.9931\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0283 - accuracy: 0.9941 - val_loss: 0.0399 - val_accuracy: 0.9931\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0275 - accuracy: 0.9944 - val_loss: 0.0394 - val_accuracy: 0.9931\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0268 - accuracy: 0.9946 - val_loss: 0.0389 - val_accuracy: 0.9931\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0261 - accuracy: 0.9946 - val_loss: 0.0384 - val_accuracy: 0.9931\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0254 - accuracy: 0.9949 - val_loss: 0.0380 - val_accuracy: 0.9931\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0248 - accuracy: 0.9949 - val_loss: 0.0376 - val_accuracy: 0.9931\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0243 - accuracy: 0.9956 - val_loss: 0.0372 - val_accuracy: 0.9931\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0238 - accuracy: 0.9956 - val_loss: 0.0368 - val_accuracy: 0.9931\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0233 - accuracy: 0.9956 - val_loss: 0.0365 - val_accuracy: 0.9938\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0229 - accuracy: 0.9956 - val_loss: 0.0362 - val_accuracy: 0.9938\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0224 - accuracy: 0.9956 - val_loss: 0.0359 - val_accuracy: 0.9938\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0220 - accuracy: 0.9959 - val_loss: 0.0356 - val_accuracy: 0.9938\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0216 - accuracy: 0.9959 - val_loss: 0.0353 - val_accuracy: 0.9938\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0212 - accuracy: 0.9959 - val_loss: 0.0352 - val_accuracy: 0.9938\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0208 - accuracy: 0.9962 - val_loss: 0.0349 - val_accuracy: 0.9946\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0205 - accuracy: 0.9964 - val_loss: 0.0346 - val_accuracy: 0.9946\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0201 - accuracy: 0.9962 - val_loss: 0.0345 - val_accuracy: 0.9946\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0198 - accuracy: 0.9962 - val_loss: 0.0343 - val_accuracy: 0.9946\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0195 - accuracy: 0.9962 - val_loss: 0.0341 - val_accuracy: 0.9946\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0192 - accuracy: 0.9962 - val_loss: 0.0340 - val_accuracy: 0.9946\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0189 - accuracy: 0.9964 - val_loss: 0.0339 - val_accuracy: 0.9954\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0186 - accuracy: 0.9964 - val_loss: 0.0337 - val_accuracy: 0.9954\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0183 - accuracy: 0.9964 - val_loss: 0.0335 - val_accuracy: 0.9946\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0181 - accuracy: 0.9962 - val_loss: 0.0334 - val_accuracy: 0.9946\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0178 - accuracy: 0.9962 - val_loss: 0.0332 - val_accuracy: 0.9946\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0175 - accuracy: 0.9962 - val_loss: 0.0331 - val_accuracy: 0.9946\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0173 - accuracy: 0.9964 - val_loss: 0.0330 - val_accuracy: 0.9946\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0170 - accuracy: 0.9964 - val_loss: 0.0328 - val_accuracy: 0.9946\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0168 - accuracy: 0.9967 - val_loss: 0.0327 - val_accuracy: 0.9938\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0165 - accuracy: 0.9967 - val_loss: 0.0327 - val_accuracy: 0.9946\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0163 - accuracy: 0.9967 - val_loss: 0.0326 - val_accuracy: 0.9946\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0160 - accuracy: 0.9969 - val_loss: 0.0325 - val_accuracy: 0.9938\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0158 - accuracy: 0.9969 - val_loss: 0.0325 - val_accuracy: 0.9946\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0155 - accuracy: 0.9969 - val_loss: 0.0323 - val_accuracy: 0.9938\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0153 - accuracy: 0.9969 - val_loss: 0.0324 - val_accuracy: 0.9938\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0151 - accuracy: 0.9969 - val_loss: 0.0322 - val_accuracy: 0.9938\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0149 - accuracy: 0.9969 - val_loss: 0.0321 - val_accuracy: 0.9938\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0147 - accuracy: 0.9969 - val_loss: 0.0320 - val_accuracy: 0.9938\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.0320 - val_accuracy: 0.9938\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0143 - accuracy: 0.9969 - val_loss: 0.0320 - val_accuracy: 0.9938\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0142 - accuracy: 0.9972 - val_loss: 0.0319 - val_accuracy: 0.9946\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0139 - accuracy: 0.9974 - val_loss: 0.0318 - val_accuracy: 0.9938\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0138 - accuracy: 0.9972 - val_loss: 0.0317 - val_accuracy: 0.9938\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0136 - accuracy: 0.9974 - val_loss: 0.0317 - val_accuracy: 0.9938\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0135 - accuracy: 0.9974 - val_loss: 0.0317 - val_accuracy: 0.9946\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0133 - accuracy: 0.9977 - val_loss: 0.0316 - val_accuracy: 0.9938\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0131 - accuracy: 0.9974 - val_loss: 0.0315 - val_accuracy: 0.9938\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0130 - accuracy: 0.9974 - val_loss: 0.0315 - val_accuracy: 0.9938\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0129 - accuracy: 0.9977 - val_loss: 0.0315 - val_accuracy: 0.9946\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0127 - accuracy: 0.9979 - val_loss: 0.0316 - val_accuracy: 0.9946\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0126 - accuracy: 0.9977 - val_loss: 0.0314 - val_accuracy: 0.9946\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0125 - accuracy: 0.9979 - val_loss: 0.0313 - val_accuracy: 0.9946\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0123 - accuracy: 0.9979 - val_loss: 0.0313 - val_accuracy: 0.9946\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0122 - accuracy: 0.9979 - val_loss: 0.0312 - val_accuracy: 0.9946\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0122 - accuracy: 0.9982 - val_loss: 0.0314 - val_accuracy: 0.9946\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0120 - accuracy: 0.9979 - val_loss: 0.0312 - val_accuracy: 0.9946\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0119 - accuracy: 0.9982 - val_loss: 0.0311 - val_accuracy: 0.9946\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0118 - accuracy: 0.9982 - val_loss: 0.0312 - val_accuracy: 0.9946\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0116 - accuracy: 0.9982 - val_loss: 0.0312 - val_accuracy: 0.9946\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0115 - accuracy: 0.9982 - val_loss: 0.0312 - val_accuracy: 0.9946\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0114 - accuracy: 0.9982 - val_loss: 0.0310 - val_accuracy: 0.9946\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0113 - accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.9946\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0113 - accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.9946\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0112 - accuracy: 0.9982 - val_loss: 0.0313 - val_accuracy: 0.9946\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0110 - accuracy: 0.9982 - val_loss: 0.0312 - val_accuracy: 0.9946\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0109 - accuracy: 0.9982 - val_loss: 0.0311 - val_accuracy: 0.9946\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0108 - accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.9946\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0107 - accuracy: 0.9982 - val_loss: 0.0309 - val_accuracy: 0.9946\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0106 - accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.9946\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0105 - accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.9946\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0104 - accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.9946\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0103 - accuracy: 0.9982 - val_loss: 0.0307 - val_accuracy: 0.9946\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=500, validation_data=(X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46d6fd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       980\n",
      "           1       1.00      0.99      0.99       320\n",
      "\n",
      "    accuracy                           1.00      1300\n",
      "   macro avg       1.00      0.99      1.00      1300\n",
      "weighted avg       1.00      1.00      1.00      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred = pd.DataFrame(pred)\n",
    "pred = pred[0].apply(lambda x: 1 if x> 0.5 else 0)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "820b1a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "015fd116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0599c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba0b15cd",
   "metadata": {},
   "source": [
    "# EarlyStopping으로 학습 조기 중단 및 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2a0fd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "208fc024",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203efe11",
   "metadata": {},
   "source": [
    "# ModelCheckpoint\n",
    "* 모델을 중간에 저장하는 옵션 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "329263ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /model created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./model\"):\n",
    "    os.makedirs(\"./model\")\n",
    "    print(f\"Directory /model created.\")\n",
    "else:\n",
    "    print(f\"Directory /model already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b1013c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = \"./model/{epoch:03d}--{val_loss:.4f}.keras\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=0, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "278f2f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0102 - accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.9946\n",
      "Epoch 2/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0101 - accuracy: 0.9985 - val_loss: 0.0308 - val_accuracy: 0.9946\n",
      "Epoch 3/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0101 - accuracy: 0.9985 - val_loss: 0.0305 - val_accuracy: 0.9946\n",
      "Epoch 4/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0100 - accuracy: 0.9985 - val_loss: 0.0306 - val_accuracy: 0.9946\n",
      "Epoch 5/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0099 - accuracy: 0.9985 - val_loss: 0.0309 - val_accuracy: 0.9946\n",
      "Epoch 6/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0098 - accuracy: 0.9985 - val_loss: 0.0307 - val_accuracy: 0.9946\n",
      "Epoch 7/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0097 - accuracy: 0.9985 - val_loss: 0.0308 - val_accuracy: 0.9946\n",
      "Epoch 8/1000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0096 - accuracy: 0.9985 - val_loss: 0.0305 - val_accuracy: 0.9946\n",
      "Epoch 9/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0095 - accuracy: 0.9985 - val_loss: 0.0308 - val_accuracy: 0.9946\n",
      "Epoch 10/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0094 - accuracy: 0.9985 - val_loss: 0.0307 - val_accuracy: 0.9946\n",
      "Epoch 11/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0094 - accuracy: 0.9985 - val_loss: 0.0308 - val_accuracy: 0.9946\n",
      "Epoch 12/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0093 - accuracy: 0.9985 - val_loss: 0.0306 - val_accuracy: 0.9946\n",
      "Epoch 13/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0092 - accuracy: 0.9985 - val_loss: 0.0308 - val_accuracy: 0.9946\n",
      "Epoch 14/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0091 - accuracy: 0.9985 - val_loss: 0.0307 - val_accuracy: 0.9946\n",
      "Epoch 15/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0090 - accuracy: 0.9985 - val_loss: 0.0308 - val_accuracy: 0.9946\n",
      "Epoch 16/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0090 - accuracy: 0.9985 - val_loss: 0.0310 - val_accuracy: 0.9946\n",
      "Epoch 17/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0089 - accuracy: 0.9985 - val_loss: 0.0307 - val_accuracy: 0.9946\n",
      "Epoch 18/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0088 - accuracy: 0.9985 - val_loss: 0.0308 - val_accuracy: 0.9946\n",
      "Epoch 19/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0087 - accuracy: 0.9985 - val_loss: 0.0308 - val_accuracy: 0.9946\n",
      "Epoch 20/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0086 - accuracy: 0.9985 - val_loss: 0.0309 - val_accuracy: 0.9946\n",
      "Epoch 21/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0086 - accuracy: 0.9985 - val_loss: 0.0309 - val_accuracy: 0.9946\n",
      "Epoch 22/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0085 - accuracy: 0.9985 - val_loss: 0.0307 - val_accuracy: 0.9946\n",
      "Epoch 23/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0084 - accuracy: 0.9985 - val_loss: 0.0309 - val_accuracy: 0.9946\n",
      "Epoch 24/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0083 - accuracy: 0.9985 - val_loss: 0.0309 - val_accuracy: 0.9946\n",
      "Epoch 25/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0083 - accuracy: 0.9985 - val_loss: 0.0308 - val_accuracy: 0.9946\n",
      "Epoch 26/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0082 - accuracy: 0.9985 - val_loss: 0.0309 - val_accuracy: 0.9946\n",
      "Epoch 27/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 0.0310 - val_accuracy: 0.9946\n",
      "Epoch 28/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 0.0311 - val_accuracy: 0.9946\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=1000, batch_size=500, validation_data=(X_valid,y_valid),\n",
    "                   callbacks=[early_stopping_callback, checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4982ee19",
   "metadata": {},
   "source": [
    "# 저장된 베스트 모델을 불러와서 테스트 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "925bf893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6464c3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = load_model(\"./model/008--0.0305.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4019b74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       980\n",
      "           1       1.00      0.99      0.99       320\n",
      "\n",
      "    accuracy                           1.00      1300\n",
      "   macro avg       1.00      0.99      1.00      1300\n",
      "weighted avg       1.00      1.00      1.00      1300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 11:31:52.480387: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "best_pred = best_model.predict(X_test)\n",
    "best_pred = pd.DataFrame(best_pred)\n",
    "best_pred = best_pred[0].apply(lambda x: 1 if x>0.5 else 0)\n",
    "print(classification_report(y_test,best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b0930c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d42373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a09ef8f",
   "metadata": {},
   "source": [
    "# 다중분류 와인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8e75bcc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = pd.read_csv(\"../06machine_learning/data/winequality-white.csv\", sep=\";\")\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4098af33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4898 entries, 0 to 4897\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         4898 non-null   float64\n",
      " 1   volatile acidity      4898 non-null   float64\n",
      " 2   citric acid           4898 non-null   float64\n",
      " 3   residual sugar        4898 non-null   float64\n",
      " 4   chlorides             4898 non-null   float64\n",
      " 5   free sulfur dioxide   4898 non-null   float64\n",
      " 6   total sulfur dioxide  4898 non-null   float64\n",
      " 7   density               4898 non-null   float64\n",
      " 8   pH                    4898 non-null   float64\n",
      " 9   sulphates             4898 non-null   float64\n",
      " 10  alcohol               4898 non-null   float64\n",
      " 11  quality               4898 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 459.3 KB\n"
     ]
    }
   ],
   "source": [
    "wine.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "449b3fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quality\n",
       "6    2198\n",
       "5    1457\n",
       "7     880\n",
       "8     175\n",
       "4     163\n",
       "3      20\n",
       "9       5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bdd61f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wine.drop('quality', axis=1)\n",
    "y = wine['quality'].copy()\n",
    "y2 = wine['quality'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c28c8804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6\n",
       "1    6\n",
       "2    6\n",
       "3    6\n",
       "4    6\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f0e89092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6f5edf81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2       ,  0.09090909,  0.33333333, ..., -0.94736842,\n",
       "        -0.14285714, -0.84210526],\n",
       "       [-0.5       ,  0.36363636,  0.16666667, ...,  0.63157895,\n",
       "         0.14285714, -0.47368421],\n",
       "       [ 1.3       ,  0.18181818,  0.66666667, ...,  0.42105263,\n",
       "        -0.21428571, -0.15789474],\n",
       "       ...,\n",
       "       [-0.3       , -0.18181818, -1.08333333, ..., -1.        ,\n",
       "        -0.07142857, -0.52631579],\n",
       "       [-1.3       ,  0.27272727, -0.16666667, ...,  0.84210526,\n",
       "        -0.64285714,  1.26315789],\n",
       "       [-0.8       , -0.45454545,  0.5       , ...,  0.42105263,\n",
       "        -1.07142857,  0.73684211]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbs = RobustScaler()\n",
    "X_scaled = rbs.fit_transform(X)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e804fe02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          3      4      5      6      7      8      9\n",
       "0     False  False  False   True  False  False  False\n",
       "1     False  False  False   True  False  False  False\n",
       "2     False  False  False   True  False  False  False\n",
       "3     False  False  False   True  False  False  False\n",
       "4     False  False  False   True  False  False  False\n",
       "...     ...    ...    ...    ...    ...    ...    ...\n",
       "4893  False  False  False   True  False  False  False\n",
       "4894  False  False   True  False  False  False  False\n",
       "4895  False  False  False   True  False  False  False\n",
       "4896  False  False  False  False   True  False  False\n",
       "4897  False  False  False   True  False  False  False\n",
       "\n",
       "[4898 rows x 7 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fbfc9165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "60dce253",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_scaled, y ,test_size=0.4 , stratify=y,random_state=10)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.5,stratify=y_valid, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0e0ed639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4654cf9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 32)                384       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,223\n",
      "Trainable params: 5,223\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d9c9e3c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "1/6 [====>.........................] - ETA: 2s - loss: 2.0112 - accuracy: 0.0940"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 14:21:51.031377: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-10 14:21:51.088249: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 14:21:51.088311: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 56ms/step - loss: 1.9776 - accuracy: 0.1304 - val_loss: 1.9364 - val_accuracy: 0.1867\n",
      "Epoch 2/10000\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.9185 - accuracy: 0.2127"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 14:21:51.328778: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-10 14:21:51.356697: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 14:21:51.356762: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 34ms/step - loss: 1.9185 - accuracy: 0.2127 - val_loss: 1.8962 - val_accuracy: 0.2286\n",
      "Epoch 3/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.8760 - accuracy: 0.2594 - val_loss: 1.8539 - val_accuracy: 0.2245\n",
      "Epoch 4/10000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 1.8235 - accuracy: 0.2914 - val_loss: 1.7942 - val_accuracy: 0.2857\n",
      "Epoch 5/10000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 1.7478 - accuracy: 0.3468 - val_loss: 1.7022 - val_accuracy: 0.3847\n",
      "Epoch 6/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.6332 - accuracy: 0.4551 - val_loss: 1.5697 - val_accuracy: 0.4643\n",
      "Epoch 7/10000\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 1.4992 - accuracy: 0.4942 - val_loss: 1.4557 - val_accuracy: 0.4816\n",
      "Epoch 8/10000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 1.3952 - accuracy: 0.5000 - val_loss: 1.3875 - val_accuracy: 0.4786\n",
      "Epoch 9/10000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 1.3367 - accuracy: 0.5092 - val_loss: 1.3480 - val_accuracy: 0.4847\n",
      "Epoch 10/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.2976 - accuracy: 0.5088 - val_loss: 1.3155 - val_accuracy: 0.4857\n",
      "Epoch 11/10000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 1.2680 - accuracy: 0.5133 - val_loss: 1.2940 - val_accuracy: 0.4908\n",
      "Epoch 12/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.2471 - accuracy: 0.5204 - val_loss: 1.2789 - val_accuracy: 0.4929\n",
      "Epoch 13/10000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 1.2293 - accuracy: 0.5255 - val_loss: 1.2646 - val_accuracy: 0.5173\n",
      "Epoch 14/10000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 1.2127 - accuracy: 0.5317 - val_loss: 1.2524 - val_accuracy: 0.5153\n",
      "Epoch 15/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.1985 - accuracy: 0.5354 - val_loss: 1.2408 - val_accuracy: 0.5092\n",
      "Epoch 16/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.1862 - accuracy: 0.5361 - val_loss: 1.2284 - val_accuracy: 0.5204\n",
      "Epoch 17/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.1726 - accuracy: 0.5412 - val_loss: 1.2179 - val_accuracy: 0.5204\n",
      "Epoch 18/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.1607 - accuracy: 0.5477 - val_loss: 1.2070 - val_accuracy: 0.5276\n",
      "Epoch 19/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.1501 - accuracy: 0.5436 - val_loss: 1.1988 - val_accuracy: 0.5204\n",
      "Epoch 20/10000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 1.1393 - accuracy: 0.5517 - val_loss: 1.1887 - val_accuracy: 0.5286\n",
      "Epoch 21/10000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 1.1292 - accuracy: 0.5528 - val_loss: 1.1802 - val_accuracy: 0.5255\n",
      "Epoch 22/10000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 1.1192 - accuracy: 0.5568 - val_loss: 1.1711 - val_accuracy: 0.5276\n",
      "Epoch 23/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.1106 - accuracy: 0.5568 - val_loss: 1.1632 - val_accuracy: 0.5316\n",
      "Epoch 24/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.1029 - accuracy: 0.5558 - val_loss: 1.1553 - val_accuracy: 0.5367\n",
      "Epoch 25/10000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 1.0936 - accuracy: 0.5589 - val_loss: 1.1504 - val_accuracy: 0.5418\n",
      "Epoch 26/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.0869 - accuracy: 0.5562 - val_loss: 1.1422 - val_accuracy: 0.5347\n",
      "Epoch 27/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.0788 - accuracy: 0.5626 - val_loss: 1.1342 - val_accuracy: 0.5449\n",
      "Epoch 28/10000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.0706 - accuracy: 0.5660 - val_loss: 1.1278 - val_accuracy: 0.5378\n",
      "Epoch 29/10000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 1.0648 - accuracy: 0.5602 - val_loss: 1.1208 - val_accuracy: 0.5439\n",
      "Epoch 30/10000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 1.0590 - accuracy: 0.5718 - val_loss: 1.1156 - val_accuracy: 0.5510\n",
      "Epoch 31/10000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 1.0518 - accuracy: 0.5684 - val_loss: 1.1125 - val_accuracy: 0.5418\n",
      "Epoch 32/10000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 1.0454 - accuracy: 0.5684 - val_loss: 1.1053 - val_accuracy: 0.5459\n",
      "Epoch 33/10000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 1.0390 - accuracy: 0.5779 - val_loss: 1.1010 - val_accuracy: 0.5429\n",
      "Epoch 34/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.0358 - accuracy: 0.5718 - val_loss: 1.0944 - val_accuracy: 0.5459\n",
      "Epoch 35/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.0293 - accuracy: 0.5776 - val_loss: 1.0917 - val_accuracy: 0.5490\n",
      "Epoch 36/10000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 1.0239 - accuracy: 0.5742 - val_loss: 1.0888 - val_accuracy: 0.5469\n",
      "Epoch 37/10000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 1.0193 - accuracy: 0.5800 - val_loss: 1.0845 - val_accuracy: 0.5531\n",
      "Epoch 38/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.0156 - accuracy: 0.5786 - val_loss: 1.0805 - val_accuracy: 0.5571\n",
      "Epoch 39/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.0134 - accuracy: 0.5813 - val_loss: 1.0778 - val_accuracy: 0.5500\n",
      "Epoch 40/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.0081 - accuracy: 0.5841 - val_loss: 1.0756 - val_accuracy: 0.5541\n",
      "Epoch 41/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.0032 - accuracy: 0.5817 - val_loss: 1.0739 - val_accuracy: 0.5541\n",
      "Epoch 42/10000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.9982 - accuracy: 0.5892 - val_loss: 1.0716 - val_accuracy: 0.5541\n",
      "Epoch 43/10000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.9960 - accuracy: 0.5916 - val_loss: 1.0691 - val_accuracy: 0.5541\n",
      "Epoch 44/10000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.9906 - accuracy: 0.5977 - val_loss: 1.0677 - val_accuracy: 0.5612\n",
      "Epoch 45/10000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.9868 - accuracy: 0.6001 - val_loss: 1.0658 - val_accuracy: 0.5622\n",
      "Epoch 46/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.9826 - accuracy: 0.6021 - val_loss: 1.0648 - val_accuracy: 0.5571\n",
      "Epoch 47/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.9787 - accuracy: 0.5994 - val_loss: 1.0631 - val_accuracy: 0.5673\n",
      "Epoch 48/10000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.9749 - accuracy: 0.6007 - val_loss: 1.0610 - val_accuracy: 0.5571\n",
      "Epoch 49/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.9717 - accuracy: 0.6038 - val_loss: 1.0587 - val_accuracy: 0.5633\n",
      "Epoch 50/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.9685 - accuracy: 0.6035 - val_loss: 1.0595 - val_accuracy: 0.5592\n",
      "Epoch 51/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.9642 - accuracy: 0.6038 - val_loss: 1.0574 - val_accuracy: 0.5612\n",
      "Epoch 52/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.9603 - accuracy: 0.6048 - val_loss: 1.0559 - val_accuracy: 0.5592\n",
      "Epoch 53/10000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.9568 - accuracy: 0.6076 - val_loss: 1.0550 - val_accuracy: 0.5633\n",
      "Epoch 54/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.9540 - accuracy: 0.6113 - val_loss: 1.0545 - val_accuracy: 0.5612\n",
      "Epoch 55/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.9508 - accuracy: 0.6093 - val_loss: 1.0523 - val_accuracy: 0.5612\n",
      "Epoch 56/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.9461 - accuracy: 0.6137 - val_loss: 1.0515 - val_accuracy: 0.5622\n",
      "Epoch 57/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.9431 - accuracy: 0.6147 - val_loss: 1.0517 - val_accuracy: 0.5582\n",
      "Epoch 58/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.9406 - accuracy: 0.6127 - val_loss: 1.0494 - val_accuracy: 0.5612\n",
      "Epoch 59/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 33ms/step - loss: 0.9383 - accuracy: 0.6188 - val_loss: 1.0482 - val_accuracy: 0.5571\n",
      "Epoch 60/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.9379 - accuracy: 0.6198 - val_loss: 1.0482 - val_accuracy: 0.5602\n",
      "Epoch 61/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.9358 - accuracy: 0.6133 - val_loss: 1.0532 - val_accuracy: 0.5531\n",
      "Epoch 62/10000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.9320 - accuracy: 0.6195 - val_loss: 1.0469 - val_accuracy: 0.5602\n",
      "Epoch 63/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.9256 - accuracy: 0.6201 - val_loss: 1.0477 - val_accuracy: 0.5520\n",
      "Epoch 64/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.9262 - accuracy: 0.6259 - val_loss: 1.0446 - val_accuracy: 0.5541\n",
      "Epoch 65/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.9189 - accuracy: 0.6195 - val_loss: 1.0467 - val_accuracy: 0.5520\n",
      "Epoch 66/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.9156 - accuracy: 0.6256 - val_loss: 1.0393 - val_accuracy: 0.5541\n",
      "Epoch 67/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.9139 - accuracy: 0.6246 - val_loss: 1.0408 - val_accuracy: 0.5561\n",
      "Epoch 68/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.9097 - accuracy: 0.6263 - val_loss: 1.0398 - val_accuracy: 0.5541\n",
      "Epoch 69/10000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.9059 - accuracy: 0.6324 - val_loss: 1.0423 - val_accuracy: 0.5541\n",
      "Epoch 70/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.9028 - accuracy: 0.6351 - val_loss: 1.0371 - val_accuracy: 0.5541\n",
      "Epoch 71/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8986 - accuracy: 0.6378 - val_loss: 1.0382 - val_accuracy: 0.5520\n",
      "Epoch 72/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8961 - accuracy: 0.6355 - val_loss: 1.0396 - val_accuracy: 0.5531\n",
      "Epoch 73/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8927 - accuracy: 0.6382 - val_loss: 1.0401 - val_accuracy: 0.5531\n",
      "Epoch 74/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8900 - accuracy: 0.6368 - val_loss: 1.0379 - val_accuracy: 0.5520\n",
      "Epoch 75/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8866 - accuracy: 0.6433 - val_loss: 1.0374 - val_accuracy: 0.5531\n",
      "Epoch 76/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8840 - accuracy: 0.6413 - val_loss: 1.0409 - val_accuracy: 0.5469\n",
      "Epoch 77/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8817 - accuracy: 0.6450 - val_loss: 1.0398 - val_accuracy: 0.5551\n",
      "Epoch 78/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8794 - accuracy: 0.6457 - val_loss: 1.0426 - val_accuracy: 0.5541\n",
      "Epoch 79/10000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.8768 - accuracy: 0.6477 - val_loss: 1.0358 - val_accuracy: 0.5510\n",
      "Epoch 80/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8761 - accuracy: 0.6443 - val_loss: 1.0394 - val_accuracy: 0.5531\n",
      "Epoch 81/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8709 - accuracy: 0.6457 - val_loss: 1.0369 - val_accuracy: 0.5480\n",
      "Epoch 82/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8705 - accuracy: 0.6487 - val_loss: 1.0378 - val_accuracy: 0.5500\n",
      "Epoch 83/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8674 - accuracy: 0.6521 - val_loss: 1.0388 - val_accuracy: 0.5541\n",
      "Epoch 84/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8672 - accuracy: 0.6430 - val_loss: 1.0375 - val_accuracy: 0.5520\n",
      "Epoch 85/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8656 - accuracy: 0.6430 - val_loss: 1.0467 - val_accuracy: 0.5500\n",
      "Epoch 86/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8595 - accuracy: 0.6555 - val_loss: 1.0362 - val_accuracy: 0.5531\n",
      "Epoch 87/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8559 - accuracy: 0.6613 - val_loss: 1.0387 - val_accuracy: 0.5592\n",
      "Epoch 88/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.8531 - accuracy: 0.6590 - val_loss: 1.0355 - val_accuracy: 0.5592\n",
      "Epoch 89/10000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.8515 - accuracy: 0.6600 - val_loss: 1.0381 - val_accuracy: 0.5500\n",
      "Epoch 90/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8486 - accuracy: 0.6617 - val_loss: 1.0444 - val_accuracy: 0.5541\n",
      "Epoch 91/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8485 - accuracy: 0.6600 - val_loss: 1.0411 - val_accuracy: 0.5541\n",
      "Epoch 92/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8441 - accuracy: 0.6637 - val_loss: 1.0385 - val_accuracy: 0.5520\n",
      "Epoch 93/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8414 - accuracy: 0.6607 - val_loss: 1.0364 - val_accuracy: 0.5571\n",
      "Epoch 94/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8386 - accuracy: 0.6647 - val_loss: 1.0375 - val_accuracy: 0.5531\n",
      "Epoch 95/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8378 - accuracy: 0.6634 - val_loss: 1.0443 - val_accuracy: 0.5520\n",
      "Epoch 96/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8353 - accuracy: 0.6651 - val_loss: 1.0432 - val_accuracy: 0.5612\n",
      "Epoch 97/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8322 - accuracy: 0.6685 - val_loss: 1.0419 - val_accuracy: 0.5520\n",
      "Epoch 98/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.8293 - accuracy: 0.6692 - val_loss: 1.0440 - val_accuracy: 0.5592\n",
      "Epoch 99/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8262 - accuracy: 0.6692 - val_loss: 1.0427 - val_accuracy: 0.5541\n",
      "Epoch 100/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.8248 - accuracy: 0.6712 - val_loss: 1.0441 - val_accuracy: 0.5531\n",
      "Epoch 101/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8254 - accuracy: 0.6719 - val_loss: 1.0439 - val_accuracy: 0.5561\n",
      "Epoch 102/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.8243 - accuracy: 0.6702 - val_loss: 1.0493 - val_accuracy: 0.5561\n",
      "Epoch 103/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8171 - accuracy: 0.6692 - val_loss: 1.0406 - val_accuracy: 0.5612\n",
      "Epoch 104/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8133 - accuracy: 0.6807 - val_loss: 1.0462 - val_accuracy: 0.5520\n",
      "Epoch 105/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8113 - accuracy: 0.6753 - val_loss: 1.0456 - val_accuracy: 0.5561\n",
      "Epoch 106/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8097 - accuracy: 0.6784 - val_loss: 1.0465 - val_accuracy: 0.5571\n",
      "Epoch 107/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8057 - accuracy: 0.6784 - val_loss: 1.0454 - val_accuracy: 0.5551\n",
      "Epoch 108/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8044 - accuracy: 0.6804 - val_loss: 1.0469 - val_accuracy: 0.5653\n",
      "Epoch 109/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8037 - accuracy: 0.6784 - val_loss: 1.0512 - val_accuracy: 0.5582\n",
      "Epoch 110/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8010 - accuracy: 0.6814 - val_loss: 1.0512 - val_accuracy: 0.5612\n",
      "Epoch 111/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8004 - accuracy: 0.6845 - val_loss: 1.0482 - val_accuracy: 0.5612\n",
      "Epoch 112/10000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.7974 - accuracy: 0.6865 - val_loss: 1.0518 - val_accuracy: 0.5602\n",
      "Epoch 113/10000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.7919 - accuracy: 0.6852 - val_loss: 1.0489 - val_accuracy: 0.5571\n",
      "Epoch 114/10000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7904 - accuracy: 0.6879 - val_loss: 1.0546 - val_accuracy: 0.5633\n",
      "Epoch 115/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7884 - accuracy: 0.6903 - val_loss: 1.0486 - val_accuracy: 0.5592\n",
      "Epoch 116/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7860 - accuracy: 0.6865 - val_loss: 1.0484 - val_accuracy: 0.5592\n",
      "Epoch 117/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7855 - accuracy: 0.6886 - val_loss: 1.0571 - val_accuracy: 0.5633\n",
      "Epoch 118/10000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.7852 - accuracy: 0.6886 - val_loss: 1.0560 - val_accuracy: 0.5622\n",
      "Epoch 119/10000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7815 - accuracy: 0.6882 - val_loss: 1.0589 - val_accuracy: 0.5622\n",
      "Epoch 120/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.7783 - accuracy: 0.6903 - val_loss: 1.0555 - val_accuracy: 0.5551\n",
      "Epoch 121/10000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.7752 - accuracy: 0.6916 - val_loss: 1.0575 - val_accuracy: 0.5653\n",
      "Epoch 122/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7717 - accuracy: 0.7001 - val_loss: 1.0635 - val_accuracy: 0.5612\n",
      "Epoch 123/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7709 - accuracy: 0.6964 - val_loss: 1.0546 - val_accuracy: 0.5684\n",
      "Epoch 124/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7689 - accuracy: 0.6947 - val_loss: 1.0601 - val_accuracy: 0.5622\n",
      "Epoch 125/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.7678 - accuracy: 0.7032 - val_loss: 1.0624 - val_accuracy: 0.5684\n",
      "Epoch 126/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.7670 - accuracy: 0.6950 - val_loss: 1.0729 - val_accuracy: 0.5541\n",
      "Epoch 127/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7664 - accuracy: 0.6923 - val_loss: 1.0581 - val_accuracy: 0.5694\n",
      "Epoch 128/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7637 - accuracy: 0.7001 - val_loss: 1.0715 - val_accuracy: 0.5755\n",
      "Epoch 129/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7672 - accuracy: 0.6978 - val_loss: 1.0789 - val_accuracy: 0.5541\n",
      "Epoch 130/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.7613 - accuracy: 0.6981 - val_loss: 1.0755 - val_accuracy: 0.5714\n",
      "Epoch 131/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7584 - accuracy: 0.7052 - val_loss: 1.0666 - val_accuracy: 0.5704\n",
      "Epoch 132/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7520 - accuracy: 0.7080 - val_loss: 1.0800 - val_accuracy: 0.5653\n",
      "Epoch 133/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7507 - accuracy: 0.7039 - val_loss: 1.0668 - val_accuracy: 0.5714\n",
      "Epoch 134/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7498 - accuracy: 0.7049 - val_loss: 1.0839 - val_accuracy: 0.5694\n",
      "Epoch 135/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7493 - accuracy: 0.7086 - val_loss: 1.0728 - val_accuracy: 0.5643\n",
      "Epoch 136/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7456 - accuracy: 0.7076 - val_loss: 1.0716 - val_accuracy: 0.5735\n",
      "Epoch 137/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7411 - accuracy: 0.7107 - val_loss: 1.0696 - val_accuracy: 0.5704\n",
      "Epoch 138/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.7443 - accuracy: 0.7120 - val_loss: 1.0765 - val_accuracy: 0.5673\n",
      "Epoch 139/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.7407 - accuracy: 0.7052 - val_loss: 1.0862 - val_accuracy: 0.5622\n",
      "Epoch 140/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7367 - accuracy: 0.7168 - val_loss: 1.0716 - val_accuracy: 0.5694\n",
      "Epoch 141/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7338 - accuracy: 0.7134 - val_loss: 1.0790 - val_accuracy: 0.5745\n",
      "Epoch 142/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7343 - accuracy: 0.7155 - val_loss: 1.0868 - val_accuracy: 0.5663\n",
      "Epoch 143/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.7290 - accuracy: 0.7199 - val_loss: 1.0799 - val_accuracy: 0.5673\n",
      "Epoch 144/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7290 - accuracy: 0.7124 - val_loss: 1.0875 - val_accuracy: 0.5755\n",
      "Epoch 145/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7282 - accuracy: 0.7131 - val_loss: 1.0796 - val_accuracy: 0.5684\n",
      "Epoch 146/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.7268 - accuracy: 0.7175 - val_loss: 1.0840 - val_accuracy: 0.5663\n",
      "Epoch 147/10000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7223 - accuracy: 0.7206 - val_loss: 1.0893 - val_accuracy: 0.5704\n",
      "Epoch 148/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.7202 - accuracy: 0.7229 - val_loss: 1.0819 - val_accuracy: 0.5714\n",
      "Epoch 149/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7172 - accuracy: 0.7240 - val_loss: 1.0901 - val_accuracy: 0.5724\n",
      "Epoch 150/10000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.7193 - accuracy: 0.7161 - val_loss: 1.0962 - val_accuracy: 0.5653\n",
      "Epoch 151/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7172 - accuracy: 0.7212 - val_loss: 1.0960 - val_accuracy: 0.5653\n",
      "Epoch 152/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7158 - accuracy: 0.7243 - val_loss: 1.0982 - val_accuracy: 0.5786\n",
      "Epoch 153/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.7152 - accuracy: 0.7243 - val_loss: 1.0900 - val_accuracy: 0.5622\n",
      "Epoch 154/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7104 - accuracy: 0.7240 - val_loss: 1.1034 - val_accuracy: 0.5745\n",
      "Epoch 155/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7072 - accuracy: 0.7270 - val_loss: 1.0925 - val_accuracy: 0.5684\n",
      "Epoch 156/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7044 - accuracy: 0.7291 - val_loss: 1.1040 - val_accuracy: 0.5653\n",
      "Epoch 157/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7031 - accuracy: 0.7308 - val_loss: 1.1029 - val_accuracy: 0.5673\n",
      "Epoch 158/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6997 - accuracy: 0.7311 - val_loss: 1.1002 - val_accuracy: 0.5684\n",
      "Epoch 159/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6999 - accuracy: 0.7311 - val_loss: 1.1004 - val_accuracy: 0.5684\n",
      "Epoch 160/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6962 - accuracy: 0.7352 - val_loss: 1.1102 - val_accuracy: 0.5663\n",
      "Epoch 161/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6949 - accuracy: 0.7369 - val_loss: 1.1038 - val_accuracy: 0.5663\n",
      "Epoch 162/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6940 - accuracy: 0.7301 - val_loss: 1.1212 - val_accuracy: 0.5684\n",
      "Epoch 163/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6942 - accuracy: 0.7349 - val_loss: 1.1089 - val_accuracy: 0.5643\n",
      "Epoch 164/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6923 - accuracy: 0.7308 - val_loss: 1.1195 - val_accuracy: 0.5673\n",
      "Epoch 165/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.6909 - accuracy: 0.7335 - val_loss: 1.1095 - val_accuracy: 0.5663\n",
      "Epoch 166/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6860 - accuracy: 0.7430 - val_loss: 1.1144 - val_accuracy: 0.5673\n",
      "Epoch 167/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6869 - accuracy: 0.7362 - val_loss: 1.1166 - val_accuracy: 0.5694\n",
      "Epoch 168/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6818 - accuracy: 0.7413 - val_loss: 1.1163 - val_accuracy: 0.5735\n",
      "Epoch 169/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6818 - accuracy: 0.7427 - val_loss: 1.1185 - val_accuracy: 0.5704\n",
      "Epoch 170/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6777 - accuracy: 0.7417 - val_loss: 1.1182 - val_accuracy: 0.5704\n",
      "Epoch 171/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6791 - accuracy: 0.7423 - val_loss: 1.1222 - val_accuracy: 0.5653\n",
      "Epoch 172/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6756 - accuracy: 0.7447 - val_loss: 1.1458 - val_accuracy: 0.5531\n",
      "Epoch 173/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6811 - accuracy: 0.7369 - val_loss: 1.1328 - val_accuracy: 0.5724\n",
      "Epoch 174/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6723 - accuracy: 0.7485 - val_loss: 1.1204 - val_accuracy: 0.5643\n",
      "Epoch 175/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6689 - accuracy: 0.7488 - val_loss: 1.1302 - val_accuracy: 0.5745\n",
      "Epoch 176/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6679 - accuracy: 0.7491 - val_loss: 1.1484 - val_accuracy: 0.5714\n",
      "Epoch 177/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6685 - accuracy: 0.7509 - val_loss: 1.1336 - val_accuracy: 0.5704\n",
      "Epoch 178/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6662 - accuracy: 0.7440 - val_loss: 1.1351 - val_accuracy: 0.5673\n",
      "Epoch 179/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6629 - accuracy: 0.7515 - val_loss: 1.1296 - val_accuracy: 0.5684\n",
      "Epoch 180/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6593 - accuracy: 0.7515 - val_loss: 1.1437 - val_accuracy: 0.5694\n",
      "Epoch 181/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6561 - accuracy: 0.7539 - val_loss: 1.1375 - val_accuracy: 0.5714\n",
      "Epoch 182/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6562 - accuracy: 0.7536 - val_loss: 1.1342 - val_accuracy: 0.5684\n",
      "Epoch 183/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6563 - accuracy: 0.7515 - val_loss: 1.1425 - val_accuracy: 0.5714\n",
      "Epoch 184/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6561 - accuracy: 0.7553 - val_loss: 1.1446 - val_accuracy: 0.5724\n",
      "Epoch 185/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6533 - accuracy: 0.7560 - val_loss: 1.1418 - val_accuracy: 0.5694\n",
      "Epoch 186/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6533 - accuracy: 0.7491 - val_loss: 1.1551 - val_accuracy: 0.5704\n",
      "Epoch 187/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6521 - accuracy: 0.7539 - val_loss: 1.1514 - val_accuracy: 0.5694\n",
      "Epoch 188/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6474 - accuracy: 0.7628 - val_loss: 1.1426 - val_accuracy: 0.5571\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "early_stop = EarlyStopping(patience=100)\n",
    "filepath=\"/model/white_wine{epoch:04d}__{val_loss:.4f}.keras\"\n",
    "model_save = ModelCheckpoint(filepath=filepath, save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10000, batch_size=500, validation_data=(X_valid,y_valid), \n",
    "                    callbacks=[early_stop,model_save])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "840c30bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 14:30:06.908372: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "wine_best_model = load_model(\"./model/white_wine0088__1.0355.keras\")\n",
    "wine_pred = wine_best_model.predict(X_test)\n",
    "wine_pred = pd.DataFrame(wine_pred,columns=y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6471b6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004084</td>\n",
       "      <td>0.008073</td>\n",
       "      <td>0.098135</td>\n",
       "      <td>0.768133</td>\n",
       "      <td>0.114346</td>\n",
       "      <td>0.006879</td>\n",
       "      <td>0.000351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005688</td>\n",
       "      <td>0.006195</td>\n",
       "      <td>0.036908</td>\n",
       "      <td>0.650371</td>\n",
       "      <td>0.241850</td>\n",
       "      <td>0.057538</td>\n",
       "      <td>0.001449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004882</td>\n",
       "      <td>0.046232</td>\n",
       "      <td>0.316800</td>\n",
       "      <td>0.583672</td>\n",
       "      <td>0.043409</td>\n",
       "      <td>0.004383</td>\n",
       "      <td>0.000622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.009459</td>\n",
       "      <td>0.120742</td>\n",
       "      <td>0.602630</td>\n",
       "      <td>0.257367</td>\n",
       "      <td>0.008471</td>\n",
       "      <td>0.000245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001173</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.099251</td>\n",
       "      <td>0.722725</td>\n",
       "      <td>0.154535</td>\n",
       "      <td>0.019342</td>\n",
       "      <td>0.000401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>0.013026</td>\n",
       "      <td>0.107886</td>\n",
       "      <td>0.431916</td>\n",
       "      <td>0.387267</td>\n",
       "      <td>0.033966</td>\n",
       "      <td>0.022703</td>\n",
       "      <td>0.003237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>0.003376</td>\n",
       "      <td>0.738663</td>\n",
       "      <td>0.239338</td>\n",
       "      <td>0.016705</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>0.007724</td>\n",
       "      <td>0.017328</td>\n",
       "      <td>0.276579</td>\n",
       "      <td>0.608933</td>\n",
       "      <td>0.081704</td>\n",
       "      <td>0.007083</td>\n",
       "      <td>0.000649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>0.007076</td>\n",
       "      <td>0.039315</td>\n",
       "      <td>0.378750</td>\n",
       "      <td>0.525649</td>\n",
       "      <td>0.039306</td>\n",
       "      <td>0.008688</td>\n",
       "      <td>0.001217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>0.004965</td>\n",
       "      <td>0.018305</td>\n",
       "      <td>0.379414</td>\n",
       "      <td>0.517208</td>\n",
       "      <td>0.073082</td>\n",
       "      <td>0.006027</td>\n",
       "      <td>0.000999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>980 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6\n",
       "0    0.004084  0.008073  0.098135  0.768133  0.114346  0.006879  0.000351\n",
       "1    0.005688  0.006195  0.036908  0.650371  0.241850  0.057538  0.001449\n",
       "2    0.004882  0.046232  0.316800  0.583672  0.043409  0.004383  0.000622\n",
       "3    0.001086  0.009459  0.120742  0.602630  0.257367  0.008471  0.000245\n",
       "4    0.001173  0.002574  0.099251  0.722725  0.154535  0.019342  0.000401\n",
       "..        ...       ...       ...       ...       ...       ...       ...\n",
       "975  0.013026  0.107886  0.431916  0.387267  0.033966  0.022703  0.003237\n",
       "976  0.003376  0.738663  0.239338  0.016705  0.001549  0.000226  0.000143\n",
       "977  0.007724  0.017328  0.276579  0.608933  0.081704  0.007083  0.000649\n",
       "978  0.007076  0.039315  0.378750  0.525649  0.039306  0.008688  0.001217\n",
       "979  0.004965  0.018305  0.379414  0.517208  0.073082  0.006027  0.000999\n",
       "\n",
       "[980 rows x 7 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b7a132ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      6\n",
       "1      6\n",
       "2      6\n",
       "3      6\n",
       "4      6\n",
       "      ..\n",
       "975    5\n",
       "976    4\n",
       "977    6\n",
       "978    6\n",
       "979    6\n",
       "Length: 980, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_pred_class=wine_pred.idxmax(axis=1)\n",
    "wine_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9b572428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          3      4      5      6      7      8      9\n",
       "0     False  False  False   True  False  False  False\n",
       "1     False  False  False   True  False  False  False\n",
       "2     False  False  False   True  False  False  False\n",
       "3     False  False  False   True  False  False  False\n",
       "4     False  False  False   True  False  False  False\n",
       "...     ...    ...    ...    ...    ...    ...    ...\n",
       "4893  False  False  False   True  False  False  False\n",
       "4894  False  False   True  False  False  False  False\n",
       "4895  False  False  False   True  False  False  False\n",
       "4896  False  False  False  False   True  False  False\n",
       "4897  False  False  False   True  False  False  False\n",
       "\n",
       "[4898 rows x 7 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "45176402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      6\n",
       "1      6\n",
       "2      7\n",
       "3      7\n",
       "4      5\n",
       "      ..\n",
       "975    6\n",
       "976    4\n",
       "977    5\n",
       "978    6\n",
       "979    6\n",
       "Length: 980, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_class = y_test.idxmax(axis=1)\n",
    "y_test_class=y_test_class.reset_index(drop=True)\n",
    "y_test_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0b765645",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.58      0.21      0.31        33\n",
      "           5       0.60      0.58      0.59       291\n",
      "           6       0.56      0.74      0.64       440\n",
      "           7       0.54      0.32      0.40       176\n",
      "           8       0.00      0.00      0.00        35\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.57       980\n",
      "   macro avg       0.33      0.26      0.28       980\n",
      "weighted avg       0.55      0.57      0.54       980\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_class, wine_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b72dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db6bc535",
   "metadata": {},
   "source": [
    "XGB로 비교분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "067ae924",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "13ecb9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 3, 4, 3])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "y2_labeled = le.fit_transform(y2)\n",
    "y2_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e4cf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "13caf2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_valid2, y_train2, y_valid2 = train_test_split(X_scaled, y2_labeled ,test_size=0.4 , stratify=y2_labeled,random_state=10)\n",
    "X_valid2, X_test2, y_valid2, y_test2 = train_test_split(X_valid2, y_valid2, test_size=0.5,stratify=y_valid2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0fc7d14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Using cached xgboost-2.1.1-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /home/user/miniforge3/envs/dml/lib/python3.9/site-packages (from xgboost) (1.26.4)\n",
      "Collecting nvidia-nccl-cu12 (from xgboost)\n",
      "  Using cached nvidia_nccl_cu12-2.22.3-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: scipy in /home/user/miniforge3/envs/dml/lib/python3.9/site-packages (from xgboost) (1.13.1)\n",
      "Using cached xgboost-2.1.1-py3-none-manylinux_2_28_x86_64.whl (153.9 MB)\n",
      "Using cached nvidia_nccl_cu12-2.22.3-py3-none-manylinux2014_x86_64.whl (190.9 MB)\n",
      "Installing collected packages: nvidia-nccl-cu12, xgboost\n",
      "Successfully installed nvidia-nccl-cu12-2.22.3 xgboost-2.1.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "af6bc97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b5100731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.48      0.33      0.39        33\n",
      "           2       0.64      0.61      0.62       291\n",
      "           3       0.64      0.70      0.67       440\n",
      "           4       0.59      0.60      0.59       176\n",
      "           5       0.60      0.34      0.44        35\n",
      "           6       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.62       980\n",
      "   macro avg       0.42      0.37      0.39       980\n",
      "weighted avg       0.62      0.62      0.62       980\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "xgb=XGBClassifier(max_depth=5, n_estimators = 1000, random_state = 10, n_jobs=-1)\n",
    "xgb.fit(X_train2, y_train2)\n",
    "xgb_pred=xgb.predict(X_valid2)\n",
    "print(classification_report(y_valid2, xgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11800087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfb36e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad74c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585e8ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8b2afe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b08a73d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2788b2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d4ab09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f8e597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
