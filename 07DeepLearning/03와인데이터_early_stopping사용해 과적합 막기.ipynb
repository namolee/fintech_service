{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eae9f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9737aa0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2    3      4     5      6        7     8     9     10  \\\n",
       "0      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
       "1      7.8  0.88  0.00  2.6  0.098  25.0   67.0  0.99680  3.20  0.68   9.8   \n",
       "2      7.8  0.76  0.04  2.3  0.092  15.0   54.0  0.99700  3.26  0.65   9.8   \n",
       "3     11.2  0.28  0.56  1.9  0.075  17.0   60.0  0.99800  3.16  0.58   9.8   \n",
       "4      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
       "...    ...   ...   ...  ...    ...   ...    ...      ...   ...   ...   ...   \n",
       "6492   6.2  0.21  0.29  1.6  0.039  24.0   92.0  0.99114  3.27  0.50  11.2   \n",
       "6493   6.6  0.32  0.36  8.0  0.047  57.0  168.0  0.99490  3.15  0.46   9.6   \n",
       "6494   6.5  0.24  0.19  1.2  0.041  30.0  111.0  0.99254  2.99  0.46   9.4   \n",
       "6495   5.5  0.29  0.30  1.1  0.022  20.0  110.0  0.98869  3.34  0.38  12.8   \n",
       "6496   6.0  0.21  0.38  0.8  0.020  22.0   98.0  0.98941  3.26  0.32  11.8   \n",
       "\n",
       "      11  12  \n",
       "0      5   1  \n",
       "1      5   1  \n",
       "2      5   1  \n",
       "3      6   1  \n",
       "4      5   1  \n",
       "...   ..  ..  \n",
       "6492   6   0  \n",
       "6493   5   0  \n",
       "6494   6   0  \n",
       "6495   7   0  \n",
       "6496   6   0  \n",
       "\n",
       "[6497 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/haram4th/ADsP/main/wine.csv\", header=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47b8b0e",
   "metadata": {},
   "source": [
    "1. Alcohol\n",
    "2. Malic acid\n",
    "3. Ash\n",
    "4. Alcalinity of ash\n",
    "5. Magnesium\n",
    "6. Total phenols\n",
    "7. Flavanoids\n",
    "8. Nonflavanoid phenols\n",
    "9. Proanthocyanins\n",
    "10.Color intensity\n",
    "11.Hue\n",
    "12.OD280/OD315 of diluted wines\n",
    "13.Proline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7259c64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6497 entries, 0 to 6496\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       6497 non-null   float64\n",
      " 1   1       6497 non-null   float64\n",
      " 2   2       6497 non-null   float64\n",
      " 3   3       6497 non-null   float64\n",
      " 4   4       6497 non-null   float64\n",
      " 5   5       6497 non-null   float64\n",
      " 6   6       6497 non-null   float64\n",
      " 7   7       6497 non-null   float64\n",
      " 8   8       6497 non-null   float64\n",
      " 9   9       6497 non-null   float64\n",
      " 10  10      6497 non-null   float64\n",
      " 11  11      6497 non-null   int64  \n",
      " 12  12      6497 non-null   int64  \n",
      "dtypes: float64(11), int64(2)\n",
      "memory usage: 660.0 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aac85a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data.iloc[:,0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499a3ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ccfc83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12\n",
       "0    4898\n",
       "1    1599\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[12].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61640759",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(12, axis=1)\n",
    "y = data[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1412e6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4b1056f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.30769231,  2.41176471, -2.21428571, ...,  0.29411765,\n",
       "        -0.5       , -1.        ],\n",
       "       [ 0.61538462,  3.47058824, -2.21428571, ...,  1.        ,\n",
       "        -0.27777778, -1.        ],\n",
       "       [ 0.61538462,  2.76470588, -1.92857143, ...,  0.82352941,\n",
       "        -0.27777778, -1.        ],\n",
       "       ...,\n",
       "       [-0.38461538, -0.29411765, -0.85714286, ..., -0.29411765,\n",
       "        -0.5       ,  0.        ],\n",
       "       [-1.15384615,  0.        , -0.07142857, ..., -0.76470588,\n",
       "         1.38888889,  1.        ],\n",
       "       [-0.76923077, -0.47058824,  0.5       , ..., -1.11764706,\n",
       "         0.83333333,  0.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = RobustScaler()\n",
    "X_scaled = rs.fit_transform(X)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96ecc56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "6492    0\n",
       "6493    0\n",
       "6494    0\n",
       "6495    0\n",
       "6496    0\n",
       "Name: 12, Length: 6497, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bc9d732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1df35e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_scaled, y ,test_size=0.4 , stratify=y,random_state=10)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.5,stratify=y_valid, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74083a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 09:08:32.071152: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-11 09:08:34.925117: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libdirectml.d6f03b303ac3c4f2eeb8ca631688c9757b361310.so\n",
      "2024-09-11 09:08:34.925277: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libdxcore.so\n",
      "2024-09-11 09:08:34.929563: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libd3d12.so\n",
      "2024-09-11 09:08:35.148798: I tensorflow/c/logging.cc:34] DirectML device enumeration: found 1 compatible adapters.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87c9e71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                416       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,089\n",
      "Trainable params: 1,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 09:12:25.020101: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-11 09:12:25.022264: I tensorflow/c/logging.cc:34] DirectML: creating device on adapter 0 (AMD Radeon(TM) Graphics)\n",
      "2024-09-11 09:12:25.104741: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-11 09:12:25.104796: W tensorflow/core/common_runtime/pluggable_device/pluggable_device_bfc_allocator.cc:28] Overriding allow_growth setting because force_memory_growth was requested by the device.\n",
      "2024-09-11 09:12:25.104820: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0246dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.6751 - accuracy: 0.6551"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 09:12:28.091228: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-11 09:12:28.161626: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-11 09:12:28.161699: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 35ms/step - loss: 0.6730 - accuracy: 0.6621 - val_loss: 0.6483 - val_accuracy: 0.7421\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6336 - accuracy: 0.7878 - val_loss: 0.6102 - val_accuracy: 0.8391\n",
      "Epoch 3/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.6089 - accuracy: 0.8540"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 09:12:28.428279: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-11 09:12:28.453219: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-11 09:12:28.453281: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5925 - accuracy: 0.8774 - val_loss: 0.5643 - val_accuracy: 0.9338\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5420 - accuracy: 0.9441 - val_loss: 0.5093 - val_accuracy: 0.9584\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4827 - accuracy: 0.9664 - val_loss: 0.4475 - val_accuracy: 0.9677\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4196 - accuracy: 0.9779 - val_loss: 0.3875 - val_accuracy: 0.9746\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3595 - accuracy: 0.9828 - val_loss: 0.3315 - val_accuracy: 0.9761\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3036 - accuracy: 0.9831 - val_loss: 0.2799 - val_accuracy: 0.9784\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2528 - accuracy: 0.9846 - val_loss: 0.2340 - val_accuracy: 0.9823\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2085 - accuracy: 0.9882 - val_loss: 0.1945 - val_accuracy: 0.9831\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1714 - accuracy: 0.9887 - val_loss: 0.1616 - val_accuracy: 0.9846\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1409 - accuracy: 0.9885 - val_loss: 0.1354 - val_accuracy: 0.9846\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1171 - accuracy: 0.9895 - val_loss: 0.1149 - val_accuracy: 0.9861\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0987 - accuracy: 0.9892 - val_loss: 0.0990 - val_accuracy: 0.9885\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0844 - accuracy: 0.9892 - val_loss: 0.0868 - val_accuracy: 0.9900\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0734 - accuracy: 0.9897 - val_loss: 0.0774 - val_accuracy: 0.9908\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0650 - accuracy: 0.9897 - val_loss: 0.0701 - val_accuracy: 0.9908\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0585 - accuracy: 0.9897 - val_loss: 0.0643 - val_accuracy: 0.9915\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0533 - accuracy: 0.9910 - val_loss: 0.0596 - val_accuracy: 0.9915\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0491 - accuracy: 0.9913 - val_loss: 0.0558 - val_accuracy: 0.9923\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0456 - accuracy: 0.9918 - val_loss: 0.0528 - val_accuracy: 0.9923\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0426 - accuracy: 0.9926 - val_loss: 0.0504 - val_accuracy: 0.9923\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0403 - accuracy: 0.9928 - val_loss: 0.0483 - val_accuracy: 0.9923\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0382 - accuracy: 0.9928 - val_loss: 0.0466 - val_accuracy: 0.9923\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0364 - accuracy: 0.9928 - val_loss: 0.0452 - val_accuracy: 0.9923\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0349 - accuracy: 0.9933 - val_loss: 0.0439 - val_accuracy: 0.9931\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0336 - accuracy: 0.9933 - val_loss: 0.0429 - val_accuracy: 0.9931\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0324 - accuracy: 0.9936 - val_loss: 0.0420 - val_accuracy: 0.9931\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0313 - accuracy: 0.9938 - val_loss: 0.0411 - val_accuracy: 0.9931\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0304 - accuracy: 0.9938 - val_loss: 0.0404 - val_accuracy: 0.9931\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0295 - accuracy: 0.9941 - val_loss: 0.0396 - val_accuracy: 0.9931\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0287 - accuracy: 0.9941 - val_loss: 0.0390 - val_accuracy: 0.9931\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0279 - accuracy: 0.9944 - val_loss: 0.0384 - val_accuracy: 0.9931\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0273 - accuracy: 0.9946 - val_loss: 0.0379 - val_accuracy: 0.9931\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0267 - accuracy: 0.9949 - val_loss: 0.0375 - val_accuracy: 0.9931\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0261 - accuracy: 0.9949 - val_loss: 0.0370 - val_accuracy: 0.9931\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0255 - accuracy: 0.9949 - val_loss: 0.0366 - val_accuracy: 0.9931\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0250 - accuracy: 0.9951 - val_loss: 0.0363 - val_accuracy: 0.9938\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0245 - accuracy: 0.9951 - val_loss: 0.0360 - val_accuracy: 0.9946\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0241 - accuracy: 0.9951 - val_loss: 0.0357 - val_accuracy: 0.9946\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0236 - accuracy: 0.9951 - val_loss: 0.0352 - val_accuracy: 0.9946\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0232 - accuracy: 0.9951 - val_loss: 0.0349 - val_accuracy: 0.9946\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0228 - accuracy: 0.9951 - val_loss: 0.0346 - val_accuracy: 0.9946\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0224 - accuracy: 0.9951 - val_loss: 0.0344 - val_accuracy: 0.9946\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0220 - accuracy: 0.9956 - val_loss: 0.0341 - val_accuracy: 0.9946\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0217 - accuracy: 0.9956 - val_loss: 0.0339 - val_accuracy: 0.9946\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0213 - accuracy: 0.9959 - val_loss: 0.0337 - val_accuracy: 0.9954\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0210 - accuracy: 0.9959 - val_loss: 0.0334 - val_accuracy: 0.9954\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0206 - accuracy: 0.9959 - val_loss: 0.0331 - val_accuracy: 0.9954\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0204 - accuracy: 0.9959 - val_loss: 0.0330 - val_accuracy: 0.9954\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0200 - accuracy: 0.9964 - val_loss: 0.0328 - val_accuracy: 0.9954\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0197 - accuracy: 0.9964 - val_loss: 0.0327 - val_accuracy: 0.9954\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0194 - accuracy: 0.9962 - val_loss: 0.0327 - val_accuracy: 0.9954\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0191 - accuracy: 0.9962 - val_loss: 0.0325 - val_accuracy: 0.9954\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0188 - accuracy: 0.9964 - val_loss: 0.0322 - val_accuracy: 0.9954\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0185 - accuracy: 0.9967 - val_loss: 0.0320 - val_accuracy: 0.9954\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0183 - accuracy: 0.9967 - val_loss: 0.0319 - val_accuracy: 0.9954\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0181 - accuracy: 0.9967 - val_loss: 0.0320 - val_accuracy: 0.9954\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0177 - accuracy: 0.9967 - val_loss: 0.0317 - val_accuracy: 0.9954\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0175 - accuracy: 0.9967 - val_loss: 0.0315 - val_accuracy: 0.9954\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0172 - accuracy: 0.9967 - val_loss: 0.0315 - val_accuracy: 0.9954\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0170 - accuracy: 0.9967 - val_loss: 0.0315 - val_accuracy: 0.9954\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0168 - accuracy: 0.9967 - val_loss: 0.0314 - val_accuracy: 0.9954\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0166 - accuracy: 0.9967 - val_loss: 0.0315 - val_accuracy: 0.9954\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0164 - accuracy: 0.9967 - val_loss: 0.0313 - val_accuracy: 0.9954\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0162 - accuracy: 0.9967 - val_loss: 0.0311 - val_accuracy: 0.9954\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0160 - accuracy: 0.9967 - val_loss: 0.0309 - val_accuracy: 0.9954\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0158 - accuracy: 0.9969 - val_loss: 0.0308 - val_accuracy: 0.9954\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0156 - accuracy: 0.9967 - val_loss: 0.0311 - val_accuracy: 0.9954\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0154 - accuracy: 0.9967 - val_loss: 0.0309 - val_accuracy: 0.9954\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0153 - accuracy: 0.9969 - val_loss: 0.0309 - val_accuracy: 0.9954\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0151 - accuracy: 0.9969 - val_loss: 0.0307 - val_accuracy: 0.9954\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0149 - accuracy: 0.9969 - val_loss: 0.0308 - val_accuracy: 0.9954\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0148 - accuracy: 0.9969 - val_loss: 0.0308 - val_accuracy: 0.9954\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0146 - accuracy: 0.9969 - val_loss: 0.0307 - val_accuracy: 0.9954\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0145 - accuracy: 0.9972 - val_loss: 0.0306 - val_accuracy: 0.9954\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0144 - accuracy: 0.9972 - val_loss: 0.0307 - val_accuracy: 0.9954\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0142 - accuracy: 0.9974 - val_loss: 0.0306 - val_accuracy: 0.9954\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0141 - accuracy: 0.9972 - val_loss: 0.0305 - val_accuracy: 0.9954\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0140 - accuracy: 0.9972 - val_loss: 0.0304 - val_accuracy: 0.9954\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0139 - accuracy: 0.9972 - val_loss: 0.0306 - val_accuracy: 0.9954\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0137 - accuracy: 0.9974 - val_loss: 0.0303 - val_accuracy: 0.9954\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0136 - accuracy: 0.9974 - val_loss: 0.0304 - val_accuracy: 0.9954\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0135 - accuracy: 0.9974 - val_loss: 0.0305 - val_accuracy: 0.9954\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0134 - accuracy: 0.9974 - val_loss: 0.0304 - val_accuracy: 0.9954\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0133 - accuracy: 0.9977 - val_loss: 0.0304 - val_accuracy: 0.9954\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0132 - accuracy: 0.9977 - val_loss: 0.0305 - val_accuracy: 0.9954\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0131 - accuracy: 0.9977 - val_loss: 0.0302 - val_accuracy: 0.9954\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0130 - accuracy: 0.9977 - val_loss: 0.0302 - val_accuracy: 0.9954\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0128 - accuracy: 0.9977 - val_loss: 0.0303 - val_accuracy: 0.9954\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0127 - accuracy: 0.9974 - val_loss: 0.0303 - val_accuracy: 0.9954\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0126 - accuracy: 0.9974 - val_loss: 0.0302 - val_accuracy: 0.9954\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0126 - accuracy: 0.9977 - val_loss: 0.0299 - val_accuracy: 0.9954\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0125 - accuracy: 0.9977 - val_loss: 0.0301 - val_accuracy: 0.9954\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0123 - accuracy: 0.9977 - val_loss: 0.0302 - val_accuracy: 0.9954\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0123 - accuracy: 0.9977 - val_loss: 0.0302 - val_accuracy: 0.9954\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0122 - accuracy: 0.9977 - val_loss: 0.0300 - val_accuracy: 0.9954\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0121 - accuracy: 0.9977 - val_loss: 0.0298 - val_accuracy: 0.9954\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0120 - accuracy: 0.9977 - val_loss: 0.0299 - val_accuracy: 0.9954\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0119 - accuracy: 0.9977 - val_loss: 0.0303 - val_accuracy: 0.9954\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=500, validation_data=(X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46d6fd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       980\n",
      "           1       1.00      0.98      0.99       320\n",
      "\n",
      "    accuracy                           1.00      1300\n",
      "   macro avg       1.00      0.99      0.99      1300\n",
      "weighted avg       1.00      1.00      1.00      1300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 09:12:41.322621: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-11 09:12:41.448316: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-11 09:12:41.448403: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2024-09-11 09:12:41.469784: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-11 09:12:41.469848: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2024-09-11 09:12:41.474878: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-11 09:12:41.474938: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred = pd.DataFrame(pred)\n",
    "pred = pred[0].apply(lambda x: 1 if x> 0.5 else 0)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "820b1a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "015fd116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAF2CAYAAAB9KhCBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABREUlEQVR4nO3deXwU9f3H8dfsbnZzJ0AgBEhCFOQUkKAISL2joKi1VuqF/tRaftVW4KdWpI9flbbiT6vFC6pVa61aaQv256/iEaoihwfGgAjIIUcCJIRwJIQcm92d3x+b3WRJwJBrdpP38/GYx8zOzsx+NsPxnm++8x3DNE0TEREREZEIZLO6ABERERGRllKYFREREZGIpTArIiIiIhFLYVZEREREIpbCrIiIiIhELIVZEREREYlYCrMiIiIiErEUZkVEREQkYinMioiIiEjEUpgVERERkYhleZhdsGABWVlZREdHk52dzYoVK4677S233IJhGI2mYcOGdWDFIiIiIhIuDNM0Tas+fNGiRdx0000sWLCACRMm8Nxzz/HCCy+wceNGMjIyGm1fVlZGVVVV8LXH42HkyJH87Gc/48EHH2zWZ/p8Pvbu3UtCQgKGYbTVVxERERGRNmKaJkeOHKFPnz7YbN/R9mpa6KyzzjKnT58esm7w4MHm/fff36z933zzTdMwDHPnzp3N/szCwkIT0KRJkyZNmjRp0hTmU2Fh4XdmOwcWcbvd5OXlcf/994esz8nJYfXq1c06xosvvshFF11EZmbmcbepqamhpqYm+Nqsa4guLCwkMTGxBZWLiIiISHsqLy8nPT2dhISE79zWsjBbWlqK1+slNTU1ZH1qairFxcXfuX9RURHvvPMOr7/++gm3mzdvHg899FCj9YmJiQqzIiIiImGsOV1CLb8B7NgiTdNsVuEvv/wyycnJXHXVVSfcbvbs2ZSVlQWnwsLC1pQrIiIiImHEspbZlJQU7HZ7o1bYkpKSRq21xzJNk5deeombbroJp9N5wm1dLhcul6vV9YqIiIhI+LGsZdbpdJKdnU1ubm7I+tzcXMaPH3/CfZcvX862bdu47bbb2rNEEREREQlzlrXMAsyaNYubbrqJMWPGMG7cOJ5//nkKCgqYPn064O8isGfPHl555ZWQ/V588UXGjh3L8OHDrShbREREBNM08Xg8eL1eq0uJSFFRUdjt9lYfx9IwO3XqVA4cOMDcuXMpKipi+PDhLF26NDg6QVFREQUFBSH7lJWVsXjxYp588kkrShYRERHB7XZTVFREZWWl1aVELMMw6NevH/Hx8a07jmla99AEK5SXl5OUlERZWZlGMxAREZGT5vP52Lp1K3a7nZ49e+J0OvUgppNkmib79++nsrKSgQMHNmqhPZm8ZmnLrIiIiEikcbvd+Hw+0tPTiY2NtbqciNWzZ0927txJbW1tq7obWD40l4iIiEgk+s7HrMoJtVVrts6CiIiIiEQshdl2VlHj4X/X7uHrPWVWlyIiIiLSZvr378/8+fOtLkNhtr098s4m7n5jLX/5ZJfVpYiIiEgXd9555zFjxow2OdaaNWu444472uRYraEw284mn54GwLsbinF7fBZXIyIiInJ8gbFzm6Nnz55hcQOcwmw7G5vVg54JLsqqalm5bb/V5YiIiEgXdcstt7B8+XKefPJJDMPAMAxefvllDMPgvffeY8yYMbhcLlasWMG3337LlVdeSWpqKvHx8Zx55pksW7Ys5HjHdjMwDIMXXniB73//+8TGxjJw4EDeeuutdv9eCrPtzG4zuKyudfZf64osrkZERETag2maVLo9HT6dzOMCnnzyScaNG8ePf/xjioqKKCoqIj09HYD77ruPefPmsWnTJkaMGEFFRQWTJ09m2bJl5Ofnc8kllzBlypRGD7M61kMPPcS1117LV199xeTJk7nhhhs4ePBgq36230XjzHaAy0ek8fLqnby/cR/VtV6io1r/6DYREREJH1W1Xob+93sd/rkb515CrLN5cS4pKQmn00lsbCy9e/cG4JtvvgFg7ty5XHzxxcFte/TowciRI4Ovf/Ob3/Dmm2/y1ltvcddddx33M2655Rauu+46AB5++GGefvppPv/8cy699NKT/m7NpZbZDjA6oxtpSdFU1Hj4aLO6GoiIiEh4GTNmTMjro0ePct999zF06FCSk5OJj4/nm2+++c6W2REjRgSX4+LiSEhIoKSkpF1qDlDLbAew2QwuH5HGH1fs4F9f7eXS4b2tLklERETaUEyUnY1zL7Hkc9tCXFxcyOt7772X9957j9/97ncMGDCAmJgYrrnmGtxu9wmPExUVFfLaMAx8vva9AV5htoNcPqIPf1yxg39vKqHS7Wn2rwREREQk/BmGERH/tzudTrxe73dut2LFCm655Ra+//3vA1BRUcHOnTvbubqWUTeDDjKiXxIZ3WOpqvXy703t29wuIiIi0pT+/fvz2WefsXPnTkpLS4/bajpgwACWLFnC2rVrWbduHddff327t7C2lMJsR/B6MDzVXD7CP6rB/63ba3FBIiIi0hXdc8892O12hg4dSs+ePY/bB/b3v/893bp1Y/z48UyZMoVLLrmE0aNHd3C1zWOYJzOmQydQXl5OUlISZWVlJCYmtv8Hfv5HWP4/MP7nbDrlFiY9uQKnw0beLy8iITrqu/cXERGRsFJdXc2OHTvIysoiOjra6nIi1ol+jieT19Qy295sdji6H9b/jcG9Ezi1Zxxuj4/cjfusrkxEREQk4inMtrehV4HNAcXrMfZv5vIRfQB1NRARERFpCwqz7S22Owy4yL/89T+YMtLfb3bF1lIOV554eAsREREROTGF2Y5w+g/98/V/Z0DPeAb3TsDjM3n362Jr6xIRERGJcAqzHWHQJIiKg0M7YfcXTBnp72rwr6+KrK1LREREJMIpzHYEZxwMvsy/vP7vTKnrN7v621JKK2osLExEREQksinMdpRAV4MNS8hIdjKiXxI+E95RVwMRERGRFlOY7Sinng+xPfzDdO34iMmn+28Ee/drdTUQERERaSmF2Y5ij4Jh/ucbs/4fTBreG4BPtx/k4FGNaiAiIiLSEgqzHSnQ1WDT/5GZaGNYn0S8PpPcjepqICIiIuGvf//+zJ8/3+oyQijMdqT0sZCcAe4K2PJusKvB0vUKsyIiIiItoTDbkQwDhl/jX/7q78GuBqu2lVJWWWthYSIiIiKRSWG2owW6Gmx9n1PiaxmU6n+AQu6mfdbWJSIiIp3ac889R9++ffH5fCHrr7jiCm6++Wa+/fZbrrzySlJTU4mPj+fMM89k2bJlFlXbfAqzHS11KPQaBr5a2PgWk073t85qVAMREZEIZprgPtrxk2k2u8Qf/vCHlJaW8uGHHwbXHTp0iPfee48bbriBiooKJk+ezLJly8jPz+eSSy5hypQpFBQUtMdPrM04rC6gSxrxQ1i2Adb/ncmTrmb+sq18vKWUI9W1JERHWV2diIiInKzaSni4T8d/7gN7/Q9naobu3btz6aWX8vrrr3PhhRcC8Pe//53u3btz4YUXYrfbGTlyZHD73/zmN7z55pu89dZb3HXXXe1SfltQy6wVhv/AP9+5koHRZZzaMw6318cH35RYW5eIiIh0ajfccAOLFy+mpsb/BNLXXnuNH/3oR9jtdo4ePcp9993H0KFDSU5OJj4+nm+++UYts99lwYIFPPbYYxQVFTFs2DDmz5/PxIkTj7t9TU0Nc+fO5dVXX6W4uJh+/foxZ84cbr311g6supWSMyD9bCj8FOObpUw+/Vye/mAbS9cXceWovlZXJyIiIicrKtbfSmrF556EKVOm4PP5ePvttznzzDNZsWIFTzzxBAD33nsv7733Hr/73e8YMGAAMTExXHPNNbjd4T0evqVhdtGiRcyYMYMFCxYwYcIEnnvuOSZNmsTGjRvJyMhocp9rr72Wffv28eKLLzJgwABKSkrweDwdXHkbGDQJCj+Fre8x6YIf8fQH2/ho836O1niIc1l+jSEiIiInwzCa/et+K8XExHD11Vfz2muvsW3bNk477TSys7MBWLFiBbfccgvf/77/IU8VFRXs3LnTwmqbx9JuBk888QS33XYbt99+O0OGDGH+/Pmkp6ezcOHCJrd/9913Wb58OUuXLuWiiy6if//+nHXWWYwfP76DK28Dp13in+9YwZAUO5k9Yqnx+Pho835r6xIREZFO7YYbbuDtt9/mpZde4sYbbwyuHzBgAEuWLGHt2rWsW7eO66+/vtHIB+HIsjDrdrvJy8sjJycnZH1OTg6rV69ucp+33nqLMWPG8Oijj9K3b19OO+007rnnHqqqqjqi5LbVczAkZYC3BmPHCiYNr3uAgkY1EBERkXZ0wQUX0L17dzZv3sz1118fXP/73/+ebt26MX78eKZMmcIll1zC6NGjLay0eSz7fXZpaSler5fU1NSQ9ampqRQXN/1ErO3bt7Ny5Uqio6N58803KS0t5ac//SkHDx7kpZdeanKfmpqaYCdngPLy8rb7Eq1hGDDwYvjiRdj6HpNH/Yo/LP+WD78pocrtJcZpt7pCERER6YTsdjt79zbu39u/f38++OCDkHV33nlnyOtw7HZg+WgGhmGEvDZNs9G6AJ/Ph2EYvPbaa5x11llMnjyZJ554gpdffvm4rbPz5s0jKSkpOKWnp7f5d2ixQFeDLe9zep9E+ibHUOn2snyLuhqIiIiINIdlYTYlJQW73d6oFbakpKRRa21AWloaffv2JSkpKbhuyJAhmKbJ7t27m9xn9uzZlJWVBafCwsK2+xKt1X8iOKKhfDfG/k1M1gMURERERE6KZWHW6XSSnZ1Nbm5uyPrc3Nzj3tA1YcIE9u7dS0VFRXDdli1bsNls9OvXr8l9XC4XiYmJIVPYcMZC1vf8y1veY9Lp/n6zyzaV4PaEf4drEREREatZ2s1g1qxZvPDCC7z00kts2rSJmTNnUlBQwPTp0wF/q+q0adOC219//fX06NGD//iP/2Djxo18/PHH3Hvvvdx6663ExMRY9TVaZ2DdDXBb32dUv2R6xDmpqPGwbvdhS8sSERERiQSWhtmpU6cyf/585s6dy6hRo/j4449ZunQpmZmZABQVFYU8dSI+Pp7c3FwOHz7MmDFjuOGGG5gyZQpPPfWUVV+h9QL9Zgs/w1Z9iPEDUgBYubXUwqJEREREIoNhmqZpdREdqby8nKSkJMrKysKny8GzZ8P+TfCDF1lUfRa/WLyeMZnd+Md/RuD4uSIiIp1cdXU1O3bsoH///pH7m+EwUFVVxc6dO8nKyiI6OjrkvZPJa5aPZiDAaXVdDba8x4S6ltn8wsMcqa61sCgRERFpSlRUFACVlZUWVxLZAo/JtdtbNxypnpsaDgZeAquehG3L6Pd9F/17xLLzQCWf7zjIhUOaHtlBRERErGG320lOTqakpASA2NjY4w4rKk3z+Xzs37+f2NhYHI7WxVGF2XCQPhaik6DqIOz+ggkDUth5oICV20oVZkVERMJQ797+4TQDgVZOns1mIyMjo9UXAgqz4cDugFMvhA1LYOt7nDPgx7z2WYFuAhMREQlThmGQlpZGr169qK1Vt8CWcDqd2Gyt7/GqMBsuTrvEH2a3vM+4cfdjGLC1pIJ95dWkJkZ/9/4iIiLS4ex2e6v7fErr6AawcDHgIsCAfetJrt3P6X39TzlbtU2tsyIiIiLHozAbLuJSoN8Y//LW94OjGqxUmBURERE5LoXZcDKw7gEKW3M5py7MrtpWShcbClhERESk2RRmw0lgvNntH5HdLw6Xw8a+8hq+3V9hbV0iIiIiYUphNpz0HgGxPaD2KNElX3Fm/+6AHm0rIiIicjwKs+HEMCCz7hG2u1Y16Dd7wMKiRERERMKXwmy4yZzgn+9aFew3++n2A3i8PguLEhEREQlPCrPhJhBmCz5jaO9YkmOjqKjxsG53mbV1iYiIiIQhhdlwkzoMXEngPoJ933rGn9oD0HizIiIiIk1RmA03NjtkjvMvh/SbVZgVEREROZbCbDgK3gS2OthvNr/gEEdrPBYWJSIiIhJ+FGbDUeY5/vmu1WR0i6ZftxhqvSaf7zxobV0iIiIiYUZhNhyljYSoOKg+jFGyKdg6q/FmRUREREIpzIYjuwMyxvqXd61ifF2Y/XyHWmZFREREGlKYDVcNxpsdk9kNgI1F5VS61W9WREREJEBhNlwFw+xq+iRFk5YUjddnsq5Q482KiIiIBCjMhqu+o8ERDUf3Q+kWRte1zn5ZcMjiwkRERETCh8JsuHK4oN+Z/uVdq8jO8IfZvF0KsyIiIiIBCrPhLNDVYOcqshu0zPp8poVFiYiIiIQPhdlw1r++3+zQtASio2wcrqxle+lRa+sSERERCRMKs+Gs7xiwRcGRvUSV72JEv2QAvlRXAxERERFAYTa8OWOhb7Z/eWf9EF1f7NJ4syIiIiKgMBv+Msf757tWB/vN6iYwERERET+F2XAX7De7kjPqRjT4dv9RDh11W1iUiIiISHhQmA136WPBsMPhArrX7uOUnnEA5BeqdVZEREREYTbcuRIgbaR/eddqjTcrIiIi0oDCbCRo0NVA/WZFRERE6lkeZhcsWEBWVhbR0dFkZ2ezYsWK42770UcfYRhGo+mbb77pwIotkDHOPy9cEwyz6wrLqPX6LCxKRERExHqWhtlFixYxY8YM5syZQ35+PhMnTmTSpEkUFBSccL/NmzdTVFQUnAYOHNhBFVsk8Fjb/d9waqKPxGgHVbVevik6Ym1dIiIiIhazNMw+8cQT3Hbbbdx+++0MGTKE+fPnk56ezsKFC0+4X69evejdu3dwstvtHVSxReJ7QXIGYGIrymd0sKuBxpsVERGRrs2yMOt2u8nLyyMnJydkfU5ODqtXrz7hvmeccQZpaWlceOGFfPjhhyfctqamhvLy8pApIgVaZ3evqb8JrOCwdfWIiIiIhAHLwmxpaSler5fU1NSQ9ampqRQXFze5T1paGs8//zyLFy9myZIlDBo0iAsvvJCPP/74uJ8zb948kpKSglN6enqbfo8O03eMf777i2C/WT3WVkRERLo6h9UFGIYR8to0zUbrAgYNGsSgQYOCr8eNG0dhYSG/+93v+N73vtfkPrNnz2bWrFnB1+Xl5ZEZaIMts18w8uokbAbsOVxFUVkVaUkx1tYmIiIiYhHLWmZTUlKw2+2NWmFLSkoatdaeyNlnn83WrVuP+77L5SIxMTFkikhpI8DuhMpS4ip3MyTN/z2+3HXY2rpERERELGRZmHU6nWRnZ5ObmxuyPjc3l/Hjxzf7OPn5+aSlpbV1eeHH4YLep/uXG3Q10HizIiIi0pVZ2s1g1qxZ3HTTTYwZM4Zx48bx/PPPU1BQwPTp0wF/F4E9e/bwyiuvADB//nz69+/PsGHDcLvdvPrqqyxevJjFixdb+TU6Tr8zYU8e7PmC7MzxvPLJLvIKFGZFRESk67I0zE6dOpUDBw4wd+5cioqKGD58OEuXLiUzMxOAoqKikDFn3W4399xzD3v27CEmJoZhw4bx9ttvM3nyZKu+QsfqdyZ89gf/iAZn+1tmN+wpo7rWS3RUJx+eTERERKQJhmmaptVFdKTy8nKSkpIoKyuLvP6zB3fAU6PAFoU5u5CzH1vFvvIaFt1xNmNP6WF1dSIiIiJt4mTymuWPs5WT0K0/xKaArxaj+GtG1403+6XGmxUREZEuSmE2khhGyMMTRqUnA7Cu8LBlJYmIiIhYSWE20vTL9s8bhtndhy0rR0RERMRKCrORJtAyu+cLhvf1PzyhqKyafeXV1tYlIiIiYgGF2UjTZzRgwOEC4twHOC01AYC16mogIiIiXZDCbKSJToSeg/3Le74IdjVQmBUREZGuSGE2EvUb45/vbhBmNaKBiIiIdEEKs5EoGGbXMLIuzK7fU4bX16WGDBYRERFRmI1IgZvA9uZzWs9YYp12Kmo8fLu/wtq6RERERDqYwmwk6jkYnPHgrsB+YDPD+yYB6jcrIiIiXY/CbCSy2aHPGf7l3Ws4QzeBiYiISBelMBupgk8C+yLYb1ZPAhMREZGuRmE2UjUIs4ERDb4pPkKV22tdTSIiIiIdTGE2UgVGNNj/DWnRbnoluPD6TDbsLbO2LhEREZEOpDAbqeJ7QXIGYGLszQ92NVC/WREREelKFGYjWaCrQeEaPQlMREREuiSF2UjW7yz/fPfnCrMiIiLSJSnMRrL0QMvs55zeNwHDgN2HqiitqLG2LhEREZEOojAbyXqPAEcMVB8msWIXp/aMBzREl4iIiHQdCrORzB5V//CEws+CXQ0UZkVERKSrUJiNdIGuBrs/D45okK8wKyIiIl2EwmykSx/rnxfWP9Z2XeFhTNO0riYRERGRDqIwG+kCIxrs38SgZB8uh43yag87So9aW5eIiIhIB1CYjXTxPaFbFgBRRXkM75sEwLrdhy0sSkRERKRjKMx2Bul1rbOFaxjZLxmAtQWHLStHREREpKMozHYGwSeBfcaojGRAD08QERGRrkFhtjMI3AS2J49RfRIA2FhUTnWt18KiRERERNqfwmxn0GsoRMVBTTnp3l30iHNS6zXZsLfc6spERERE2pXCbGdgd0Df0QAYu9dwRkY3APILDllZlYiIiEi7U5jtLAJdDXavYXRmMgBfKsyKiIhIJ6cw21kERzT4jNF1LbNf7jpsXT0iIiIiHcDyMLtgwQKysrKIjo4mOzubFStWNGu/VatW4XA4GDVqVPsWGCkCIxoc2MaI7l7sNoPi8mr2Hq6yti4RERGRdmRpmF20aBEzZsxgzpw55OfnM3HiRCZNmkRBQcEJ9ysrK2PatGlceOGFHVRpBIjtDj0G+hdL8hmalghA3i51NRAREZHOy9Iw+8QTT3Dbbbdx++23M2TIEObPn096ejoLFy484X4/+clPuP766xk3blwHVRohQroaJAPqNysiIiKdm2Vh1u12k5eXR05OTsj6nJwcVq9efdz9/vSnP/Htt9/yq1/9qlmfU1NTQ3l5ecjUaQXD7OeMzqzrN6sngYmIiEgnZlmYLS0txev1kpqaGrI+NTWV4uLiJvfZunUr999/P6+99hoOh6NZnzNv3jySkpKCU3p6eqtrD1v96sLsnjxG96t7eMLeMj08QURERDoty28AMwwj5LVpmo3WAXi9Xq6//noeeughTjvttGYff/bs2ZSVlQWnwsLCVtcctnoOBlci1FbSz72dlHgXtV6Tr/eUWV2ZiIiISLuwLMympKRgt9sbtcKWlJQ0aq0FOHLkCF988QV33XUXDocDh8PB3LlzWbduHQ6Hgw8++KDJz3G5XCQmJoZMnZbNBv3GAP6HJ2TXjTerm8BERESks7IszDqdTrKzs8nNzQ1Zn5uby/jx4xttn5iYyPr161m7dm1wmj59OoMGDWLt2rWMHTu2o0oPb/0a9JsNjDerm8BERESkk2pex9N2MmvWLG666SbGjBnDuHHjeP755ykoKGD69OmAv4vAnj17eOWVV7DZbAwfPjxk/169ehEdHd1ofZeWXjfe7O7PGZ1dfxPY8bpviIiIiEQyS8Ps1KlTOXDgAHPnzqWoqIjhw4ezdOlSMjMzASgqKvrOMWflGH3HAAYc2snpSdU4bAb7j9Sw+1AV6d1jra5OREREpE0ZpmmaVhfRkcrLy0lKSqKsrKzz9p9dOAH2fQ0//DNXfpjCut1lPPmjUVw5qq/VlYmIiIh8p5PJa5aPZiDtIKPuYRK7VtePN6ubwERERKQTUpjtjDLrbqArWN3gJrDD1tUjIiIi0k4UZjujQJgt/prs3nYANhWVU+XWwxNERESkc1GY7YwSekO3LMAkrWwtqYkuPD6Tr3YftroyERERkTalMNtZZU4AwCj4hOxMdTUQERGRzklhtrPKbHATWF2/WT0JTERERDobhdnOKtBvds+XjO4TA0B+wSG62EhsIiIi0skpzHZW3bIgvjf4ahnOVpx2GweOuik4WGl1ZSIiIiJtpkVh9s9//jNvv/128PV9991HcnIy48ePZ9euXW1WnLSCYQRbZ527P2VYX/+Aw18WqKuBiIiIdB4tCrMPP/wwMTH+X11/8sknPPPMMzz66KOkpKQwc+bMNi1QWiHQ1WDXarID483uOmxdPSIiIiJtzNGSnQoLCxkwYAAA//znP7nmmmu44447mDBhAuedd15b1ietEXgSWOHnZI9M4AXgC90EJiIiIp1Ii1pm4+PjOXDgAADvv/8+F110EQDR0dFUVVW1XXXSOr2GQnQS1B5lbOxuAL4pLqesqtbiwkRERETaRovC7MUXX8ztt9/O7bffzpYtW7jssssA2LBhA/3792/L+qQ1bLZg62z3/XlkpcRhmpC366DFhYmIiIi0jRaF2WeffZZx48axf/9+Fi9eTI8ePQDIy8vjuuuua9MCpZUa9Js9q393AD7foa4GIiIi0jm0qM9scnIyzzzzTKP1Dz30UKsLkjaWURdmCz7hzAuTWfRFIZ/vOGBtTSIiIiJtpEUts++++y4rV64Mvn722WcZNWoU119/PYcOqdUvrKSNhKhYqDrIhCR/iP1qdxlVbq/FhYmIiIi0XovC7L333kt5eTkA69ev57/+67+YPHky27dvZ9asWW1aoLSSwwn9xgDQ+/CX9E6MxuMzyS/URYeIiIhEvhaF2R07djB06FAAFi9ezOWXX87DDz/MggULeOedd9q0QGkDmRMAMHat5qysQL9Z3QQmIiIika9FYdbpdFJZ6X8s6rJly8jJyQGge/fuwRZbCSOB8WYLPuHM/v6HJ6zZqTArIiIika9FN4Cdc845zJo1iwkTJvD555+zaNEiALZs2UK/fv3atEBpA/3OBJsDyvcwIcV/EZK36xBujw+no0XXMyIiIiJhoUVJ5plnnsHhcPCPf/yDhQsX0rdvXwDeeecdLr300jYtUNqAMxb6nAFA/4q1dIuNorrWx9d7yywuTERERKR1WtQym5GRwb/+9a9G63//+9+3uiBpJxnjYPcabIWfMKb/zeRu3MeaHQcZndHN6spEREREWqzFv2P2er0sXryY3/zmN/z2t79lyZIleL0a7ils1d0Exs6VjNVNYCIiItJJtKhldtu2bUyePJk9e/YwaNAgTNNky5YtpKen8/bbb3Pqqae2dZ3SWpnjwbDDwe2MT6kC/DeB+XwmNpthcXEiIiIiLdOiltmf//znnHrqqRQWFvLll1+Sn59PQUEBWVlZ/PznP2/rGqUtRCdC39EADKrKJ9Zpp7zaw+Z9RywuTERERKTlWhRmly9fzqOPPkr37t2D63r06MEjjzzC8uXL26w4aWNZ3wPAvvNjsjP9fWXV1UBEREQiWYvCrMvl4siRxi16FRUVOJ3OVhcl7STrXP98+3LOCoRZjTcrIiIiEaxFYfbyyy/njjvu4LPPPsM0TUzT5NNPP2X69OlcccUVbV2jtJX0sWB3QUUxE3scBvwts6ZpWluXiIiISAu1KMw+9dRTnHrqqYwbN47o6Giio6MZP348AwYMYP78+W1corSZqGjIGAvAsOp8nHYb+4/UsPNApcWFiYiIiLRMi0YzSE5O5n//93/Ztm0bmzZtwjRNhg4dyoABA9q6PmlrWefCjo+J2vUxI9PvZM3OQ6zZcZCslDirKxMRERE5ac0Os7NmzTrh+x999FFw+YknnmhxQdLOTjkPPvg17FzJWSMfYM3OQ3y24yDXnpludWUiIiIiJ63ZYTY/P79Z2xnGyY1ZumDBAh577DGKiooYNmwY8+fPZ+LEiU1uu3LlSn7xi1/wzTffUFlZSWZmJj/5yU+YOXPmSX1ml5Y2ClyJUH2Y85P38Sz+8WZFREREIlGzw+yHH37Y5h++aNEiZsyYwYIFC5gwYQLPPfcckyZNYuPGjWRkZDTaPi4ujrvuuosRI0YQFxfHypUr+clPfkJcXBx33HFHm9fXKdkd/qeBbXmH02vysRmDKThYSVFZFWlJMVZXJyIiInJSDNPCW9nHjh3L6NGjWbhwYXDdkCFDuOqqq5g3b16zjnH11VcTFxfHX/7yl2ZtX15eTlJSEmVlZSQmJrao7oj36UJ493449QIuPzyLr/eU8+SPRnHlqL5WVyYiIiJyUnmtRaMZtAW3201eXh45OTkh63Nycli9enWzjpGfn8/q1as599xz26PEzisw3uyuTzg7w/8H5NPtBywsSERERKRlWjSaQVsoLS3F6/WSmpoasj41NZXi4uIT7tuvXz/279+Px+PhwQcf5Pbbbz/utjU1NdTU1ARfl5eXt67wzqDXEIjrCUf3M7lbIS9gsGqbwqyIiIhEHstaZgOOvWHMNM3vvIlsxYoVfPHFF/zhD39g/vz5/PWvfz3utvPmzSMpKSk4pafrrn0MI/ho2+E1a3HYDAoOVlKg8WZFREQkwlgWZlNSUrDb7Y1aYUtKShq11h4rKyuL008/nR//+MfMnDmTBx988Ljbzp49m7KysuBUWFjYFuVHvrquBs6CFYxKTwZg1belFhYkIiIicvIsC7NOp5Ps7Gxyc3ND1ufm5jJ+/PhmH8c0zZBuBMdyuVwkJiaGTAKcUtdvds8XnJcVC8CqbQqzIiIiElks6zML/gcx3HTTTYwZM4Zx48bx/PPPU1BQwPTp0wF/q+qePXt45ZVXAHj22WfJyMhg8ODBgH/c2d/97nf87Gc/s+w7RKxu/SE5Aw4XkBO/nd/hYvW3B/D5TGy2kxsrWERERMQqlobZqVOncuDAAebOnUtRURHDhw9n6dKlZGZmAlBUVERBQUFwe5/Px+zZs9mxYwcOh4NTTz2VRx55hJ/85CdWfYXIlnUu5P+FUyvyiHVO5OBRN5uKyxnWJ8nqykRERESaxdJxZq2gcWYbWP8PWHwb9B7Bf7ge58PN+3lg8mDu+N6pVlcmIiIiXVhEjDMrYaB/3WODi9dzQaa/kV5DdImIiEgkUZjtyhJSoecQwOR812YAPt9xkBqP19q6RERERJpJYbarO+U8APqWriYl3klVrZf8gsOWliQiIiLSXAqzXd3AiwEwtr7P+FN6ALBaQ3SJiIhIhFCY7er6nwNRcVBRzOW99gOwUmFWREREIoTCbFfncAW7Goz1rAFg3e4yjlTXWliUiIiISPMozAqclgNAUuGH9O8Ri9dn8tn2gxYXJSIiIvLdFGYFBvrDLHvyuLi/HVBXAxEREYkMCrMCiX2g9+mAyeUxGwBYpTArIiIiEUBhVvwGXgLAkCOfYBiwtaSCkvJqi4sSEREROTGFWfE7zR9mnTs/YmRaHACrvlXrrIiIiIQ3hVnx65sNsT2gpowfpu4FYOVWPdpWREREwpvCrPjZ7DDgIgDO5UsAVn9bimmaVlYlIiIickIKs1KvblSDPvs/xumwUVRWzbf7KywuSkREROT4FGal3oALwbBjK93M5Rn+hyb8e1OJxUWJiIiIHJ/CrNSL6QbpYwGYmrQRgGWb9llZkYiIiMgJKcxKqLqngY2s+gyAvF2HOFBRY2VFIiIiIselMCuh6sabjd69mjN6O/GZ8OHm/RYXJSIiItI0hVkJ1WsIJKWDp5ppaQUA/FtdDURERCRMKcxKKMMIjmrwPdM/RNfyLfuprvVaWZWIiIhIkxRmpbG6p4F13/sRqQlOKt1ePt2uByiIiIhI+FGYlcb6TwRHNEb5bm7MOgJoVAMREREJTwqz0pgzNvg0sCvs/lEN/r2pRE8DExERkbCjMCtNG/Z9ANKL3iUmyv80sA17yy0uSkRERCSUwqw07bRLwRGD7fBObso4CKirgYiIiIQfhVlpmis+eCPY1a7PAYVZERERCT8Ks3J8w68GYOD+ZRiGydd7yikqq7K4KBEREZF6CrNyfANzwBmP/chuftTb3yr7700lFhclIiIiUk9hVo4vKgYGTQbgutg1gLoaiIiISHhRmJUTq+tqMPTwBxj4WL3tAEdrPBYXJSIiIuKnMCsnduoF4ErCcXQflyfvwu31sWJrqdVViYiIiAAKs/JdHC4YcjkA0xLyAHU1EBERkfBheZhdsGABWVlZREdHk52dzYoVK4677ZIlS7j44ovp2bMniYmJjBs3jvfee68Dq+2ihvm7Gow8shw7XpZt2ofb47O4KBERERGLw+yiRYuYMWMGc+bMIT8/n4kTJzJp0iQKCgqa3P7jjz/m4osvZunSpeTl5XH++eczZcoU8vPzO7jyLuaUcyGmO87qA1wav43DlbV8uFmjGoiIiIj1DNM0Tas+fOzYsYwePZqFCxcG1w0ZMoSrrrqKefPmNesYw4YNY+rUqfz3f/93s7YvLy8nKSmJsrIyEhMTW1R3l/TWz+HLP5Pf80q+XziVScN7s/DGbKurEhERkU7oZPKaZS2zbrebvLw8cnJyQtbn5OSwevXqZh3D5/Nx5MgRunfvftxtampqKC8vD5mkBepGNTi9fDkOPPx7UwlllbUWFyUiIiJdnWVhtrS0FK/XS2pqasj61NRUiouLm3WMxx9/nKNHj3Lttdced5t58+aRlJQUnNLT01tVd5eVeQ7E9cRRc5ipPbbj9vp4e32R1VWJiIhIF2f5DWCGYYS8Nk2z0bqm/PWvf+XBBx9k0aJF9OrV67jbzZ49m7KysuBUWFjY6pq7JLsDhl4J1I9q8Gb+bisrEhEREbEuzKakpGC32xu1wpaUlDRqrT3WokWLuO222/jb3/7GRRdddMJtXS4XiYmJIZO00PAfADDwwAfEG1Ws2XmIwoOVFhclIiIiXZllYdbpdJKdnU1ubm7I+tzcXMaPH3/c/f76179yyy238Prrr3PZZZe1d5nSUMY46DEAW+1RZqWuA+DN/D0WFyUiIiJdmaXdDGbNmsULL7zASy+9xKZNm5g5cyYFBQVMnz4d8HcRmDZtWnD7v/71r0ybNo3HH3+cs88+m+LiYoqLiykrK7PqK3QthgFjbgXgat97gMk/8/dg4YAYIiIi0sVZGmanTp3K/PnzmTt3LqNGjeLjjz9m6dKlZGZmAlBUVBQy5uxzzz2Hx+PhzjvvJC0tLTjdfffdVn2FrmfkdeCIJrl8M2OjtrO99CjrdutiQkRERKxh6TizVtA4s23gzf+Eda/zeeIlXFtyMzePy+ShK4dbXZWIiIh0EhExzqxEsDNvA2BMxYckUcH/fVVErVePtxUREZGOpzArJ69vNvQ+HZvPzS2xqzh41M3yzfutrkpERES6IIVZOXmGAWP8rbPToj4ATI1qICIiIpZQmJWWOf2H4EygR00h420byN20j/JqPd5WREREOpbCrLSMKx5GTgVgeuxHuD0+ln6lx9uKiIhIx1KYlZarG3P2HO9n9OIQr3yyS2POioiISIdSmJWWSx0G6WdjM73c4PyIjUXlfLr9oNVViYiISBeiMCutUzdM182u5djx8tKqHRYXJCIiIl2Jwqy0zpArIKY7ybUlnG9by7JN+9hZetTqqkRERKSLUJiV1omKhtE3AXB//FJM0+Tl1TutrUlERES6DIVZab2z7wRHDAPcmzjPtpa/fVFIWZWG6RIREZH2pzArrZeQCmf9GIA50UuodHv425pCi4sSERGRrkBhVtrGhBngjGeg71susX3By6t34vH6rK5KREREOjmFWWkbcT3g7P8E4B7nYvYePsp7G/ZZXJSIiIh0dgqz0nbG3QmuJAZSwOW2T3lx5XarKxIREZFOTmFW2k5MNxj/MwBmRi1mXcEB8gsOWVyUiIiIdGYKs9K2zp4OMd05xSjiKtsqXlq10+qKREREpBNTmJW25UqAc2YAcLdjMe+vL2T3oUpraxIREZFOS2FW2t6ZP4a4XmTY9nO18RGPvbfZ6opERESkk1KYlbbnjIWJ/wXAzxxv8u7aneo7KyIiIu1CYVbaR/YtkNiXPsZB7nT8k1//ayOmaVpdlYiIiHQyCrPSPqKi4dJ5APzU/hY1hWv511dFFhclIiIinY3CrLSfoVfC0CtxGD4ejXqOx5Z+TXWt1+qqREREpBNRmJX2Nfl3mDHdGGbbxZSKv/PSqh1WVyQiIiKdiMKstK/4XhiX/g8AP3cs4d0Pl7P/SI3FRYmIiEhnoTAr7W/EtZgDL8FleHjIXMDv399kdUUiIiLSSSjMSvszDIzLf48nKoEzbNuIy3+eb4rLra5KREREOgGFWekYSX1xXPobAGbZ/85zb+bi82moLhEREWkdhVnpOKNvprrfOcQYbq4r+h/+tGKL1RWJiIhIhFOYlY5jGERf/Qy19ljOsm0m/t+/YH3hYaurEhERkQimMCsdq3sWjmv/hA8bU20fsvIvv6KixmN1VSIiIhKhLA+zCxYsICsri+joaLKzs1mxYsVxty0qKuL6669n0KBB2Gw2ZsyY0XGFSpsxBl1KzQUPAfCTmj+z6C9/sLgiERERiVSWhtlFixYxY8YM5syZQ35+PhMnTmTSpEkUFBQ0uX1NTQ09e/Zkzpw5jBw5soOrlbYUM/Fn7DvtBmyGyXWFc/n3h7lWlyQiIiIRyDBN07JbyseOHcvo0aNZuHBhcN2QIUO46qqrmDdv3gn3Pe+88xg1ahTz588/qc8sLy8nKSmJsrIyEhMTW1K2tBVvLbuevozMw59RbHbH/R+5ZPQfYHVVIiIiYrGTyWuWtcy63W7y8vLIyckJWZ+Tk8Pq1avb7HNqamooLy8PmSRM2KPod8cidjsy6G0cxP2Xa3FXHrG6KhEREYkgloXZ0tJSvF4vqampIetTU1MpLi5us8+ZN28eSUlJwSk9Pb3Nji2tZ4/thvOmv3OQBAZ4v6VgwRWY1brgEBERkeax/AYwwzBCXpum2Whda8yePZuysrLgVFhY2GbHlrbRK3Mw2y/8IxVmNAMqvqT46YsxK0qsLktEREQigGVhNiUlBbvd3qgVtqSkpFFrbWu4XC4SExNDJgk/YyZOYuU5L1NqJpJ29BvKnr0QDu20uiwREREJc5aFWafTSXZ2Nrm5oXex5+bmMn78eIuqEitdevEkPhj3CrvNFJKrCqj8w0VQ/LXVZYmIiEgYs7SbwaxZs3jhhRd46aWX2LRpEzNnzqSgoIDp06cD/i4C06ZNC9ln7dq1rF27loqKCvbv38/atWvZuHGjFeVLO7j20vN5+8w/840vndia/bhfuBR2td0NgSIiItK5OKz88KlTp3LgwAHmzp1LUVERw4cPZ+nSpWRmZgL+hyQcO+bsGWecEVzOy8vj9ddfJzMzk507d3Zk6dKO7rhsAv/j/iMXrL2bszyb8f75KuyTHoYxt0Eb9qcWERGRyGfpOLNW0DizkcHnM3ng72u48Ov7udie5185MAeueAYS2q5PtYiIiISfiBhnVuREbDaD31wzhv8d/Chza2+ixoyCre9jLhwHm/5ldXkiIiISJhRmJWw57DaevC6b6Il3McX9Gzb6MjEqD8CiG+B/74QaPWBBRESkq1OYlbBmtxncd+lg7pw6hWt9v+EPnin4MCD/VXj2bFj7Ovi8VpcpIiIiFlGYlYhw5ai+/HX6ufw57j+4ruaX7KEnlO+Gf/4n/GEibHkfulb3bxEREUFhViLI6f2S+N+7JuDJGM8F1Y/xcO11VNrioWQDvP5D+PMU2J1ndZkiIiLSgTSagUScGo+Xh9/exCuf7iLRrGBWzNvcaLyD3ef2bzDgYjh7OpxyAdh0vSYiIhJpTiavKcxKxMrbdYgHlqxn874j9KGUR7r/i4mVuRjU/ZFOOQ3OugNGXgeueGuLFRERkWZTmD0BhdnOxe3x8ccV23nq31up8fgY6ChhXr9PyD74Noa7wr+RKxHOuBFGXQ+pw/XgBRERkTCnMHsCCrOd064DR5nz5tes3FYKQI8oNw9nfcWF5f/EcXh7/YY9B8Pwa+D0H0D3UyyqVkRERE5EYfYEFGY7L9M0yd24j6c/2Mb6PWUAuBzwy9P2co3tQ2J2LANvTf0OfcfAsO/DwIv9XRLUYisiIhIWFGZPQGG28zNNk+Vb9vP0B9vI23UIAIfN4PLT4vhJr40MLn0PY8dyMH31OyWlw6kXwICL4JRzITrJoupFREREYfYEFGa7DtM0+WT7AZ7+9zY+2X4guL53YjTTTo/mR3Ff0n3PB7BzVWiLrWGHtJGQfpZ/6ncWJPVTy62IiEgHUZg9AYXZrumb4nIWrSnkzfw9HK6sDa4/K6s7lw1OYnLCt/TctxK2LYMD2xofICEN+p0JvUdA7+GQOszfmquAKyIi0uYUZk9AYbZrq/F4yd24j0VrClm5rTTkoWFD0xK5eGgql2XUMrBmA8buNVD4ORSvB7OJR+a6kvyhttcQ6DnI3+825TRI7KOQKyIi0goKsyegMCsBew5X8e7Xxby/oZg1Ow/ia/A3oVeCi/Gn9mD8gBTOyYylz9FvYE8e7Psa9m2A/ZvBV9v0gZ0JkDLQP1pCcgYkp9fNM/3dFaJiOuYLioiIRCiF2RNQmJWmHDzq5t+b9pG7cR8fb91Pda0v5P3+PWIZd2oKYzK7MTqzG/2THRgHtkHx17D/Gyjd4g+4B7c33YrbUEx3f+ttQhokpkFCH0jo7Z/ie0F8KsT1AoezHb+xiIhI+FKYPQGFWfku1bVevtx1iFXflrL62wN8tbsMry/0r0n3OCejM5I5I6Mbo9KTGdQ7gZR4F3jccGiHP9ge3gWHC0KnwIMcmiOmG8T1hNgUiO0OsT3qp5huEJMM0cmh86hYdXEQEZGIpzB7AgqzcrLKq2v5fPtBPt1+gC8LDvH1nnLcXl+j7VLinZyWmsBpqQkM6p3AwF7xnNoznm5xdS2spglVh+BIEZQXwZG99fMjxVCxDypK/HOfp2XF2qIah9zoRHDGgyuhfu4KzJP88+hE/5PSXAngjAObvYU/LRERkdZTmD0BhVlprRqPlw17y/ly1yG+LDjEhr3lFBys5Hh/k7rHOTm1ZxynpMRzaq84MrrHkdE9lvTuMSRERzXeweeD6sP+gFtZCpUH6qaD9ctVh/3BuPqwf7n6cMsDcFMcMf5Q64zzB2BnrL/V1xlXN4+FqDh//9+oWIiKrl92RNdNTv/c7gKHy78cFVM/OWLAZmu7mkVEpNNQmD0BhVlpD5VuD9tKKthcfIQt+47wTfERtu8/yp7DVSfcr1tsFBndY+nXLZa0pGh6J0WTlhRD76Ro+iRH0zPehcPejMBnmv4uDNVl9eE2MK85Uj+5Kxq8roCasvrX1eXHv6mtvdgDITe6LvDG+OdRMf5WZntgcoLN4Z/bnf6gbHf533O4Grwf5Z8HtnVE1x8vEKYD29ud9cduuGyLUsgWEbGYwuwJKMxKR6p0e9i+/yjbS4/ybUkF3+6voPBQFYUHKzl41P2d+xsG9Ihz0jMhml4JLv+U6CIlvn7qmeAkJd5FUkwURmv6y5omeGrAfdQfet1HQ5drKxvMK6H2KNRW+1976ua1Vf7JU+N/EIWn4VTl377hAyrClc1RF6ad/i4XNrv/YRoN58FQ3VQYttcF67owbrPXh2ybo/71sYE6sC4YzO11xwvsZ2tch2E/znpbE5PhP8+Y9XOo26dBXQ3rsznUD1tEOpzC7AkozEq4qKjxUHiwkoKDlew+VMW+8mr2Hq6iuKyaorJq9pVX4/E1/6+nw2bQLc5J91gn3eKi6B7npFusf0qKifJPsf55cmwUyTFOkmOjiI7q4P6xPm9d+A0E4bqg66mpD8KeKvDW+idfbf2y110/eWpCX3s99dsG5p7qxsetrW5wzLrj0KX+GTx5wWAbBXZHfcC2NwjoRiBAUx+eMfyPjTa9/vDs8/pfG0bjVvFA8A+E8UCgNk7w59Mw/J/R8HMxjnmvbh44xw1DfOC7HXuRYRxzMWALzB0NfgYNfg4hn0X9RYPP6/+z5vPUTV7/djZb/ecEPpcmLhgMI7SmwAVN4HuYvtAp+P0I/Y6GrfF3Moxjfn4Nfk4hx6278AmpOVBT4DcYRl35TRwzcE4Mo3G9gZobXrAFfrYNz1WgDqj7M+St/7MU+LMVvIBr4nse++clcDHXqI5ADQ3/PNqO2bduOfD5Detp9O9Ig+2burAM/nmKavo+hUCNPk+Dc+Grr/94Ap/X8Hy19II00MjhrfHf4Oyp9t+YHBXdsuOdhJPJa452r0ZEmhTvcjAkLZEhaU3/JfX6TA4edVNypJqSIzXsL68JLpdW1FB6xE1pRQ37K2o4Uu3B4zPZf6SG/UdOruUzOsoWDLZJMVEkREeRGO0gPtpBQrSDeFcUCcFlBwnRUXVz/+tYlx2X4yQCsc1e3x+XHidVa7tpGIRDQnNdEAn+5+n192n2eerer6kLzTX1+/nqjuXz1gdrn7dBoKmbvuszmzpG4PND6mniP1XTW/+fX8P/9IHQwFH3H1zgP8zj9bs+0Xsi0gaM+ou5hn+P2/L4IRdGDX6TA4RexOCfe+saDI51878ga2Ib1tZ6CrMiYcpuM+iZ4KJngoth37Ftda2Xg0fdHKp0c+hoLQcr3Rw66ubAUTdllW7Kqmo5XFVLWWCq9L/2+kyqa30U11ZTXF7d4lqj7AZxLgdxTgdxLjsxTgcxUTZinQ5inHZio+zEOu3EuhzEOe3EOuuDcKzTTnSUnZgoOzHOY+ZR9ub1GW4te12LUFd/oEWwJcgbGrR9taGt3z5P3XpvffAOaXGjfjnQKhRoMbPZ6/6jbKK1vWHoDwnYx7au0bi7REjrJMe8ZzZomTqm9dRseKFRd/HQVAtioB5vg5bWwPKxnxXQsA93w+AQ/H7e+oulpjS8UAleVNX9PJpq6QtplQ581yZacH3e4/z8zGOOSX3LZPAiylNfD2b9z/q456RBa2KjVlObf33wZ9ngAi7wPRq27AZatY/tUtPwNwDHttg2VVewDqOJOhpcZDb3NzYNW4SDjv3sBn8+m2Q2HRzbjNk2F6V2Z1he2CrMinQC0VF2+iTH0Ce5+WHMNE0qajwcrqzlcGUthyrdHK6qpaLaw5HqWipqPBypDkz+18euq/H4/3Gu9ZrB47Q1p91GdJTNH4qdDlwOW0jYjXbacTlsuByBuX9yOmxER9Wti/IH5ujAcnCdf7/APLCfw2a0rv9xpAqETpsd0EM7pIvzNfgNx7HhNKRv+kn8WxFywRgIzg0CtOmlUR/2pi5aTvS5DS9aGl44BcL+sRdT0ES4p+5m2cBoNHU3zobpv4sKsyJdlGEYJET7uxWkd2/ZMWq9PirdXirdHo7WeDha4+Vojce/rtZLldtDVd1yZY2XSrf//aNu/zYVNR6qa71Uub1U1XqDy5W13mCjitvrw+31UV7tATrm5jGbAS6HHWdduHXa6+dRDiP4umEADmzvOnaf4H42XMH97UTZjZDtohrMjz1GlN1GlL2LBmwRq9jsQBvfU6ALxnahMCsiLRZlt5EUYyMpponxclvBNE1qPD5/uA0E3GMCb8PlGo+vbvLirluurq1bX+uj2uMNzqtr/dvVNJhXe7zUeut/pegz8X9ubVv2WWs9h83AYTeIsvnDscNmBAO0y2HHFeUPwK4oO1E2gyi7DYfdH74Dyw6bgd3mD8d2m4HDbsNpN0LCdDCAB9cZwUDuqDuu3WYQZTdw2ALL9esavu6yrdwi0mEUZkUk7BiG4e8WEGUnuYM+0+czcXt99SE3GI79690eH7V18xqPr25bb/C9Go9/7q57L2Sd10dtYO6tX1/rrT9mrdesW+8P1m6vr9FjlD0+E4/PpBpfRzVStwnDALvhD7mBgOuKstcF79AAbq8L7HabPzjbDH9ADoTxKFvd3O5/314X0B22+tdRtobBumGIDw3ZgXrshoGtbtlm1L/XMPw7GtRutzX8LjZstvrvp+Au0vEUZkVEAJvNINpmrxuqrG1bmlvK6zODAbnW58PjNYMB2OMzQ8J1ICAHWps9Pn9ADmxf6zXxeE08Pv++3rr9A8c8NrC7vcfsXxfqA/v4g7UPr9ek1uerO17TN8yYJnhMM3Souerwu4mkLdgMGoVkxzFBObAuODfqA7zdoD4g170XEriN0DDd8Jh2G9gM/7rABYTt2G3qPst/3Prt7bbAtnX7GQ1e1x2j4T52W2g9wXWG/2LUMPzbGVC/HHKsE3x24HiGEfJzaLifUfc5IqAwKyIStuw2w3+zm7ODxwJuIdP0h+RAC7KnrnXZa5r4fODx+fD5oNbXIITXtW77A3hgf1/9cbwmXp8Pt9d/vECIr/X68PrAWxfaA/t56pZrfWbwvcB+gWN6j6nPV1e3z6yvsWENgcAe/A4nuMndZ4LPe/xgL23LCIZif7i1HxN4A4HbMBqH/WPDcaP3bGBQf+yG84ZBPBDS7Q1CtkGDYxiNA7yt4bDEBPbzv7Id850C9dRfNISG/sAFQyDc13+HwHLji4CQi4y6fQj53Pp9jWOOOaZ/d1LiXVac7uNSmBURkTZh1LX6ncyww5HIVxfQG4bjhutCJrP+PY+3Pjg3nDwNtvP4GswbbOtfptF23mO28dWFcq9Z/9rrI3ishvsF3zfrvlPgGA3Cff2y/4LEZ4Z+J6+v/ucRmJsmmJjB5y2YZv2xfHWvvQ1r9TV8bZ7wYuFYZt139fdu1wVER3j1trGcM1BhNsSCBQt47LHHKCoqYtiwYcyfP5+JE48/GO/y5cuZNWsWGzZsoE+fPtx3331Mnz69AysWEZGuzGYzsGHQ0Q/P6yoahl9vg4Dr9ZmYdWG5YTD21YVnX10oDwRc0wzdNxDIg9sGtwkc+5jP9qdy//a+xp8Z+IyGFxN1uwSXfcfUGwjsgdDf8Dv7t6uvL1B/4Ps0vDBpeMFBwwuH4L6EfH9fg2M1vNhouH/w+4XU03i/xBjLo2Mjlla0aNEiZsyYwYIFC5gwYQLPPfcckyZNYuPGjWRkZDTafseOHUyePJkf//jHvPrqq6xatYqf/vSn9OzZkx/84AcWfAMRERFpS/7uAmDXBYM0k2GaJ3rAb/saO3Yso0ePZuHChcF1Q4YM4aqrrmLevHmNtv/FL37BW2+9xaZNm4Lrpk+fzrp16/jkk0+a9Zkn86xfEREREel4J5PXOuA5kU1zu93k5eWRk5MTsj4nJ4fVq1c3uc8nn3zSaPtLLrmEL774gtratn/ykIiIiIiEN8u6GZSWluL1eklNTQ1Zn5qaSnFxcZP7FBcXN7m9x+OhtLSUtLS0RvvU1NRQU1M/IGN5eXkbVC8iIiIi4cCyltmAY8eJM03zhGPHNbV9U+sD5s2bR1JSUnBKT09vZcUiIiIiEi4sC7MpKSnY7fZGrbAlJSWNWl8Devfu3eT2DoeDHj16NLnP7NmzKSsrC06FhYVt8wVERERExHKWhVmn00l2dja5ubkh63Nzcxk/fnyT+4wbN67R9u+//z5jxowhKqrpJ/a4XC4SExNDJhERERHpHCztZjBr1ixeeOEFXnrpJTZt2sTMmTMpKCgIjhs7e/Zspk2bFtx++vTp7Nq1i1mzZrFp0yZeeuklXnzxRe655x6rvoKIiIiIWMjScWanTp3KgQMHmDt3LkVFRQwfPpylS5eSmZkJQFFREQUFBcHts7KyWLp0KTNnzuTZZ5+lT58+PPXUUxpjVkRERKSLsnScWStonFkRERGR8BYR48yKiIiIiLSWwqyIiIiIRCxL+8xaIdCrQg9PEBEREQlPgZzWnN6wXS7MHjlyBEAPTxAREREJc0eOHCEpKemE23S5G8B8Ph979+4lISHhhE8aa0vl5eWkp6dTWFiom84ilM5h56Dz2DnoPHYOOo+dQ3udR9M0OXLkCH369MFmO3Gv2C7XMmuz2ejXr58ln62HNkQ+ncPOQeexc9B57Bx0HjuH9jiP39UiG6AbwEREREQkYinMioiIiEjEUpjtAC6Xi1/96le4XC6rS5EW0jnsHHQeOwedx85B57FzCIfz2OVuABMRERGRzkMtsyIiIiISsRRmRURERCRiKcyKiIiISMRSmBURERGRiKUw284WLFhAVlYW0dHRZGdns2LFCqtLkhOYN28eZ555JgkJCfTq1YurrrqKzZs3h2xjmiYPPvggffr0ISYmhvPOO48NGzZYVLF8l3nz5mEYBjNmzAiu0zmMDHv27OHGG2+kR48exMbGMmrUKPLy8oLv6zyGP4/Hwy9/+UuysrKIiYnhlFNOYe7cufh8vuA2Oo/h5+OPP2bKlCn06dMHwzD45z//GfJ+c85ZTU0NP/vZz0hJSSEuLo4rrriC3bt3t0u9CrPtaNGiRcyYMYM5c+aQn5/PxIkTmTRpEgUFBVaXJsexfPly7rzzTj799FNyc3PxeDzk5ORw9OjR4DaPPvooTzzxBM888wxr1qyhd+/eXHzxxRw5csTCyqUpa9as4fnnn2fEiBEh63UOw9+hQ4eYMGECUVFRvPPOO2zcuJHHH3+c5OTk4DY6j+Hvf/7nf/jDH/7AM888w6ZNm3j00Ud57LHHePrpp4Pb6DyGn6NHjzJy5EieeeaZJt9vzjmbMWMGb775Jm+88QYrV66koqKCyy+/HK/X2/YFm9JuzjrrLHP69Okh6wYPHmzef//9FlUkJ6ukpMQEzOXLl5umaZo+n8/s3bu3+cgjjwS3qa6uNpOSksw//OEPVpUpTThy5Ig5cOBAMzc31zz33HPNu+++2zRNncNI8Ytf/MI855xzjvu+zmNkuOyyy8xbb701ZN3VV19t3njjjaZp6jxGAsB88803g6+bc84OHz5sRkVFmW+88UZwmz179pg2m818991327xGtcy2E7fbTV5eHjk5OSHrc3JyWL16tUVVyckqKysDoHv37gDs2LGD4uLikPPqcrk499xzdV7DzJ133slll13GRRddFLJe5zAyvPXWW4wZM4Yf/vCH9OrVizPOOIM//vGPwfd1HiPDOeecw7///W+2bNkCwLp161i5ciWTJ08GdB4jUXPOWV5eHrW1tSHb9OnTh+HDh7fLeXW0+REFgNLSUrxeL6mpqSHrU1NTKS4utqgqORmmaTJr1izOOecchg8fDhA8d02d1127dnV4jdK0N954gy+//JI1a9Y0ek/nMDJs376dhQsXMmvWLB544AE+//xzfv7zn+NyuZg2bZrOY4T4xS9+QVlZGYMHD8Zut+P1evntb3/LddddB+jvYyRqzjkrLi7G6XTSrVu3Rtu0RwZSmG1nhmGEvDZNs9E6CU933XUXX331FStXrmz0ns5r+CosLOTuu+/m/fffJzo6+rjb6RyGN5/Px5gxY3j44YcBOOOMM9iwYQMLFy5k2rRpwe10HsPbokWLePXVV3n99dcZNmwYa9euZcaMGfTp04ebb745uJ3OY+RpyTlrr/OqbgbtJCUlBbvd3ugKpKSkpNHVjISfn/3sZ7z11lt8+OGH9OvXL7i+d+/eADqvYSwvL4+SkhKys7NxOBw4HA6WL1/OU089hcPhCJ4nncPwlpaWxtChQ0PWDRkyJHgDrf4uRoZ7772X+++/nx/96Eecfvrp3HTTTcycOZN58+YBOo+RqDnnrHfv3rjdbg4dOnTcbdqSwmw7cTqdZGdnk5ubG7I+NzeX8ePHW1SVfBfTNLnrrrtYsmQJH3zwAVlZWSHvZ2Vl0bt375Dz6na7Wb58uc5rmLjwwgtZv349a9euDU5jxozhhhtuYO3atZxyyik6hxFgwoQJjYbF27JlC5mZmYD+LkaKyspKbLbQqGG324NDc+k8Rp7mnLPs7GyioqJCtikqKuLrr79un/Pa5reUSdAbb7xhRkVFmS+++KK5ceNGc8aMGWZcXJy5c+dOq0uT4/jP//xPMykpyfzoo4/MoqKi4FRZWRnc5pFHHjGTkpLMJUuWmOvXrzevu+46My0tzSwvL7ewcjmRhqMZmKbOYST4/PPPTYfDYf72t781t27dar722mtmbGys+eqrrwa30XkMfzfffLPZt29f81//+pe5Y8cOc8mSJWZKSop53333BbfReQw/R44cMfPz8838/HwTMJ944gkzPz/f3LVrl2mazTtn06dPN/v162cuW7bM/PLLL80LLrjAHDlypOnxeNq8XoXZdvbss8+amZmZptPpNEePHh0c4knCE9Dk9Kc//Sm4jc/nM3/1q1+ZvXv3Nl0ul/m9733PXL9+vXVFy3c6NszqHEaG//u//zOHDx9uulwuc/Dgwebzzz8f8r7OY/grLy837777bjMjI8OMjo42TznlFHPOnDlmTU1NcBudx/Dz4YcfNvl/4c0332yaZvPOWVVVlXnXXXeZ3bt3N2NiYszLL7/cLCgoaJd6DdM0zbZv7xURERERaX/qMysiIiIiEUthVkREREQilsKsiIiIiEQshVkRERERiVgKsyIiIiISsRRmRURERCRiKcyKiIiISMRSmBUR6SI++ugjDMPg8OHDVpciItJmFGZFREREJGIpzIqIiIhIxFKYFRHpIKZp8uijj3LKKacQExPDyJEj+cc//gHUdwF4++23GTlyJNHR0YwdO5b169eHHGPx4sUMGzYMl8tF//79efzxx0Per6mp4b777iM9PR2Xy8XAgQN58cUXQ7bJy8tjzJgxxMbGMn78eDZv3hx8b926dZx//vkkJCSQmJhIdnY2X3zxRTv9REREWs9hdQEiIl3FL3/5S5YsWcLChQsZOHAgH3/8MTfeeCM9e/YMbnPvvffy5JNP0rt3bx544AGuuOIKtmzZQlRUFHl5eVx77bU8+OCDTJ06ldWrV/PTn/6UHj16cMsttwAwbdo0PvnkE5566ilGjhzJjh07KC0tDaljzpw5PP744/Ts2ZPp06dz6623smrVKgBuuOEGzjjjDBYuXIjdbmft2rVERUV12M9IRORkGaZpmlYXISLS2R09epSUlBQ++OADxo0bF1x/++23U1lZyR133MH555/PG2+8wdSpUwE4ePAg/fr14+WXX+baa6/lhhtuYP/+/bz//vvB/e+77z7efvttNmzYwJYtWxg0aBC5ublcdNFFjWr46KOPOP/881m2bBkXXnghAEuXLuWyyy6jqqqK6OhoEhMTefrpp7n55pvb+SciItI21M1ARKQDbNy4kerqai6++GLi4+OD0yuvvMK3334b3K5h0O3evTuDBg1i06ZNAGzatIkJEyaEHHfChAls3boVr9fL2rVrsdvtnHvuuSesZcSIEcHltLQ0AEpKSgCYNWsWt99+OxdddBGPPPJISG0iIuFIYVZEpAP4fD4A3n77bdauXRucNm7cGOw3ezyGYQD+PreB5YCGv1yLiYlpVi0Nuw0Ejheo78EHH2TDhg1cdtllfPDBBwwdOpQ333yzWccVEbGCwqyISAcYOnQoLpeLgoICBgwYEDKlp6cHt/v000+Dy4cOHWLLli0MHjw4eIyVK1eGHHf16tWcdtpp2O12Tj/9dHw+H8uXL29VraeddhozZ87k/fff5+qrr+ZPf/pTq44nItKedAOYiEgHSEhI4J577mHmzJn4fD7OOeccysvLWb16NfHx8WRmZgIwd+5cevToQWpqKnPmzCElJYWrrroKgP/6r//izDPP5Ne//jVTp07lk08+4ZlnnmHBggUA9O/fn5tvvplbb701eAPYrl27KCkp4dprr/3OGquqqrj33nu55ppryMrKYvfu3axZs4Yf/OAH7fZzERFpLYVZEZEO8utf/5pevXoxb948tm/fTnJyMqNHj+aBBx4I/pr/kUce4e6772br1q2MHDmSt956C6fTCcDo0aP529/+xn//93/z61//mrS0NObOnRscyQBg4cKFPPDAA/z0pz/lwIEDZGRk8MADDzSrPrvdzoEDB5g2bRr79u0jJSWFq6++moceeqjNfxYiIm1FoxmIiISBwEgDhw4dIjk52epyREQihvrMioiIiEjEUpgVERERkYilbgYiIiIiErHUMisiIiIiEUthVkREREQilsKsiIiIiEQshVkRERERiVgKsyIiIiISsRRmRURERCRiKcyKiIiISMRSmBURERGRiKUwKyIiIiIR6/8BEO9ppvV0IR8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0599c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba0b15cd",
   "metadata": {},
   "source": [
    "# EarlyStoppingìœ¼ë¡œ í•™ìŠµ ì¡°ê¸° ì¤‘ë‹¨ ë° ì €ìž¥í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2a0fd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "208fc024",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203efe11",
   "metadata": {},
   "source": [
    "# ModelCheckpoint\n",
    "* ëª¨ë¸ì„ ì¤‘ê°„ì— ì €ìž¥í•˜ëŠ” ì˜µì…˜ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "329263ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /model created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./model\"):\n",
    "    os.makedirs(\"./model\")\n",
    "    print(f\"Directory /model created.\")\n",
    "else:\n",
    "    print(f\"Directory /model already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b1013c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = \"./model/{epoch:03d}--{val_loss:.4f}.keras\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=0, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "278f2f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0102 - accuracy: 0.9982 - val_loss: 0.0308 - val_accuracy: 0.9946\n",
      "Epoch 2/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0101 - accuracy: 0.9985 - val_loss: 0.0308 - val_accuracy: 0.9946\n",
      "Epoch 3/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0101 - accuracy: 0.9985 - val_loss: 0.0305 - val_accuracy: 0.9946\n",
      "Epoch 4/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0100 - accuracy: 0.9985 - val_loss: 0.0306 - val_accuracy: 0.9946\n",
      "Epoch 5/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0099 - accuracy: 0.9985 - val_loss: 0.0309 - val_accuracy: 0.9946\n",
      "Epoch 6/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0098 - accuracy: 0.9985 - val_loss: 0.0307 - val_accuracy: 0.9946\n",
      "Epoch 7/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0097 - accuracy: 0.9985 - val_loss: 0.0308 - val_accuracy: 0.9946\n",
      "Epoch 8/1000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0096 - accuracy: 0.9985 - val_loss: 0.0305 - val_accuracy: 0.9946\n",
      "Epoch 9/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0095 - accuracy: 0.9985 - val_loss: 0.0308 - val_accuracy: 0.9946\n",
      "Epoch 10/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0094 - accuracy: 0.9985 - val_loss: 0.0307 - val_accuracy: 0.9946\n",
      "Epoch 11/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0094 - accuracy: 0.9985 - val_loss: 0.0308 - val_accuracy: 0.9946\n",
      "Epoch 12/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0093 - accuracy: 0.9985 - val_loss: 0.0306 - val_accuracy: 0.9946\n",
      "Epoch 13/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0092 - accuracy: 0.9985 - val_loss: 0.0308 - val_accuracy: 0.9946\n",
      "Epoch 14/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0091 - accuracy: 0.9985 - val_loss: 0.0307 - val_accuracy: 0.9946\n",
      "Epoch 15/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0090 - accuracy: 0.9985 - val_loss: 0.0308 - val_accuracy: 0.9946\n",
      "Epoch 16/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0090 - accuracy: 0.9985 - val_loss: 0.0310 - val_accuracy: 0.9946\n",
      "Epoch 17/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0089 - accuracy: 0.9985 - val_loss: 0.0307 - val_accuracy: 0.9946\n",
      "Epoch 18/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0088 - accuracy: 0.9985 - val_loss: 0.0308 - val_accuracy: 0.9946\n",
      "Epoch 19/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0087 - accuracy: 0.9985 - val_loss: 0.0308 - val_accuracy: 0.9946\n",
      "Epoch 20/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0086 - accuracy: 0.9985 - val_loss: 0.0309 - val_accuracy: 0.9946\n",
      "Epoch 21/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0086 - accuracy: 0.9985 - val_loss: 0.0309 - val_accuracy: 0.9946\n",
      "Epoch 22/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0085 - accuracy: 0.9985 - val_loss: 0.0307 - val_accuracy: 0.9946\n",
      "Epoch 23/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0084 - accuracy: 0.9985 - val_loss: 0.0309 - val_accuracy: 0.9946\n",
      "Epoch 24/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0083 - accuracy: 0.9985 - val_loss: 0.0309 - val_accuracy: 0.9946\n",
      "Epoch 25/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0083 - accuracy: 0.9985 - val_loss: 0.0308 - val_accuracy: 0.9946\n",
      "Epoch 26/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0082 - accuracy: 0.9985 - val_loss: 0.0309 - val_accuracy: 0.9946\n",
      "Epoch 27/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 0.0310 - val_accuracy: 0.9946\n",
      "Epoch 28/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 0.0311 - val_accuracy: 0.9946\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=1000, batch_size=500, validation_data=(X_valid,y_valid),\n",
    "                   callbacks=[early_stopping_callback, checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4982ee19",
   "metadata": {},
   "source": [
    "# ì €ìž¥ëœ ë² ìŠ¤íŠ¸ ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ì„œ í…ŒìŠ¤íŠ¸ í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "925bf893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6464c3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = load_model(\"./model/008--0.0305.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4019b74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       980\n",
      "           1       1.00      0.99      0.99       320\n",
      "\n",
      "    accuracy                           1.00      1300\n",
      "   macro avg       1.00      0.99      1.00      1300\n",
      "weighted avg       1.00      1.00      1.00      1300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 11:31:52.480387: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "best_pred = best_model.predict(X_test)\n",
    "best_pred = pd.DataFrame(best_pred)\n",
    "best_pred = best_pred[0].apply(lambda x: 1 if x>0.5 else 0)\n",
    "print(classification_report(y_test,best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b0930c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d42373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a09ef8f",
   "metadata": {},
   "source": [
    "# ë‹¤ì¤‘ë¶„ë¥˜ ì™€ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8e75bcc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = pd.read_csv(\"../06machine_learning/data/winequality-white.csv\", sep=\";\")\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4098af33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4898 entries, 0 to 4897\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         4898 non-null   float64\n",
      " 1   volatile acidity      4898 non-null   float64\n",
      " 2   citric acid           4898 non-null   float64\n",
      " 3   residual sugar        4898 non-null   float64\n",
      " 4   chlorides             4898 non-null   float64\n",
      " 5   free sulfur dioxide   4898 non-null   float64\n",
      " 6   total sulfur dioxide  4898 non-null   float64\n",
      " 7   density               4898 non-null   float64\n",
      " 8   pH                    4898 non-null   float64\n",
      " 9   sulphates             4898 non-null   float64\n",
      " 10  alcohol               4898 non-null   float64\n",
      " 11  quality               4898 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 459.3 KB\n"
     ]
    }
   ],
   "source": [
    "wine.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "449b3fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quality\n",
       "6    2198\n",
       "5    1457\n",
       "7     880\n",
       "8     175\n",
       "4     163\n",
       "3      20\n",
       "9       5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bdd61f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wine.drop('quality', axis=1)\n",
    "y = wine['quality'].copy()\n",
    "y2 = wine['quality'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c28c8804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6\n",
       "1    6\n",
       "2    6\n",
       "3    6\n",
       "4    6\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f0e89092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6f5edf81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2       ,  0.09090909,  0.33333333, ..., -0.94736842,\n",
       "        -0.14285714, -0.84210526],\n",
       "       [-0.5       ,  0.36363636,  0.16666667, ...,  0.63157895,\n",
       "         0.14285714, -0.47368421],\n",
       "       [ 1.3       ,  0.18181818,  0.66666667, ...,  0.42105263,\n",
       "        -0.21428571, -0.15789474],\n",
       "       ...,\n",
       "       [-0.3       , -0.18181818, -1.08333333, ..., -1.        ,\n",
       "        -0.07142857, -0.52631579],\n",
       "       [-1.3       ,  0.27272727, -0.16666667, ...,  0.84210526,\n",
       "        -0.64285714,  1.26315789],\n",
       "       [-0.8       , -0.45454545,  0.5       , ...,  0.42105263,\n",
       "        -1.07142857,  0.73684211]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbs = RobustScaler()\n",
    "X_scaled = rbs.fit_transform(X)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e804fe02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          3      4      5      6      7      8      9\n",
       "0     False  False  False   True  False  False  False\n",
       "1     False  False  False   True  False  False  False\n",
       "2     False  False  False   True  False  False  False\n",
       "3     False  False  False   True  False  False  False\n",
       "4     False  False  False   True  False  False  False\n",
       "...     ...    ...    ...    ...    ...    ...    ...\n",
       "4893  False  False  False   True  False  False  False\n",
       "4894  False  False   True  False  False  False  False\n",
       "4895  False  False  False   True  False  False  False\n",
       "4896  False  False  False  False   True  False  False\n",
       "4897  False  False  False   True  False  False  False\n",
       "\n",
       "[4898 rows x 7 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fbfc9165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "60dce253",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_scaled, y ,test_size=0.4 , stratify=y,random_state=10)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.5,stratify=y_valid, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0e0ed639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4654cf9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 32)                384       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,223\n",
      "Trainable params: 5,223\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d9c9e3c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "1/6 [====>.........................] - ETA: 2s - loss: 2.0112 - accuracy: 0.0940"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 14:21:51.031377: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-10 14:21:51.088249: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 14:21:51.088311: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 56ms/step - loss: 1.9776 - accuracy: 0.1304 - val_loss: 1.9364 - val_accuracy: 0.1867\n",
      "Epoch 2/10000\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.9185 - accuracy: 0.2127"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 14:21:51.328778: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-10 14:21:51.356697: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 14:21:51.356762: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 34ms/step - loss: 1.9185 - accuracy: 0.2127 - val_loss: 1.8962 - val_accuracy: 0.2286\n",
      "Epoch 3/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.8760 - accuracy: 0.2594 - val_loss: 1.8539 - val_accuracy: 0.2245\n",
      "Epoch 4/10000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 1.8235 - accuracy: 0.2914 - val_loss: 1.7942 - val_accuracy: 0.2857\n",
      "Epoch 5/10000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 1.7478 - accuracy: 0.3468 - val_loss: 1.7022 - val_accuracy: 0.3847\n",
      "Epoch 6/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.6332 - accuracy: 0.4551 - val_loss: 1.5697 - val_accuracy: 0.4643\n",
      "Epoch 7/10000\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 1.4992 - accuracy: 0.4942 - val_loss: 1.4557 - val_accuracy: 0.4816\n",
      "Epoch 8/10000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 1.3952 - accuracy: 0.5000 - val_loss: 1.3875 - val_accuracy: 0.4786\n",
      "Epoch 9/10000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 1.3367 - accuracy: 0.5092 - val_loss: 1.3480 - val_accuracy: 0.4847\n",
      "Epoch 10/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.2976 - accuracy: 0.5088 - val_loss: 1.3155 - val_accuracy: 0.4857\n",
      "Epoch 11/10000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 1.2680 - accuracy: 0.5133 - val_loss: 1.2940 - val_accuracy: 0.4908\n",
      "Epoch 12/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.2471 - accuracy: 0.5204 - val_loss: 1.2789 - val_accuracy: 0.4929\n",
      "Epoch 13/10000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 1.2293 - accuracy: 0.5255 - val_loss: 1.2646 - val_accuracy: 0.5173\n",
      "Epoch 14/10000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 1.2127 - accuracy: 0.5317 - val_loss: 1.2524 - val_accuracy: 0.5153\n",
      "Epoch 15/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.1985 - accuracy: 0.5354 - val_loss: 1.2408 - val_accuracy: 0.5092\n",
      "Epoch 16/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.1862 - accuracy: 0.5361 - val_loss: 1.2284 - val_accuracy: 0.5204\n",
      "Epoch 17/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.1726 - accuracy: 0.5412 - val_loss: 1.2179 - val_accuracy: 0.5204\n",
      "Epoch 18/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.1607 - accuracy: 0.5477 - val_loss: 1.2070 - val_accuracy: 0.5276\n",
      "Epoch 19/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.1501 - accuracy: 0.5436 - val_loss: 1.1988 - val_accuracy: 0.5204\n",
      "Epoch 20/10000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 1.1393 - accuracy: 0.5517 - val_loss: 1.1887 - val_accuracy: 0.5286\n",
      "Epoch 21/10000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 1.1292 - accuracy: 0.5528 - val_loss: 1.1802 - val_accuracy: 0.5255\n",
      "Epoch 22/10000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 1.1192 - accuracy: 0.5568 - val_loss: 1.1711 - val_accuracy: 0.5276\n",
      "Epoch 23/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.1106 - accuracy: 0.5568 - val_loss: 1.1632 - val_accuracy: 0.5316\n",
      "Epoch 24/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.1029 - accuracy: 0.5558 - val_loss: 1.1553 - val_accuracy: 0.5367\n",
      "Epoch 25/10000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 1.0936 - accuracy: 0.5589 - val_loss: 1.1504 - val_accuracy: 0.5418\n",
      "Epoch 26/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.0869 - accuracy: 0.5562 - val_loss: 1.1422 - val_accuracy: 0.5347\n",
      "Epoch 27/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.0788 - accuracy: 0.5626 - val_loss: 1.1342 - val_accuracy: 0.5449\n",
      "Epoch 28/10000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.0706 - accuracy: 0.5660 - val_loss: 1.1278 - val_accuracy: 0.5378\n",
      "Epoch 29/10000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 1.0648 - accuracy: 0.5602 - val_loss: 1.1208 - val_accuracy: 0.5439\n",
      "Epoch 30/10000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 1.0590 - accuracy: 0.5718 - val_loss: 1.1156 - val_accuracy: 0.5510\n",
      "Epoch 31/10000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 1.0518 - accuracy: 0.5684 - val_loss: 1.1125 - val_accuracy: 0.5418\n",
      "Epoch 32/10000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 1.0454 - accuracy: 0.5684 - val_loss: 1.1053 - val_accuracy: 0.5459\n",
      "Epoch 33/10000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 1.0390 - accuracy: 0.5779 - val_loss: 1.1010 - val_accuracy: 0.5429\n",
      "Epoch 34/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.0358 - accuracy: 0.5718 - val_loss: 1.0944 - val_accuracy: 0.5459\n",
      "Epoch 35/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.0293 - accuracy: 0.5776 - val_loss: 1.0917 - val_accuracy: 0.5490\n",
      "Epoch 36/10000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 1.0239 - accuracy: 0.5742 - val_loss: 1.0888 - val_accuracy: 0.5469\n",
      "Epoch 37/10000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 1.0193 - accuracy: 0.5800 - val_loss: 1.0845 - val_accuracy: 0.5531\n",
      "Epoch 38/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.0156 - accuracy: 0.5786 - val_loss: 1.0805 - val_accuracy: 0.5571\n",
      "Epoch 39/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.0134 - accuracy: 0.5813 - val_loss: 1.0778 - val_accuracy: 0.5500\n",
      "Epoch 40/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.0081 - accuracy: 0.5841 - val_loss: 1.0756 - val_accuracy: 0.5541\n",
      "Epoch 41/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.0032 - accuracy: 0.5817 - val_loss: 1.0739 - val_accuracy: 0.5541\n",
      "Epoch 42/10000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.9982 - accuracy: 0.5892 - val_loss: 1.0716 - val_accuracy: 0.5541\n",
      "Epoch 43/10000\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.9960 - accuracy: 0.5916 - val_loss: 1.0691 - val_accuracy: 0.5541\n",
      "Epoch 44/10000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.9906 - accuracy: 0.5977 - val_loss: 1.0677 - val_accuracy: 0.5612\n",
      "Epoch 45/10000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.9868 - accuracy: 0.6001 - val_loss: 1.0658 - val_accuracy: 0.5622\n",
      "Epoch 46/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.9826 - accuracy: 0.6021 - val_loss: 1.0648 - val_accuracy: 0.5571\n",
      "Epoch 47/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.9787 - accuracy: 0.5994 - val_loss: 1.0631 - val_accuracy: 0.5673\n",
      "Epoch 48/10000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.9749 - accuracy: 0.6007 - val_loss: 1.0610 - val_accuracy: 0.5571\n",
      "Epoch 49/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.9717 - accuracy: 0.6038 - val_loss: 1.0587 - val_accuracy: 0.5633\n",
      "Epoch 50/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.9685 - accuracy: 0.6035 - val_loss: 1.0595 - val_accuracy: 0.5592\n",
      "Epoch 51/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.9642 - accuracy: 0.6038 - val_loss: 1.0574 - val_accuracy: 0.5612\n",
      "Epoch 52/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.9603 - accuracy: 0.6048 - val_loss: 1.0559 - val_accuracy: 0.5592\n",
      "Epoch 53/10000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.9568 - accuracy: 0.6076 - val_loss: 1.0550 - val_accuracy: 0.5633\n",
      "Epoch 54/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.9540 - accuracy: 0.6113 - val_loss: 1.0545 - val_accuracy: 0.5612\n",
      "Epoch 55/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.9508 - accuracy: 0.6093 - val_loss: 1.0523 - val_accuracy: 0.5612\n",
      "Epoch 56/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.9461 - accuracy: 0.6137 - val_loss: 1.0515 - val_accuracy: 0.5622\n",
      "Epoch 57/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.9431 - accuracy: 0.6147 - val_loss: 1.0517 - val_accuracy: 0.5582\n",
      "Epoch 58/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.9406 - accuracy: 0.6127 - val_loss: 1.0494 - val_accuracy: 0.5612\n",
      "Epoch 59/10000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.9383 - accuracy: 0.6188 - val_loss: 1.0482 - val_accuracy: 0.5571\n",
      "Epoch 60/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.9379 - accuracy: 0.6198 - val_loss: 1.0482 - val_accuracy: 0.5602\n",
      "Epoch 61/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.9358 - accuracy: 0.6133 - val_loss: 1.0532 - val_accuracy: 0.5531\n",
      "Epoch 62/10000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.9320 - accuracy: 0.6195 - val_loss: 1.0469 - val_accuracy: 0.5602\n",
      "Epoch 63/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.9256 - accuracy: 0.6201 - val_loss: 1.0477 - val_accuracy: 0.5520\n",
      "Epoch 64/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.9262 - accuracy: 0.6259 - val_loss: 1.0446 - val_accuracy: 0.5541\n",
      "Epoch 65/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.9189 - accuracy: 0.6195 - val_loss: 1.0467 - val_accuracy: 0.5520\n",
      "Epoch 66/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.9156 - accuracy: 0.6256 - val_loss: 1.0393 - val_accuracy: 0.5541\n",
      "Epoch 67/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.9139 - accuracy: 0.6246 - val_loss: 1.0408 - val_accuracy: 0.5561\n",
      "Epoch 68/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.9097 - accuracy: 0.6263 - val_loss: 1.0398 - val_accuracy: 0.5541\n",
      "Epoch 69/10000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.9059 - accuracy: 0.6324 - val_loss: 1.0423 - val_accuracy: 0.5541\n",
      "Epoch 70/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.9028 - accuracy: 0.6351 - val_loss: 1.0371 - val_accuracy: 0.5541\n",
      "Epoch 71/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8986 - accuracy: 0.6378 - val_loss: 1.0382 - val_accuracy: 0.5520\n",
      "Epoch 72/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8961 - accuracy: 0.6355 - val_loss: 1.0396 - val_accuracy: 0.5531\n",
      "Epoch 73/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8927 - accuracy: 0.6382 - val_loss: 1.0401 - val_accuracy: 0.5531\n",
      "Epoch 74/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8900 - accuracy: 0.6368 - val_loss: 1.0379 - val_accuracy: 0.5520\n",
      "Epoch 75/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8866 - accuracy: 0.6433 - val_loss: 1.0374 - val_accuracy: 0.5531\n",
      "Epoch 76/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8840 - accuracy: 0.6413 - val_loss: 1.0409 - val_accuracy: 0.5469\n",
      "Epoch 77/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8817 - accuracy: 0.6450 - val_loss: 1.0398 - val_accuracy: 0.5551\n",
      "Epoch 78/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8794 - accuracy: 0.6457 - val_loss: 1.0426 - val_accuracy: 0.5541\n",
      "Epoch 79/10000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.8768 - accuracy: 0.6477 - val_loss: 1.0358 - val_accuracy: 0.5510\n",
      "Epoch 80/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8761 - accuracy: 0.6443 - val_loss: 1.0394 - val_accuracy: 0.5531\n",
      "Epoch 81/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8709 - accuracy: 0.6457 - val_loss: 1.0369 - val_accuracy: 0.5480\n",
      "Epoch 82/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8705 - accuracy: 0.6487 - val_loss: 1.0378 - val_accuracy: 0.5500\n",
      "Epoch 83/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8674 - accuracy: 0.6521 - val_loss: 1.0388 - val_accuracy: 0.5541\n",
      "Epoch 84/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8672 - accuracy: 0.6430 - val_loss: 1.0375 - val_accuracy: 0.5520\n",
      "Epoch 85/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8656 - accuracy: 0.6430 - val_loss: 1.0467 - val_accuracy: 0.5500\n",
      "Epoch 86/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8595 - accuracy: 0.6555 - val_loss: 1.0362 - val_accuracy: 0.5531\n",
      "Epoch 87/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8559 - accuracy: 0.6613 - val_loss: 1.0387 - val_accuracy: 0.5592\n",
      "Epoch 88/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.8531 - accuracy: 0.6590 - val_loss: 1.0355 - val_accuracy: 0.5592\n",
      "Epoch 89/10000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.8515 - accuracy: 0.6600 - val_loss: 1.0381 - val_accuracy: 0.5500\n",
      "Epoch 90/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8486 - accuracy: 0.6617 - val_loss: 1.0444 - val_accuracy: 0.5541\n",
      "Epoch 91/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8485 - accuracy: 0.6600 - val_loss: 1.0411 - val_accuracy: 0.5541\n",
      "Epoch 92/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8441 - accuracy: 0.6637 - val_loss: 1.0385 - val_accuracy: 0.5520\n",
      "Epoch 93/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8414 - accuracy: 0.6607 - val_loss: 1.0364 - val_accuracy: 0.5571\n",
      "Epoch 94/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8386 - accuracy: 0.6647 - val_loss: 1.0375 - val_accuracy: 0.5531\n",
      "Epoch 95/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8378 - accuracy: 0.6634 - val_loss: 1.0443 - val_accuracy: 0.5520\n",
      "Epoch 96/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8353 - accuracy: 0.6651 - val_loss: 1.0432 - val_accuracy: 0.5612\n",
      "Epoch 97/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8322 - accuracy: 0.6685 - val_loss: 1.0419 - val_accuracy: 0.5520\n",
      "Epoch 98/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.8293 - accuracy: 0.6692 - val_loss: 1.0440 - val_accuracy: 0.5592\n",
      "Epoch 99/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8262 - accuracy: 0.6692 - val_loss: 1.0427 - val_accuracy: 0.5541\n",
      "Epoch 100/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.8248 - accuracy: 0.6712 - val_loss: 1.0441 - val_accuracy: 0.5531\n",
      "Epoch 101/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8254 - accuracy: 0.6719 - val_loss: 1.0439 - val_accuracy: 0.5561\n",
      "Epoch 102/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.8243 - accuracy: 0.6702 - val_loss: 1.0493 - val_accuracy: 0.5561\n",
      "Epoch 103/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8171 - accuracy: 0.6692 - val_loss: 1.0406 - val_accuracy: 0.5612\n",
      "Epoch 104/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8133 - accuracy: 0.6807 - val_loss: 1.0462 - val_accuracy: 0.5520\n",
      "Epoch 105/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8113 - accuracy: 0.6753 - val_loss: 1.0456 - val_accuracy: 0.5561\n",
      "Epoch 106/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8097 - accuracy: 0.6784 - val_loss: 1.0465 - val_accuracy: 0.5571\n",
      "Epoch 107/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8057 - accuracy: 0.6784 - val_loss: 1.0454 - val_accuracy: 0.5551\n",
      "Epoch 108/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8044 - accuracy: 0.6804 - val_loss: 1.0469 - val_accuracy: 0.5653\n",
      "Epoch 109/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8037 - accuracy: 0.6784 - val_loss: 1.0512 - val_accuracy: 0.5582\n",
      "Epoch 110/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8010 - accuracy: 0.6814 - val_loss: 1.0512 - val_accuracy: 0.5612\n",
      "Epoch 111/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8004 - accuracy: 0.6845 - val_loss: 1.0482 - val_accuracy: 0.5612\n",
      "Epoch 112/10000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.7974 - accuracy: 0.6865 - val_loss: 1.0518 - val_accuracy: 0.5602\n",
      "Epoch 113/10000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.7919 - accuracy: 0.6852 - val_loss: 1.0489 - val_accuracy: 0.5571\n",
      "Epoch 114/10000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7904 - accuracy: 0.6879 - val_loss: 1.0546 - val_accuracy: 0.5633\n",
      "Epoch 115/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7884 - accuracy: 0.6903 - val_loss: 1.0486 - val_accuracy: 0.5592\n",
      "Epoch 116/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7860 - accuracy: 0.6865 - val_loss: 1.0484 - val_accuracy: 0.5592\n",
      "Epoch 117/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7855 - accuracy: 0.6886 - val_loss: 1.0571 - val_accuracy: 0.5633\n",
      "Epoch 118/10000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.7852 - accuracy: 0.6886 - val_loss: 1.0560 - val_accuracy: 0.5622\n",
      "Epoch 119/10000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7815 - accuracy: 0.6882 - val_loss: 1.0589 - val_accuracy: 0.5622\n",
      "Epoch 120/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.7783 - accuracy: 0.6903 - val_loss: 1.0555 - val_accuracy: 0.5551\n",
      "Epoch 121/10000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.7752 - accuracy: 0.6916 - val_loss: 1.0575 - val_accuracy: 0.5653\n",
      "Epoch 122/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7717 - accuracy: 0.7001 - val_loss: 1.0635 - val_accuracy: 0.5612\n",
      "Epoch 123/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7709 - accuracy: 0.6964 - val_loss: 1.0546 - val_accuracy: 0.5684\n",
      "Epoch 124/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7689 - accuracy: 0.6947 - val_loss: 1.0601 - val_accuracy: 0.5622\n",
      "Epoch 125/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.7678 - accuracy: 0.7032 - val_loss: 1.0624 - val_accuracy: 0.5684\n",
      "Epoch 126/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.7670 - accuracy: 0.6950 - val_loss: 1.0729 - val_accuracy: 0.5541\n",
      "Epoch 127/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7664 - accuracy: 0.6923 - val_loss: 1.0581 - val_accuracy: 0.5694\n",
      "Epoch 128/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7637 - accuracy: 0.7001 - val_loss: 1.0715 - val_accuracy: 0.5755\n",
      "Epoch 129/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7672 - accuracy: 0.6978 - val_loss: 1.0789 - val_accuracy: 0.5541\n",
      "Epoch 130/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.7613 - accuracy: 0.6981 - val_loss: 1.0755 - val_accuracy: 0.5714\n",
      "Epoch 131/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7584 - accuracy: 0.7052 - val_loss: 1.0666 - val_accuracy: 0.5704\n",
      "Epoch 132/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7520 - accuracy: 0.7080 - val_loss: 1.0800 - val_accuracy: 0.5653\n",
      "Epoch 133/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7507 - accuracy: 0.7039 - val_loss: 1.0668 - val_accuracy: 0.5714\n",
      "Epoch 134/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7498 - accuracy: 0.7049 - val_loss: 1.0839 - val_accuracy: 0.5694\n",
      "Epoch 135/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7493 - accuracy: 0.7086 - val_loss: 1.0728 - val_accuracy: 0.5643\n",
      "Epoch 136/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7456 - accuracy: 0.7076 - val_loss: 1.0716 - val_accuracy: 0.5735\n",
      "Epoch 137/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7411 - accuracy: 0.7107 - val_loss: 1.0696 - val_accuracy: 0.5704\n",
      "Epoch 138/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.7443 - accuracy: 0.7120 - val_loss: 1.0765 - val_accuracy: 0.5673\n",
      "Epoch 139/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.7407 - accuracy: 0.7052 - val_loss: 1.0862 - val_accuracy: 0.5622\n",
      "Epoch 140/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7367 - accuracy: 0.7168 - val_loss: 1.0716 - val_accuracy: 0.5694\n",
      "Epoch 141/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7338 - accuracy: 0.7134 - val_loss: 1.0790 - val_accuracy: 0.5745\n",
      "Epoch 142/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7343 - accuracy: 0.7155 - val_loss: 1.0868 - val_accuracy: 0.5663\n",
      "Epoch 143/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.7290 - accuracy: 0.7199 - val_loss: 1.0799 - val_accuracy: 0.5673\n",
      "Epoch 144/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7290 - accuracy: 0.7124 - val_loss: 1.0875 - val_accuracy: 0.5755\n",
      "Epoch 145/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7282 - accuracy: 0.7131 - val_loss: 1.0796 - val_accuracy: 0.5684\n",
      "Epoch 146/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.7268 - accuracy: 0.7175 - val_loss: 1.0840 - val_accuracy: 0.5663\n",
      "Epoch 147/10000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7223 - accuracy: 0.7206 - val_loss: 1.0893 - val_accuracy: 0.5704\n",
      "Epoch 148/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.7202 - accuracy: 0.7229 - val_loss: 1.0819 - val_accuracy: 0.5714\n",
      "Epoch 149/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7172 - accuracy: 0.7240 - val_loss: 1.0901 - val_accuracy: 0.5724\n",
      "Epoch 150/10000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.7193 - accuracy: 0.7161 - val_loss: 1.0962 - val_accuracy: 0.5653\n",
      "Epoch 151/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7172 - accuracy: 0.7212 - val_loss: 1.0960 - val_accuracy: 0.5653\n",
      "Epoch 152/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7158 - accuracy: 0.7243 - val_loss: 1.0982 - val_accuracy: 0.5786\n",
      "Epoch 153/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.7152 - accuracy: 0.7243 - val_loss: 1.0900 - val_accuracy: 0.5622\n",
      "Epoch 154/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7104 - accuracy: 0.7240 - val_loss: 1.1034 - val_accuracy: 0.5745\n",
      "Epoch 155/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7072 - accuracy: 0.7270 - val_loss: 1.0925 - val_accuracy: 0.5684\n",
      "Epoch 156/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7044 - accuracy: 0.7291 - val_loss: 1.1040 - val_accuracy: 0.5653\n",
      "Epoch 157/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7031 - accuracy: 0.7308 - val_loss: 1.1029 - val_accuracy: 0.5673\n",
      "Epoch 158/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6997 - accuracy: 0.7311 - val_loss: 1.1002 - val_accuracy: 0.5684\n",
      "Epoch 159/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6999 - accuracy: 0.7311 - val_loss: 1.1004 - val_accuracy: 0.5684\n",
      "Epoch 160/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6962 - accuracy: 0.7352 - val_loss: 1.1102 - val_accuracy: 0.5663\n",
      "Epoch 161/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6949 - accuracy: 0.7369 - val_loss: 1.1038 - val_accuracy: 0.5663\n",
      "Epoch 162/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6940 - accuracy: 0.7301 - val_loss: 1.1212 - val_accuracy: 0.5684\n",
      "Epoch 163/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6942 - accuracy: 0.7349 - val_loss: 1.1089 - val_accuracy: 0.5643\n",
      "Epoch 164/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6923 - accuracy: 0.7308 - val_loss: 1.1195 - val_accuracy: 0.5673\n",
      "Epoch 165/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.6909 - accuracy: 0.7335 - val_loss: 1.1095 - val_accuracy: 0.5663\n",
      "Epoch 166/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6860 - accuracy: 0.7430 - val_loss: 1.1144 - val_accuracy: 0.5673\n",
      "Epoch 167/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6869 - accuracy: 0.7362 - val_loss: 1.1166 - val_accuracy: 0.5694\n",
      "Epoch 168/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6818 - accuracy: 0.7413 - val_loss: 1.1163 - val_accuracy: 0.5735\n",
      "Epoch 169/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6818 - accuracy: 0.7427 - val_loss: 1.1185 - val_accuracy: 0.5704\n",
      "Epoch 170/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6777 - accuracy: 0.7417 - val_loss: 1.1182 - val_accuracy: 0.5704\n",
      "Epoch 171/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6791 - accuracy: 0.7423 - val_loss: 1.1222 - val_accuracy: 0.5653\n",
      "Epoch 172/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6756 - accuracy: 0.7447 - val_loss: 1.1458 - val_accuracy: 0.5531\n",
      "Epoch 173/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6811 - accuracy: 0.7369 - val_loss: 1.1328 - val_accuracy: 0.5724\n",
      "Epoch 174/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6723 - accuracy: 0.7485 - val_loss: 1.1204 - val_accuracy: 0.5643\n",
      "Epoch 175/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6689 - accuracy: 0.7488 - val_loss: 1.1302 - val_accuracy: 0.5745\n",
      "Epoch 176/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6679 - accuracy: 0.7491 - val_loss: 1.1484 - val_accuracy: 0.5714\n",
      "Epoch 177/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6685 - accuracy: 0.7509 - val_loss: 1.1336 - val_accuracy: 0.5704\n",
      "Epoch 178/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6662 - accuracy: 0.7440 - val_loss: 1.1351 - val_accuracy: 0.5673\n",
      "Epoch 179/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6629 - accuracy: 0.7515 - val_loss: 1.1296 - val_accuracy: 0.5684\n",
      "Epoch 180/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6593 - accuracy: 0.7515 - val_loss: 1.1437 - val_accuracy: 0.5694\n",
      "Epoch 181/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6561 - accuracy: 0.7539 - val_loss: 1.1375 - val_accuracy: 0.5714\n",
      "Epoch 182/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6562 - accuracy: 0.7536 - val_loss: 1.1342 - val_accuracy: 0.5684\n",
      "Epoch 183/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6563 - accuracy: 0.7515 - val_loss: 1.1425 - val_accuracy: 0.5714\n",
      "Epoch 184/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6561 - accuracy: 0.7553 - val_loss: 1.1446 - val_accuracy: 0.5724\n",
      "Epoch 185/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6533 - accuracy: 0.7560 - val_loss: 1.1418 - val_accuracy: 0.5694\n",
      "Epoch 186/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6533 - accuracy: 0.7491 - val_loss: 1.1551 - val_accuracy: 0.5704\n",
      "Epoch 187/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6521 - accuracy: 0.7539 - val_loss: 1.1514 - val_accuracy: 0.5694\n",
      "Epoch 188/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6474 - accuracy: 0.7628 - val_loss: 1.1426 - val_accuracy: 0.5571\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "early_stop = EarlyStopping(patience=100)\n",
    "filepath=\"/model/white_wine{epoch:04d}__{val_loss:.4f}.keras\"\n",
    "model_save = ModelCheckpoint(filepath=filepath, save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10000, batch_size=500, validation_data=(X_valid,y_valid), \n",
    "                    callbacks=[early_stop,model_save])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "840c30bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 14:30:06.908372: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "wine_best_model = load_model(\"./model/white_wine0088__1.0355.keras\")\n",
    "wine_pred = wine_best_model.predict(X_test)\n",
    "wine_pred = pd.DataFrame(wine_pred,columns=y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6471b6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004084</td>\n",
       "      <td>0.008073</td>\n",
       "      <td>0.098135</td>\n",
       "      <td>0.768133</td>\n",
       "      <td>0.114346</td>\n",
       "      <td>0.006879</td>\n",
       "      <td>0.000351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005688</td>\n",
       "      <td>0.006195</td>\n",
       "      <td>0.036908</td>\n",
       "      <td>0.650371</td>\n",
       "      <td>0.241850</td>\n",
       "      <td>0.057538</td>\n",
       "      <td>0.001449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004882</td>\n",
       "      <td>0.046232</td>\n",
       "      <td>0.316800</td>\n",
       "      <td>0.583672</td>\n",
       "      <td>0.043409</td>\n",
       "      <td>0.004383</td>\n",
       "      <td>0.000622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.009459</td>\n",
       "      <td>0.120742</td>\n",
       "      <td>0.602630</td>\n",
       "      <td>0.257367</td>\n",
       "      <td>0.008471</td>\n",
       "      <td>0.000245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001173</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.099251</td>\n",
       "      <td>0.722725</td>\n",
       "      <td>0.154535</td>\n",
       "      <td>0.019342</td>\n",
       "      <td>0.000401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>0.013026</td>\n",
       "      <td>0.107886</td>\n",
       "      <td>0.431916</td>\n",
       "      <td>0.387267</td>\n",
       "      <td>0.033966</td>\n",
       "      <td>0.022703</td>\n",
       "      <td>0.003237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>0.003376</td>\n",
       "      <td>0.738663</td>\n",
       "      <td>0.239338</td>\n",
       "      <td>0.016705</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>0.007724</td>\n",
       "      <td>0.017328</td>\n",
       "      <td>0.276579</td>\n",
       "      <td>0.608933</td>\n",
       "      <td>0.081704</td>\n",
       "      <td>0.007083</td>\n",
       "      <td>0.000649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>0.007076</td>\n",
       "      <td>0.039315</td>\n",
       "      <td>0.378750</td>\n",
       "      <td>0.525649</td>\n",
       "      <td>0.039306</td>\n",
       "      <td>0.008688</td>\n",
       "      <td>0.001217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>0.004965</td>\n",
       "      <td>0.018305</td>\n",
       "      <td>0.379414</td>\n",
       "      <td>0.517208</td>\n",
       "      <td>0.073082</td>\n",
       "      <td>0.006027</td>\n",
       "      <td>0.000999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>980 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6\n",
       "0    0.004084  0.008073  0.098135  0.768133  0.114346  0.006879  0.000351\n",
       "1    0.005688  0.006195  0.036908  0.650371  0.241850  0.057538  0.001449\n",
       "2    0.004882  0.046232  0.316800  0.583672  0.043409  0.004383  0.000622\n",
       "3    0.001086  0.009459  0.120742  0.602630  0.257367  0.008471  0.000245\n",
       "4    0.001173  0.002574  0.099251  0.722725  0.154535  0.019342  0.000401\n",
       "..        ...       ...       ...       ...       ...       ...       ...\n",
       "975  0.013026  0.107886  0.431916  0.387267  0.033966  0.022703  0.003237\n",
       "976  0.003376  0.738663  0.239338  0.016705  0.001549  0.000226  0.000143\n",
       "977  0.007724  0.017328  0.276579  0.608933  0.081704  0.007083  0.000649\n",
       "978  0.007076  0.039315  0.378750  0.525649  0.039306  0.008688  0.001217\n",
       "979  0.004965  0.018305  0.379414  0.517208  0.073082  0.006027  0.000999\n",
       "\n",
       "[980 rows x 7 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b7a132ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      6\n",
       "1      6\n",
       "2      6\n",
       "3      6\n",
       "4      6\n",
       "      ..\n",
       "975    5\n",
       "976    4\n",
       "977    6\n",
       "978    6\n",
       "979    6\n",
       "Length: 980, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_pred_class=wine_pred.idxmax(axis=1)\n",
    "wine_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9b572428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          3      4      5      6      7      8      9\n",
       "0     False  False  False   True  False  False  False\n",
       "1     False  False  False   True  False  False  False\n",
       "2     False  False  False   True  False  False  False\n",
       "3     False  False  False   True  False  False  False\n",
       "4     False  False  False   True  False  False  False\n",
       "...     ...    ...    ...    ...    ...    ...    ...\n",
       "4893  False  False  False   True  False  False  False\n",
       "4894  False  False   True  False  False  False  False\n",
       "4895  False  False  False   True  False  False  False\n",
       "4896  False  False  False  False   True  False  False\n",
       "4897  False  False  False   True  False  False  False\n",
       "\n",
       "[4898 rows x 7 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "45176402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      6\n",
       "1      6\n",
       "2      7\n",
       "3      7\n",
       "4      5\n",
       "      ..\n",
       "975    6\n",
       "976    4\n",
       "977    5\n",
       "978    6\n",
       "979    6\n",
       "Length: 980, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_class = y_test.idxmax(axis=1)\n",
    "y_test_class=y_test_class.reset_index(drop=True)\n",
    "y_test_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0b765645",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.58      0.21      0.31        33\n",
      "           5       0.60      0.58      0.59       291\n",
      "           6       0.56      0.74      0.64       440\n",
      "           7       0.54      0.32      0.40       176\n",
      "           8       0.00      0.00      0.00        35\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.57       980\n",
      "   macro avg       0.33      0.26      0.28       980\n",
      "weighted avg       0.55      0.57      0.54       980\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_class, wine_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b72dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db6bc535",
   "metadata": {},
   "source": [
    "XGBë¡œ ë¹„êµë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "067ae924",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "13ecb9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 3, 4, 3])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "y2_labeled = le.fit_transform(y2)\n",
    "y2_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e4cf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "13caf2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_valid2, y_train2, y_valid2 = train_test_split(X_scaled, y2_labeled ,test_size=0.4 , stratify=y2_labeled,random_state=10)\n",
    "X_valid2, X_test2, y_valid2, y_test2 = train_test_split(X_valid2, y_valid2, test_size=0.5,stratify=y_valid2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0fc7d14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Using cached xgboost-2.1.1-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /home/user/miniforge3/envs/dml/lib/python3.9/site-packages (from xgboost) (1.26.4)\n",
      "Collecting nvidia-nccl-cu12 (from xgboost)\n",
      "  Using cached nvidia_nccl_cu12-2.22.3-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: scipy in /home/user/miniforge3/envs/dml/lib/python3.9/site-packages (from xgboost) (1.13.1)\n",
      "Using cached xgboost-2.1.1-py3-none-manylinux_2_28_x86_64.whl (153.9 MB)\n",
      "Using cached nvidia_nccl_cu12-2.22.3-py3-none-manylinux2014_x86_64.whl (190.9 MB)\n",
      "Installing collected packages: nvidia-nccl-cu12, xgboost\n",
      "Successfully installed nvidia-nccl-cu12-2.22.3 xgboost-2.1.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "af6bc97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b5100731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.48      0.33      0.39        33\n",
      "           2       0.64      0.61      0.62       291\n",
      "           3       0.64      0.70      0.67       440\n",
      "           4       0.59      0.60      0.59       176\n",
      "           5       0.60      0.34      0.44        35\n",
      "           6       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.62       980\n",
      "   macro avg       0.42      0.37      0.39       980\n",
      "weighted avg       0.62      0.62      0.62       980\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "xgb=XGBClassifier(max_depth=5, n_estimators = 1000, random_state = 10, n_jobs=-1)\n",
    "xgb.fit(X_train2, y_train2)\n",
    "xgb_pred=xgb.predict(X_valid2)\n",
    "print(classification_report(y_valid2, xgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11800087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfb36e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad74c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585e8ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8b2afe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b08a73d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2788b2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d4ab09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f8e597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
