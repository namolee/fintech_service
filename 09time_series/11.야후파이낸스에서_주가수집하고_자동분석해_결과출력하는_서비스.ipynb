{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "369994a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aae7039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install koreanize-matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9be82b9e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haram4th/anaconda3/envs/ag/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241020_105444\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.15\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Fri Mar 29 23:14:13 UTC 2024\n",
      "CPU Count:          20\n",
      "Memory Avail:       13.64 GB / 15.49 GB (88.1%)\n",
      "Disk Space Avail:   492.75 GB / 953.85 GB (51.7%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20241020_105444\"\n",
      "Train Data Rows:    2718\n",
      "Train Data Columns: 1\n",
      "Label Column:       label\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (211.3800048828125, 1.6200000047683716, 51.98298, 51.50484)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    13968.09 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 1 | ['Day']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 1 | ['Day']\n",
      "\t0.0s = Fit runtime\n",
      "\t1 features in original data used to generate 1 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.18395879323031641, Train Rows: 2218, Val Rows: 500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-2.3059\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-2.1056\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 7.82448\n",
      "[2000]\tvalid_set's rmse: 6.52296\n",
      "[3000]\tvalid_set's rmse: 5.90367\n",
      "[4000]\tvalid_set's rmse: 5.53968\n",
      "[5000]\tvalid_set's rmse: 5.26042\n",
      "[6000]\tvalid_set's rmse: 5.08921\n",
      "[7000]\tvalid_set's rmse: 4.90696\n",
      "[8000]\tvalid_set's rmse: 4.78863\n",
      "[9000]\tvalid_set's rmse: 4.67797\n",
      "[10000]\tvalid_set's rmse: 4.58337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-4.5834\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.5s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 3.49426\n",
      "[2000]\tvalid_set's rmse: 3.48833\n",
      "[3000]\tvalid_set's rmse: 3.48811\n",
      "[4000]\tvalid_set's rmse: 3.48807\n",
      "[5000]\tvalid_set's rmse: 3.48806\n",
      "[6000]\tvalid_set's rmse: 3.48805\n",
      "[7000]\tvalid_set's rmse: 3.48805\n",
      "[8000]\tvalid_set's rmse: 3.48805\n",
      "[9000]\tvalid_set's rmse: 3.48805\n",
      "[10000]\tvalid_set's rmse: 3.48805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-3.4881\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.94s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-2.3173\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-3.2028\t = Validation score   (-root_mean_squared_error)\n",
      "\t49.21s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-1.9866\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.55s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\tWarning: Exception caused NeuralNetFastAI to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`. \n",
      "Fitting model: XGBoost ...\n",
      "\t-3.2629\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.29s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "/home/haram4th/anaconda3/envs/ag/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model = torch.load(net_filename)\n",
      "\t-7.3557\t = Validation score   (-root_mean_squared_error)\n",
      "\t17.5s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 3.38913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-3.3891\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.33s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'ExtraTreesMSE': 1.0}\n",
      "\t-1.9866\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 79.88s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 6627.2 rows/s (500 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241020_105444\")\n",
      "/tmp/ipykernel_33102/4223032373.py:54: DeprecationWarning: `get_model_names` has been deprecated and will be removed in version 1.2. Please use `model_names` instead. This will raise an error in the future!\n",
      "  models = predictor.get_model_names()\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "import koreanize_matplotlib\n",
    "\n",
    "# 1. 분석할 주식 리스트 (Apple, Microsoft, Amazon, Tesla, Nvidia, AMD)\n",
    "tickers = {'AAPL': 'Apple', 'MSFT': 'Microsoft', 'AMZN': 'Amazon', 'TSLA': 'Tesla', 'NVDA': 'Nvidia', 'AMD': 'AMD'}\n",
    "\n",
    "# 2. 날짜 설정 (2014년 1월 1일부터 전날까지)\n",
    "end_date = datetime.now() - timedelta(days=1)  # 전날까지의 데이터\n",
    "start_date = datetime.strptime(\"2014-01-01\", \"%Y-%m-%d\")  # 2014년 1월 1일부터\n",
    "\n",
    "# 3. 주식 데이터를 불러오는 함수\n",
    "def load_stock_data(selected_ticker):\n",
    "    if selected_ticker not in tickers:\n",
    "        return f\"잘못된 티커를 입력하셨습니다.\"\n",
    "    \n",
    "    # yfinance로 주식 데이터 불러오기\n",
    "    df = yf.download(selected_ticker, start=start_date, end=end_date)\n",
    "    \n",
    "    if df.empty:\n",
    "        return f\"{tickers[selected_ticker]}에 대한 데이터가 없습니다.\"\n",
    "    \n",
    "    return df.head(), df.tail()  # 데이터를 head와 tail로 반환\n",
    "\n",
    "# 4. 분석 및 시각화하는 함수\n",
    "def analyze_stock(selected_ticker):\n",
    "    df = yf.download(selected_ticker, start=start_date, end=end_date)\n",
    "\n",
    "    # 데이터 전처리\n",
    "    df.reset_index(inplace=True)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['Day'] = (df['Date'] - df['Date'].min()).dt.days  # 날짜를 숫자로 변환\n",
    "\n",
    "    # 50일, 200일 이동평균선 계산\n",
    "    df['MA50'] = df['Close'].rolling(window=50).mean()\n",
    "    df['MA200'] = df['Close'].rolling(window=200).mean()\n",
    "\n",
    "    # 매수 및 매도 시점 계산\n",
    "    df['Signal'] = 0\n",
    "    df.loc[50:, 'Signal'] = np.where(df['MA50'][50:] > df['MA200'][50:], 1, 0)\n",
    "    df['Position'] = df['Signal'].diff()\n",
    "\n",
    "    # AutoGluon을 이용한 종가 예측\n",
    "    train_data = df[['Day', 'Close']].copy()\n",
    "    train_data = train_data.rename(columns={'Close': 'label'})\n",
    "    predictor = TabularPredictor(label='label').fit(train_data)\n",
    "\n",
    "    best_model = predictor.model_best\n",
    "    models = predictor.get_model_names()\n",
    "    all_predictions = [predictor.predict(train_data.drop(columns=['label']), model=model) for model in models]\n",
    "    mean_predictions = np.mean(np.array(all_predictions), axis=0)\n",
    "    std_predictions = np.std(np.array(all_predictions), axis=0)\n",
    "\n",
    "    mape = np.mean(np.abs((train_data['label'] - mean_predictions) / train_data['label'])) * 100\n",
    "\n",
    "    # 향후 30일 예측값 계산\n",
    "    future_dates = [end_date + timedelta(days=i) for i in range(1, 31)]\n",
    "    future_days = [(date - df['Date'].min()).days for date in future_dates]\n",
    "    future_df = pd.DataFrame({'Day': future_days})\n",
    "    future_all_predictions = [predictor.predict(future_df, model=model) for model in models]\n",
    "    future_mean_predictions = np.mean(np.array(future_all_predictions), axis=0)\n",
    "    future_std_predictions = np.std(np.array(future_all_predictions), axis=0)\n",
    "\n",
    "    # 시각화 함수\n",
    "    def plot_graph(data_df, future_dates, future_mean_predictions, future_std_predictions, title):\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        plt.plot(data_df['Date'], data_df['Close'], label=f'{selected_ticker} Actual Close Prices', color='#A1C6EA')  # 파스텔 블루\n",
    "        plt.plot(data_df['Date'], data_df['MA50'], label='50-Day Moving Average', color='#F4B3C2', linestyle='--')  # 파스텔 핑크\n",
    "        plt.plot(data_df['Date'], data_df['MA200'], label='200-Day Moving Average', color='#B3D4A7', linestyle='--')  # 파스텔 그린\n",
    "        plt.plot(data_df[data_df['Position'] == 1]['Date'], data_df[data_df['Position'] == 1]['Close'], '^', markersize=10, color='red', lw=0, label='Buy Signal')\n",
    "        plt.plot(data_df[data_df['Position'] == -1]['Date'], data_df[data_df['Position'] == -1]['Close'], 'v', markersize=10, color='blue', lw=0, label='Sell Signal')\n",
    "        plt.plot(future_dates, future_mean_predictions, label='Future Predicted Prices', color='#B3D4A7', linestyle='--')\n",
    "        plt.fill_between(future_dates, future_mean_predictions - future_std_predictions, future_mean_predictions + future_std_predictions, color='#B3D4A7', alpha=0.2)\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Stock Price')\n",
    "        plt.title(title)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Gradio에서 그래프를 반환할 수 있도록 설정\n",
    "        return plt.gcf()\n",
    "\n",
    "    # 전체 기간 그래프\n",
    "    total_graph = plot_graph(df, future_dates, future_mean_predictions, future_std_predictions, \"전체 기간 및 예측\")\n",
    "\n",
    "    # 최근 3개월 데이터\n",
    "    last_3_months = df[df['Date'] >= (end_date - timedelta(days=90))]\n",
    "    three_month_graph = plot_graph(last_3_months, future_dates, future_mean_predictions, future_std_predictions, \"최근 3개월 및 예측\")\n",
    "\n",
    "    # 최근 1개월 데이터\n",
    "    last_1_month = df[df['Date'] >= (end_date - timedelta(days=30))]\n",
    "    one_month_graph = plot_graph(last_1_month, future_dates, future_mean_predictions, future_std_predictions, \"최근 1개월 및 예측\")\n",
    "\n",
    "    # MAPE 계산 결과 텍스트와 함께 반환\n",
    "    return total_graph, three_month_graph, one_month_graph, f\"{tickers[selected_ticker]} 분석 완료, MAPE: {mape:.2f}%\"\n",
    "\n",
    "# Gradio 이벤트 정의 수정\n",
    "def stock_analysis(selected_ticker):\n",
    "    total_graph, three_month_graph, one_month_graph, analysis_result = analyze_stock(selected_ticker)\n",
    "    # 각각의 그래프와 텍스트를 개별적으로 반환\n",
    "    return total_graph, three_month_graph, one_month_graph, analysis_result\n",
    "\n",
    "# Gradio UI 수정\n",
    "app = gr.Blocks()\n",
    "\n",
    "with app:\n",
    "    gr.Markdown(\"## 주식 데이터 조회 및 분석\")\n",
    "    \n",
    "    stock_ticker_dropdown = gr.Dropdown(choices=list(tickers.keys()), label=\"주식을 선택하세요\", value=\"AAPL\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        stock_ticker_dropdown\n",
    "    \n",
    "    df_head_output = gr.Dataframe(label=\"Head 데이터\")\n",
    "    df_tail_output = gr.Dataframe(label=\"Tail 데이터\")\n",
    "    \n",
    "    stock_view_button = gr.Button(\"주가 보기\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        stock_view_button\n",
    "    \n",
    "    with gr.Row():\n",
    "        df_head_output\n",
    "        df_tail_output\n",
    "    \n",
    "    total_graph_output = gr.Plot(label=\"전체 기간 그래프\")\n",
    "    three_month_graph_output = gr.Plot(label=\"최근 3개월 그래프\")\n",
    "    one_month_graph_output = gr.Plot(label=\"최근 1개월 그래프\")\n",
    "    analysis_text_output = gr.Textbox(label=\"분석 결과\")\n",
    "    \n",
    "    stock_analysis_button = gr.Button(\"주식 분석하기\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        stock_analysis_button\n",
    "    \n",
    "    with gr.Row():\n",
    "        total_graph_output\n",
    "        three_month_graph_output\n",
    "        one_month_graph_output\n",
    "        analysis_text_output\n",
    "\n",
    "    # Gradio 이벤트 정의\n",
    "    stock_view_button.click(load_stock_data, inputs=stock_ticker_dropdown, outputs=[df_head_output, df_tail_output])\n",
    "    stock_analysis_button.click(stock_analysis, inputs=stock_ticker_dropdown, outputs=[total_graph_output, three_month_graph_output, one_month_graph_output, analysis_text_output])\n",
    "\n",
    "# Gradio 앱 실행\n",
    "app.launch(inline=False, inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18256eb0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb82d6ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c60af6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
