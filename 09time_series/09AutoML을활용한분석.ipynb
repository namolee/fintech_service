{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4f389bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flaml[catboost]\n",
      "  Downloading FLAML-2.3.1-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: NumPy>=1.17 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from flaml[catboost]) (1.26.4)\n",
      "Collecting catboost<1.2,>=0.26 (from flaml[catboost])\n",
      "  Downloading catboost-1.1.1-cp310-none-win_amd64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: graphviz in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from catboost<1.2,>=0.26->flaml[catboost]) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from catboost<1.2,>=0.26->flaml[catboost]) (3.9.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from catboost<1.2,>=0.26->flaml[catboost]) (2.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from catboost<1.2,>=0.26->flaml[catboost]) (1.13.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from catboost<1.2,>=0.26->flaml[catboost]) (5.24.1)\n",
      "Requirement already satisfied: six in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from catboost<1.2,>=0.26->flaml[catboost]) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from pandas>=0.24.0->catboost<1.2,>=0.26->flaml[catboost]) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from pandas>=0.24.0->catboost<1.2,>=0.26->flaml[catboost]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from pandas>=0.24.0->catboost<1.2,>=0.26->flaml[catboost]) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from matplotlib->catboost<1.2,>=0.26->flaml[catboost]) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from matplotlib->catboost<1.2,>=0.26->flaml[catboost]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from matplotlib->catboost<1.2,>=0.26->flaml[catboost]) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from matplotlib->catboost<1.2,>=0.26->flaml[catboost]) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from matplotlib->catboost<1.2,>=0.26->flaml[catboost]) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from matplotlib->catboost<1.2,>=0.26->flaml[catboost]) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from matplotlib->catboost<1.2,>=0.26->flaml[catboost]) (3.1.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from plotly->catboost<1.2,>=0.26->flaml[catboost]) (9.0.0)\n",
      "Downloading catboost-1.1.1-cp310-none-win_amd64.whl (73.9 MB)\n",
      "   ---------------------------------------- 0.0/73.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/73.9 MB 1.7 MB/s eta 0:00:45\n",
      "   - -------------------------------------- 3.3/73.9 MB 34.5 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 7.8/73.9 MB 55.4 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 8.7/73.9 MB 50.4 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 9.6/73.9 MB 41.0 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 13.9/73.9 MB 54.7 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 18.5/73.9 MB 54.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 23.1/73.9 MB 93.0 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 27.6/73.9 MB 108.8 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 32.0/73.9 MB 108.8 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 34.9/73.9 MB 93.0 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 37.9/73.9 MB 81.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 38.5/73.9 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 40.9/73.9 MB 50.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 42.2/73.9 MB 46.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 42.3/73.9 MB 43.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 42.5/73.9 MB 34.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 42.5/73.9 MB 31.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 42.9/73.9 MB 25.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 44.0/73.9 MB 24.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 45.4/73.9 MB 22.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 46.4/73.9 MB 21.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 46.7/73.9 MB 19.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 47.7/73.9 MB 18.2 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 49.6/73.9 MB 19.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 51.9/73.9 MB 18.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 54.3/73.9 MB 31.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 57.0/73.9 MB 43.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 59.9/73.9 MB 54.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 63.1/73.9 MB 59.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 65.2/73.9 MB 65.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 65.6/73.9 MB 46.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 67.7/73.9 MB 46.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 71.4/73.9 MB 46.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  73.9/73.9 MB 50.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  73.9/73.9 MB 50.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  73.9/73.9 MB 50.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  73.9/73.9 MB 50.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  73.9/73.9 MB 50.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 73.9/73.9 MB 25.2 MB/s eta 0:00:00\n",
      "Downloading FLAML-2.3.1-py3-none-any.whl (313 kB)\n",
      "   ---------------------------------------- 0.0/313.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 313.3/313.3 kB 9.8 MB/s eta 0:00:00\n",
      "Installing collected packages: flaml, catboost\n",
      "Successfully installed catboost-1.1.1 flaml-2.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install \"flaml[catboost]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26652a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autogluon\n",
      "  Using cached autogluon-1.1.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting autogluon.core==1.1.1 (from autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached autogluon.core-1.1.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting autogluon.features==1.1.1 (from autogluon)\n",
      "  Using cached autogluon.features-1.1.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting autogluon.tabular==1.1.1 (from autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached autogluon.tabular-1.1.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting autogluon.multimodal==1.1.1 (from autogluon)\n",
      "  Using cached autogluon.multimodal-1.1.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting autogluon.timeseries==1.1.1 (from autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached autogluon.timeseries-1.1.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy<1.29,>=1.21 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.26.4)\n",
      "Collecting scipy<1.13,>=1.5.4 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached scipy-1.12.0-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Collecting scikit-learn<1.4.1,>=1.3.0 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached scikit_learn-1.4.0-1-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: networkx<4,>=3.0 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.3)\n",
      "Requirement already satisfied: pandas<2.3.0,>=2.0.0 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.2.2)\n",
      "Requirement already satisfied: tqdm<5,>=4.38 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (4.66.5)\n",
      "Requirement already satisfied: requests in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.32.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.9.1)\n",
      "Collecting boto3<2,>=1.10 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached boto3-1.35.42-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting autogluon.common==1.1.1 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached autogluon.common-1.1.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting ray<2.11,>=2.10.0 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached ray-2.10.0-cp310-cp310-win_amd64.whl.metadata (13 kB)\n",
      "Collecting hyperopt<0.2.8,>=0.2.7 (from autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached hyperopt-0.2.7-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: Pillow<11,>=10.0.1 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from autogluon.multimodal==1.1.1->autogluon) (10.4.0)\n",
      "Collecting torch<2.4,>=2.2 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached torch-2.3.1-cp310-cp310-win_amd64.whl.metadata (26 kB)\n",
      "Collecting lightning<2.4,>=2.2 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached lightning-2.3.3-py3-none-any.whl.metadata (35 kB)\n",
      "Collecting transformers<4.41.0,>=4.38.0 (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached transformers-4.40.2-py3-none-any.whl.metadata (137 kB)\n",
      "Collecting accelerate<0.22.0,>=0.21.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting jsonschema<4.22,>=4.18 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached seqeval-1.2.2.tar.gz (43 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting timm<0.10.0,>=0.9.5 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached timm-0.9.16-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting torchvision<0.19.0,>=0.16.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached torchvision-0.18.1-cp310-cp310-win_amd64.whl.metadata (6.6 kB)\n",
      "Collecting scikit-image<0.21.0,>=0.19.1 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached scikit_image-0.20.0-cp310-cp310-win_amd64.whl.metadata (16 kB)\n",
      "Collecting text-unidecode<1.4,>=1.3 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting torchmetrics<1.3.0,>=1.2.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached torchmetrics-1.2.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting nptyping<2.5.0,>=1.4.4 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached nptyping-2.4.1-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting omegaconf<2.3.0,>=2.1.1 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting pytorch-metric-learning<2.4,>=1.3.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached pytorch_metric_learning-2.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.4.5 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from autogluon.multimodal==1.1.1->autogluon) (3.9.1)\n",
      "Collecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: defusedxml<0.7.2,>=0.7.1 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from autogluon.multimodal==1.1.1->autogluon) (0.7.1)\n",
      "Requirement already satisfied: jinja2<3.2,>=3.0.3 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from autogluon.multimodal==1.1.1->autogluon) (3.1.4)\n",
      "Collecting tensorboard<3,>=2.9 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting pytesseract<0.3.11,>=0.3.9 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached pytesseract-0.3.10-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-ml-py3==7.352.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pdf2image<1.19,>=1.17.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting xgboost<2.1,>=1.6 (from autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached xgboost-2.0.3-py3-none-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting fastai<2.8,>=2.3.1 (from autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached fastai-2.7.17-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting lightgbm<4.4,>=3.3 (from autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached lightgbm-4.3.0-py3-none-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: catboost<1.3,>=1.1 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (1.1.1)\n",
      "Requirement already satisfied: joblib<2,>=1.1 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (1.4.2)\n",
      "Collecting pytorch-lightning<2.4,>=2.2 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached pytorch_lightning-2.3.3-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting gluonts==0.15.1 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached gluonts-0.15.1-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting statsforecast<1.5,>=1.4.0 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached statsforecast-1.4.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting mlforecast<0.10.1,>=0.10.0 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached mlforecast-0.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting utilsforecast<0.0.11,>=0.0.10 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached utilsforecast-0.0.10-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: orjson~=3.9 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (3.10.7)\n",
      "Collecting optimum<1.19,>=1.17 (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached optimum-1.18.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting psutil<6,>=5.7.3 (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached psutil-5.9.8-cp37-abi3-win_amd64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (70.1.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.7 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (2.8.2)\n",
      "Collecting toolz~=0.10 (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (4.12.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.1->autogluon) (24.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.1->autogluon) (6.0.1)\n",
      "Collecting botocore<1.36.0,>=1.35.42 (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached botocore-1.35.42-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached s3transfer-0.10.3-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: graphviz in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (0.20.3)\n",
      "Requirement already satisfied: plotly in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (5.24.1)\n",
      "Requirement already satisfied: six in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (1.16.0)\n",
      "Collecting datasets>=2.0.0 (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting dill (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached xxhash-3.5.0-cp310-cp310-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (2024.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (0.25.1)\n",
      "Requirement already satisfied: pip in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (24.0)\n",
      "Collecting fastdownload<2,>=0.0.5 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached fastdownload-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting fastcore<1.8,>=1.5.29 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached fastcore-1.7.17-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting fastprogress>=0.2.4 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached fastprogress-1.0.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting spacy<4 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached spacy-3.8.2-cp310-cp310-win_amd64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: future in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (1.0.0)\n",
      "Collecting cloudpickle (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached cloudpickle-3.1.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting py4j (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached py4j-0.10.9.7-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.1.1->autogluon) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (0.18.1)\n",
      "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached lightning_utilities-0.11.8-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: numba in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.60.0)\n",
      "Collecting window-ops (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting gdown>=4.0.0 (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: click in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.1.1->autogluon) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.1.1->autogluon) (2024.9.11)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: colorama in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.4.6)\n",
      "Collecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: rich in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (13.8.1)\n",
      "Collecting tabulate (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting coloredlogs (from optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting sympy (from optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting transformers<4.41.0,>=4.38.0 (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached transformers-4.39.3-py3-none-any.whl.metadata (134 kB)\n",
      "Collecting onnx (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached onnx-1.17.0-cp310-cp310-win_amd64.whl.metadata (16 kB)\n",
      "Collecting onnxruntime>=1.11.0 (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached onnxruntime-1.19.2-cp310-cp310-win_amd64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: protobuf>=3.20.1 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (5.28.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2024.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (3.16.1)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached msgpack-1.1.0-cp310-cp310-win_amd64.whl.metadata (8.6 kB)\n",
      "Collecting aiosignal (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting frozenlist (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached frozenlist-1.4.1-cp310-cp310-win_amd64.whl.metadata (12 kB)\n",
      "Collecting tensorboardX>=1.9 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting pyarrow>=6.0.1 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached pyarrow-17.0.0-cp310-cp310-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting aiohttp>=3.7 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached aiohttp-3.10.10-cp310-cp310-win_amd64.whl.metadata (7.8 kB)\n",
      "Collecting aiohttp-cors (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting colorful (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting py-spy>=0.2.0 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached py_spy-0.3.14-py2.py3-none-win_amd64.whl.metadata (16 kB)\n",
      "Collecting opencensus (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: prometheus-client>=0.7.1 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.20.0)\n",
      "Collecting smart-open (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached smart_open-7.0.5-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached virtualenv-20.26.6-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: grpcio>=1.42.0 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.66.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2024.8.30)\n",
      "Collecting imageio>=2.4.1 (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached imageio-2.36.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting tifffile>=2019.7.26 (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached tifffile-2024.9.20-py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (1.7.0)\n",
      "Collecting lazy_loader>=0.1 (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from scikit-learn<1.4.1,>=1.3.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.5.0)\n",
      "Requirement already satisfied: statsmodels>=0.13.2 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from statsforecast<1.5,>=1.4.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.14.2)\n",
      "Collecting absl-py>=0.4 (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached werkzeug-3.0.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting safetensors (from timm<0.10.0,>=0.9.5->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached safetensors-0.4.5-cp310-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting mkl<=2021.4.0,>=2021.1.1 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers<4.41.0,>=4.38.0->transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached tokenizers-0.15.2-cp310-none-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached sentencepiece-0.2.0-cp310-cp310-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.1.2)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached multidict-6.1.0-cp310-cp310-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached yarl-1.15.4-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting dill (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (4.12.3)\n",
      "Collecting intel-openmp==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting tbb==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached tbb-2021.13.1-py3-none-win_amd64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from numba->mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.43.0)\n",
      "Collecting flatbuffers (from onnxruntime>=1.11.0->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from pydantic<3,>=1.7->gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from pydantic<3,>=1.7->gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (2.20.1)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached murmurhash-1.0.10-cp310-cp310-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached cymem-2.0.8-cp310-cp310-win_amd64.whl.metadata (8.6 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached preshed-3.0.9-cp310-cp310-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.0 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached thinc-8.3.2-cp310-cp310-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached srsly-2.4.8-cp310-cp310-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.12.5)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached langcodes-3.4.1-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from statsmodels>=0.13.2->statsforecast<1.5,>=1.4.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.5.6)\n",
      "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (4.2.2)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting ordered-set (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (2.20.0)\n",
      "Collecting pycryptodome (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached pycryptodome-3.21.0-cp36-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached openxlab-0.1.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (306)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from plotly->catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (9.0.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (2.18.0)\n",
      "Collecting wrapt (from smart-open->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached wrapt-1.16.0-cp310-cp310-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.65.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.24.0)\n",
      "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (2.35.0)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached language_data-1.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\5-11\\miniforge3\\envs\\fintech\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.1.2)\n",
      "Collecting blis<1.1.0,>=1.0.0 (from thinc<8.4.0,>=8.3.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached blis-1.0.1-cp310-cp310-win_amd64.whl.metadata (7.8 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "INFO: pip is looking at multiple versions of thinc to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting thinc<8.4.0,>=8.3.0 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached thinc-8.3.1-cp310-cp310-win_amd64.whl.metadata (15 kB)\n",
      "  Using cached thinc-8.3.0-cp310-cp310-win_amd64.whl.metadata (15 kB)\n",
      "Collecting patsy>=0.5.6 (from statsmodels>=0.13.2->statsforecast<1.5,>=1.4.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting window-ops (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached window_ops-0.0.14-py3-none-any.whl.metadata (6.9 kB)\n",
      "INFO: pip is still looking at multiple versions of thinc to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached window_ops-0.0.13-py3-none-any.whl.metadata (5.0 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached window_ops-0.0.12-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Using cached window_ops-0.0.11-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Using cached window_ops-0.0.10-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Using cached window_ops-0.0.9-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Using cached window_ops-0.0.8-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Using cached window_ops-0.0.7-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Using cached window_ops-0.0.6-py3-none-any.whl.metadata (3.4 kB)\n",
      "  Using cached window_ops-0.0.5-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Using cached window_ops-0.0.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "  Using cached window_ops-0.0.3-py3-none-any.whl.metadata (3.5 kB)\n",
      "  Using cached window_ops-0.0.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "  Using cached window_ops-0.0.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting onnx (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached onnx-1.16.2-cp310-cp310-win_amd64.whl.metadata (16 kB)\n",
      "  Using cached onnx-1.16.1-cp310-cp310-win_amd64.whl.metadata (16 kB)\n",
      "  Using cached onnx-1.16.0-cp310-cp310-win_amd64.whl.metadata (16 kB)\n",
      "  Using cached onnx-1.15.0-cp310-cp310-win_amd64.whl.metadata (15 kB)\n",
      "  Using cached onnx-1.14.1-cp310-cp310-win_amd64.whl.metadata (15 kB)\n",
      "  Using cached onnx-1.14.0-cp310-cp310-win_amd64.whl.metadata (15 kB)\n",
      "  Using cached onnx-1.13.1-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
      "Collecting protobuf>=3.20.1 (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached protobuf-3.20.3-cp310-cp310-win_amd64.whl.metadata (698 bytes)\n",
      "Collecting onnx (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached onnx-1.13.0-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
      "  Using cached onnx-1.12.0-cp310-cp310-win_amd64.whl.metadata (13 kB)\n",
      "Collecting protobuf>=3.20.1 (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached protobuf-3.20.1-cp310-cp310-win_amd64.whl.metadata (698 bytes)\n",
      "Collecting onnx (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached onnx-1.11.0.tar.gz (9.9 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading onnx-1.10.2.tar.gz (9.9 MB)\n",
      "     ---------------------------------------- 0.0/9.9 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/9.9 MB 330.3 kB/s eta 0:00:30\n",
      "     - -------------------------------------- 0.5/9.9 MB 4.7 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 2.2/9.9 MB 17.6 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 2.3/9.9 MB 14.5 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 2.3/9.9 MB 10.5 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 2.5/9.9 MB 8.7 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 2.6/9.9 MB 8.2 MB/s eta 0:00:01\n",
      "     ----------- ---------------------------- 2.9/9.9 MB 7.7 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 4.3/9.9 MB 10.2 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 4.5/9.9 MB 9.9 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 4.8/9.9 MB 9.3 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 6.7/9.9 MB 11.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  9.9/9.9 MB 16.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 9.9/9.9 MB 15.8 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Downloading onnx-1.10.1.tar.gz (10.0 MB)\n",
      "     ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.2/10.0 MB 10.9 MB/s eta 0:00:01\n",
      "     - -------------------------------------- 0.4/10.0 MB 5.3 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 0.9/10.0 MB 6.8 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 1.2/10.0 MB 7.8 MB/s eta 0:00:02\n",
      "     ----- ---------------------------------- 1.5/10.0 MB 6.7 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 1.9/10.0 MB 7.2 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 5.9/10.0 MB 18.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 9.6/10.0 MB 26.8 MB/s eta 0:00:01\n",
      "     --------------------------------------- 10.0/10.0 MB 25.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading onnx-1.10.0.tar.gz (10.0 MB)\n",
      "     ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "     --------------- ----------------------- 3.9/10.0 MB 122.9 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 4.3/10.0 MB 91.5 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 4.5/10.0 MB 35.6 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 4.6/10.0 MB 29.2 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 4.9/10.0 MB 22.4 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 6.3/10.0 MB 25.4 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 6.5/10.0 MB 20.6 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 6.6/10.0 MB 18.3 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 6.8/10.0 MB 16.7 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 7.2/10.0 MB 16.3 MB/s eta 0:00:01\n",
      "     --------------------------------------  10.0/10.0 MB 20.6 MB/s eta 0:00:01\n",
      "     --------------------------------------- 10.0/10.0 MB 19.4 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [7 lines of output]\n",
      "  fatal: not a git repository (or any of the parent directories): .git\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 2, in <module>\n",
      "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "    File \"C:\\Users\\5-11\\AppData\\Local\\Temp\\pip-install-blc7ohyf\\onnx_a44886f39b984ee6b68d1b56890973d0\\setup.py\", line 318, in <module>\n",
      "      raise FileNotFoundError(\"Unable to find \" + requirements_file)\n",
      "  FileNotFoundError: Unable to find requirements.txt\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60d73674",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'autogluon'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautogluon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtabular\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TabularPredictor\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'autogluon'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autogluon.tabular import TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c23da6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/haram4th/ablearn/main/Taitanic_train.csv\")\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f68f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['PassengerId', 'Cabin', 'Ticket', 'Name', 'Fare'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f62744",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'Survived'\n",
    "\n",
    "time_limit = 60  # for quick demonstration only, you should set this to longest time you are willing to wait (in seconds)\n",
    "metric = 'roc_auc'  # specify your evaluation metric here\n",
    "\n",
    "model = TabularPredictor(label=target_column, eval_metric=metric)\n",
    "model.fit(data, time_limit=time_limit, presets='best_quality' )\n",
    "test_data = data.sample(frac=0.3, random_state=10)\n",
    "\n",
    "pred = model.predict(test_data)\n",
    "print(\"Train Score:\", model.evaluate(test_data))\n",
    "print(\"best model: \", model.get_model_best())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e45f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.evaluate(test_data)\n",
    "pd.DataFrame(result, index=result.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae75ace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.leaderboard(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b009ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.feature_importance(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6a08d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0839cb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65761054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b696a778",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/haram4th/ADsP/main/salary2.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abff65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'class'\n",
    "\n",
    "time_limit = 180  # for quick demonstration only, you should set this to longest time you are willing to wait (in seconds)\n",
    "metric = 'accuracy'  # specify your evaluation metric here\n",
    "\n",
    "model = TabularPredictor(label=target_column, eval_metric=metric)\n",
    "model.fit(data, time_limit=time_limit, presets='best_quality' )\n",
    "test_data = data.sample(frac=0.3, random_state=10)\n",
    "\n",
    "pred = model.predict(test_data)\n",
    "\n",
    "result = model.evaluate(test_data)\n",
    "result_df = pd.DataFrame(result, index=result.keys())\n",
    "leader_board = model.leaderboard(test_data)\n",
    "feature_importance = model.feature_importance(test_data)\n",
    "best_model_name = model.model_best\n",
    "best_model = model._trainer.load_model(best_model_name)  # Load the best model\n",
    "best_model_params = best_model.params\n",
    "\n",
    "\n",
    "display(result_df)\n",
    "print()\n",
    "display(leader_board)\n",
    "print()\n",
    "display(feature_importance)\n",
    "print(\"best_model\",best_model_name)\n",
    "print(\"Best model hyperparameters:\")\n",
    "print(best_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89bfc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best_model\",best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8402759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31425086",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/haram4th/ADsP/main/01%EB%B3%B4%EC%8A%A4%ED%84%B4%EC%A7%91%EA%B0%92%EB%8D%B0%EC%9D%B4%ED%84%B0.csv\", encoding='utf-8')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d9c718",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = ''\n",
    "\n",
    "time_limit = 300  # for quick demonstration only, you should set this to longest time you are willing to wait (in seconds)\n",
    "metric = 'root_mean_squared_error'  # specify your evaluation metric here\n",
    "\n",
    "model = TabularPredictor(label=target_column, eval_metric=metric)\n",
    "model.fit(data, time_limit=time_limit, presets='best_quality' )\n",
    "test_data = data.sample(frac=0.3, random_state=10)\n",
    "\n",
    "pred = model.predict(test_data)\n",
    "\n",
    "result = model.evaluate(test_data)\n",
    "result_df = pd.DataFrame(result, index=result.keys())\n",
    "leader_board = model.leaderboard(test_data)\n",
    "feature_importance = model.feature_importance(test_data)\n",
    "best_model_name = model.model_best\n",
    "best_model = model._trainer.load_model(best_model_name)  # Load the best model\n",
    "best_model_params = best_model.params\n",
    "\n",
    "\n",
    "display(result_df)\n",
    "print()\n",
    "display(leader_board)\n",
    "print()\n",
    "display(feature_importance)\n",
    "print(\"best_model\",best_model_name)\n",
    "print(\"Best model hyperparameters:\")\n",
    "print(best_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d9ffd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f85e850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cacdb37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6b5d78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038cd1ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1261d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01643c25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918d6c61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11307a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda79e68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d87b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bad527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e2c40b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dbfade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6bea9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ad6ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1024bc57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9615463a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481309f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c322320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f11fba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9132ccf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdadb08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaf25c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a2ecc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70af53a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac2463a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1e6bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f2e973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d82cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1e4e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add6a632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
